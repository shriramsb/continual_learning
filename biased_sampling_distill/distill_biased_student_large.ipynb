{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages and limit GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "import networks\n",
    "import utils\n",
    "import biased_sampler\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True    # set use_gpu to True if system has gpu\n",
    "gpu_id = 1        # id of gpu to be used\n",
    "cpu_device = torch.device('cpu')\n",
    "# fast_device is where computation (training, inference) happens\n",
    "fast_device = torch.device('cpu')\n",
    "if use_gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'    # set visible devices depending on system configuration\n",
    "    fast_device = torch.device('cuda:' + str(gpu_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure reproducibility\n",
    "def reproducibilitySeed():\n",
    "    \"\"\"\n",
    "    Ensure reproducibility of results; Seeds to 0\n",
    "    \"\"\"\n",
    "    torch_init_seed = 0\n",
    "    torch.manual_seed(torch_init_seed)\n",
    "    numpy_init_seed = 0\n",
    "    np.random.seed(numpy_init_seed)\n",
    "    if use_gpu:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "reproducibilitySeed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Student trained without data augmentation\n",
    "transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5), (0.5, 0.5))\n",
    "                ]\n",
    "            )\n",
    "\n",
    "train_val_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=True, \n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=False, \n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "num_train = int(1.0 * len(train_val_dataset) * 95 / 100)\n",
    "num_val = len(train_val_dataset) - num_train\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_class = 10\n",
    "class_prob = [0.0 for _ in range(num_class)]\n",
    "class_prob[7] = 0.5\n",
    "class_prob[8] = 0.5\n",
    "\n",
    "train_val_biased_sampler = biased_sampler.MNISTClassBiasedSampler(train_val_dataset, class_prob)\n",
    "train_biased_sampler = biased_sampler.MNISTClassBiasedSampler(train_dataset, class_prob)\n",
    "\n",
    "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=128, \n",
    "                                                sampler=train_val_biased_sampler, \n",
    "                                                num_workers=2)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, \n",
    "                                            sampler=train_biased_sampler, \n",
    "                                            num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path_teacher = 'checkpoints_teacher/'\n",
    "checkpoints_path_student = 'checkpoints_student_large_biased/'\n",
    "summaries_path_student = 'summaries_student_large_biased/'\n",
    "if not os.path.exists(checkpoints_path_student):\n",
    "    os.makedirs(checkpoints_path_student)\n",
    "if not os.path.exists(summaries_path_student):\n",
    "    os.makedirs(summaries_path_student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load teacher network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hparams used for training teacher to load the teacher network\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "# keeping dropout input = dropout hidden\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "for hparam_tuple in itertools.product(dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['dropout_input'] = hparam_tuple[0][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[0][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[1]\n",
    "    hparam['lr_decay'] = hparam_tuple[2]\n",
    "    hparam['momentum'] = hparam_tuple[3]\n",
    "    hparam['lr'] = hparam_tuple[4]\n",
    "    hparams_list.append(hparam)\n",
    "    \n",
    "load_path = checkpoints_path_teacher + utils.hparamToString(hparams_list[0]) + '_final.tar'\n",
    "teacher_net = networks.TeacherNetwork()\n",
    "teacher_net.load_state_dict(torch.load(load_path, map_location=fast_device)['model_state_dict'])\n",
    "teacher_net = teacher_net.to(fast_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher test accuracy:  0.9892\n"
     ]
    }
   ],
   "source": [
    "# Calculate teacher test accuracy\n",
    "_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n",
    "print('teacher test accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train student network without distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hparamsT=1, alpha=0.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.103\n",
      "[1,   100/  446] train loss: 0.044 train accuracy: 0.977\n",
      "[1,   200/  446] train loss: 0.023 train accuracy: 0.992\n",
      "[1,   300/  446] train loss: 0.027 train accuracy: 0.984\n",
      "[1,   400/  446] train loss: 0.016 train accuracy: 0.992\n",
      "epoch: 1 validation accuracy: 0.196\n",
      "[2,   100/  446] train loss: 0.005 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.038 train accuracy: 0.984\n",
      "[2,   300/  446] train loss: 0.003 train accuracy: 1.000\n",
      "[2,   400/  446] train loss: 0.018 train accuracy: 0.992\n",
      "epoch: 2 validation accuracy: 0.197\n",
      "[3,   100/  446] train loss: 0.066 train accuracy: 0.984\n",
      "[3,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.017 train accuracy: 0.984\n",
      "[3,   400/  446] train loss: 0.022 train accuracy: 0.984\n",
      "epoch: 3 validation accuracy: 0.197\n",
      "[4,   100/  446] train loss: 0.002 train accuracy: 1.000\n",
      "[4,   200/  446] train loss: 0.004 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.006 train accuracy: 1.000\n",
      "epoch: 4 validation accuracy: 0.197\n",
      "[5,   100/  446] train loss: 0.002 train accuracy: 1.000\n",
      "[5,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.001 train accuracy: 1.000\n",
      "epoch: 5 validation accuracy: 0.197\n",
      "[6,   100/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[6,   200/  446] train loss: 0.006 train accuracy: 1.000\n",
      "[6,   300/  446] train loss: 0.002 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.002 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.198\n",
      "[7,   100/  446] train loss: 0.002 train accuracy: 1.000\n",
      "[7,   200/  446] train loss: 0.002 train accuracy: 1.000\n",
      "[7,   300/  446] train loss: 0.002 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.001 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.197\n",
      "[8,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[8,   300/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.001 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.198\n",
      "[9,   100/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[9,   400/  446] train loss: 0.001 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.198\n",
      "[10,   100/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[10,   200/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.000 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.198\n",
      "[11,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[11,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.000 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.198\n",
      "[12,   100/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[12,   400/  446] train loss: 0.000 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.198\n",
      "[13,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[13,   200/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.001 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.198\n",
      "[14,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[14,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[14,   400/  446] train loss: 0.000 train accuracy: 1.000\n",
      "epoch: 14 validation accuracy: 0.198\n",
      "[15,   100/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[15,   200/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[15,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[15,   400/  446] train loss: 0.000 train accuracy: 1.000\n",
      "epoch: 15 validation accuracy: 0.198\n",
      "[16,   100/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[16,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.000 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.198\n",
      "[17,   100/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[17,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[17,   400/  446] train loss: 0.000 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.198\n",
      "[18,   100/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[18,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[18,   400/  446] train loss: 0.000 train accuracy: 1.000\n",
      "epoch: 18 validation accuracy: 0.198\n",
      "[19,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[19,   200/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[19,   400/  446] train loss: 0.000 train accuracy: 1.000\n",
      "epoch: 19 validation accuracy: 0.198\n",
      "[20,   100/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[20,   200/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[20,   400/  446] train loss: 0.000 train accuracy: 1.000\n",
      "epoch: 20 validation accuracy: 0.198\n"
     ]
    }
   ],
   "source": [
    "temperatures = [1]    # temperature for distillation loss\n",
    "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "# loss = alpha * st + (1 - alpha) * tt\n",
    "alphas = [0.0]\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "# No dropout used\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['alpha'] = hparam_tuple[0]\n",
    "    hparam['T'] = hparam_tuple[1]\n",
    "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[3]\n",
    "    hparam['lr_decay'] = hparam_tuple[4]\n",
    "    hparam['momentum'] = hparam_tuple[5]\n",
    "    hparam['lr'] = hparam_tuple[6]\n",
    "    hparams_list.append(hparam)\n",
    "\n",
    "results_no_distill = {}\n",
    "for hparam in hparams_list:\n",
    "    print('Training with hparams' + utils.hparamToString(hparam))\n",
    "    reproducibilitySeed()\n",
    "    student_net = networks.StudentNetworkLarge()\n",
    "    student_net = student_net.to(fast_device)\n",
    "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
    "    results_no_distill[hparam_tuple] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
    "                                                                    train_loader, val_loader, \n",
    "                                                                    print_every=print_every, \n",
    "                                                                    fast_device=fast_device)\n",
    "    save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    torch.save({'results' : results_no_distill[hparam_tuple], \n",
    "                'model_state_dict' : student_net.state_dict(), \n",
    "                'epoch' : num_epochs}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student test accuracy (w/o distillation):  0.1994\n"
     ]
    }
   ],
   "source": [
    "# Calculate student test accuracy\n",
    "_, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
    "print('student test accuracy (w/o distillation): ', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [10, 5]\n",
    "weight_decay_scatter = ([math.log10(h['weight_decay']) if h['weight_decay'] > 0 else -6 for h in hparams_list])\n",
    "dropout_scatter = [int(h['dropout_input'] == 0.2) for h in hparams_list]\n",
    "colors = []\n",
    "for i in range(len(hparams_list)):\n",
    "    cur_hparam_tuple = utils.hparamDictToTuple(hparams_list[i])\n",
    "    colors.append(results_no_distill[cur_hparam_tuple]['val_acc'][-1])\n",
    "    \n",
    "marker_size = 100\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(weight_decay_scatter, dropout_scatter, marker_size, c=colors, edgecolors='black')\n",
    "plt.colorbar()\n",
    "for i in range(len(weight_decay_scatter)):\n",
    "    ax.annotate(str('%0.4f' % (colors[i], )), (weight_decay_scatter[i], dropout_scatter[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train student network using distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hparamsT=1, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.103\n",
      "[1,   100/  446] train loss: 0.031 train accuracy: 0.992\n",
      "[1,   200/  446] train loss: 0.103 train accuracy: 0.992\n",
      "[1,   300/  446] train loss: 0.046 train accuracy: 0.992\n",
      "[1,   400/  446] train loss: 0.068 train accuracy: 0.992\n",
      "epoch: 1 validation accuracy: 0.197\n",
      "[2,   100/  446] train loss: 0.020 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.069 train accuracy: 0.984\n",
      "[2,   300/  446] train loss: 0.028 train accuracy: 1.000\n",
      "[2,   400/  446] train loss: 0.015 train accuracy: 1.000\n",
      "epoch: 2 validation accuracy: 0.197\n",
      "[3,   100/  446] train loss: 0.083 train accuracy: 0.984\n",
      "[3,   200/  446] train loss: 0.027 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.074 train accuracy: 1.000\n",
      "[3,   400/  446] train loss: 0.075 train accuracy: 0.992\n",
      "epoch: 3 validation accuracy: 0.198\n",
      "[4,   100/  446] train loss: 0.046 train accuracy: 1.000\n",
      "[4,   200/  446] train loss: 0.042 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.044 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.043 train accuracy: 0.984\n",
      "epoch: 4 validation accuracy: 0.202\n",
      "[5,   100/  446] train loss: 0.097 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.017 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.011 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.020 train accuracy: 1.000\n",
      "epoch: 5 validation accuracy: 0.214\n",
      "[6,   100/  446] train loss: 0.038 train accuracy: 1.000\n",
      "[6,   200/  446] train loss: 0.045 train accuracy: 0.992\n",
      "[6,   300/  446] train loss: 0.016 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.010 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.241\n",
      "[7,   100/  446] train loss: 0.015 train accuracy: 1.000\n",
      "[7,   200/  446] train loss: 0.028 train accuracy: 1.000\n",
      "[7,   300/  446] train loss: 0.029 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.016 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.247\n",
      "[8,   100/  446] train loss: 0.030 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.020 train accuracy: 1.000\n",
      "[8,   300/  446] train loss: 0.023 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.020 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.281\n",
      "[9,   100/  446] train loss: 0.018 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.020 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.024 train accuracy: 1.000\n",
      "[9,   400/  446] train loss: 0.016 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.285\n",
      "[10,   100/  446] train loss: 0.021 train accuracy: 1.000\n",
      "[10,   200/  446] train loss: 0.022 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.020 train accuracy: 0.992\n",
      "[10,   400/  446] train loss: 0.014 train accuracy: 0.992\n",
      "epoch: 10 validation accuracy: 0.295\n",
      "[11,   100/  446] train loss: 0.020 train accuracy: 0.992\n",
      "[11,   200/  446] train loss: 0.025 train accuracy: 1.000\n",
      "[11,   300/  446] train loss: 0.016 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.016 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.308\n",
      "[12,   100/  446] train loss: 0.034 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.015 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.018 train accuracy: 1.000\n",
      "[12,   400/  446] train loss: 0.009 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.319\n",
      "[13,   100/  446] train loss: 0.016 train accuracy: 0.969\n",
      "[13,   200/  446] train loss: 0.015 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.008 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.011 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.341\n",
      "[14,   100/  446] train loss: 0.012 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.021 train accuracy: 0.992\n",
      "[14,   300/  446] train loss: 0.017 train accuracy: 1.000\n",
      "[14,   400/  446] train loss: 0.010 train accuracy: 0.984\n",
      "epoch: 14 validation accuracy: 0.332\n",
      "[15,   100/  446] train loss: 0.012 train accuracy: 0.992\n",
      "[15,   200/  446] train loss: 0.017 train accuracy: 0.992\n",
      "[15,   300/  446] train loss: 0.005 train accuracy: 1.000\n",
      "[15,   400/  446] train loss: 0.010 train accuracy: 1.000\n",
      "epoch: 15 validation accuracy: 0.344\n",
      "[16,   100/  446] train loss: 0.018 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.010 train accuracy: 1.000\n",
      "[16,   300/  446] train loss: 0.016 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.009 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.356\n",
      "[17,   100/  446] train loss: 0.016 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.013 train accuracy: 0.992\n",
      "[17,   300/  446] train loss: 0.012 train accuracy: 0.977\n",
      "[17,   400/  446] train loss: 0.010 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.362\n",
      "[18,   100/  446] train loss: 0.012 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.008 train accuracy: 1.000\n",
      "[18,   300/  446] train loss: 0.006 train accuracy: 1.000\n",
      "[18,   400/  446] train loss: 0.009 train accuracy: 0.992\n",
      "epoch: 18 validation accuracy: 0.373\n",
      "[19,   100/  446] train loss: 0.009 train accuracy: 1.000\n",
      "[19,   200/  446] train loss: 0.007 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.015 train accuracy: 1.000\n",
      "[19,   400/  446] train loss: 0.009 train accuracy: 0.992\n",
      "epoch: 19 validation accuracy: 0.371\n",
      "[20,   100/  446] train loss: 0.010 train accuracy: 0.984\n",
      "[20,   200/  446] train loss: 0.011 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.006 train accuracy: 1.000\n",
      "[20,   400/  446] train loss: 0.009 train accuracy: 0.992\n",
      "epoch: 20 validation accuracy: 0.365\n",
      "Training with hparamsT=2, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.103\n",
      "[1,   100/  446] train loss: 0.263 train accuracy: 1.000\n",
      "[1,   200/  446] train loss: 0.393 train accuracy: 0.992\n",
      "[1,   300/  446] train loss: 0.219 train accuracy: 0.992\n",
      "[1,   400/  446] train loss: 0.246 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.197\n",
      "[2,   100/  446] train loss: 0.136 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.205 train accuracy: 0.992\n",
      "[2,   300/  446] train loss: 0.149 train accuracy: 1.000\n",
      "[2,   400/  446] train loss: 0.112 train accuracy: 1.000\n",
      "epoch: 2 validation accuracy: 0.235\n",
      "[3,   100/  446] train loss: 0.191 train accuracy: 0.984\n",
      "[3,   200/  446] train loss: 0.127 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.157 train accuracy: 1.000\n",
      "[3,   400/  446] train loss: 0.148 train accuracy: 0.992\n",
      "epoch: 3 validation accuracy: 0.295\n",
      "[4,   100/  446] train loss: 0.113 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.144 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.122 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.108 train accuracy: 0.984\n",
      "epoch: 4 validation accuracy: 0.341\n",
      "[5,   100/  446] train loss: 0.117 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.069 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.063 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.089 train accuracy: 1.000\n",
      "epoch: 5 validation accuracy: 0.440\n",
      "[6,   100/  446] train loss: 0.093 train accuracy: 1.000\n",
      "[6,   200/  446] train loss: 0.079 train accuracy: 0.992\n",
      "[6,   300/  446] train loss: 0.048 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.051 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.501\n",
      "[7,   100/  446] train loss: 0.063 train accuracy: 1.000\n",
      "[7,   200/  446] train loss: 0.095 train accuracy: 1.000\n",
      "[7,   300/  446] train loss: 0.079 train accuracy: 0.992\n",
      "[7,   400/  446] train loss: 0.058 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.527\n",
      "[8,   100/  446] train loss: 0.061 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.056 train accuracy: 1.000\n",
      "[8,   300/  446] train loss: 0.058 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.057 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.558\n",
      "[9,   100/  446] train loss: 0.052 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.053 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.054 train accuracy: 0.992\n",
      "[9,   400/  446] train loss: 0.037 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.581\n",
      "[10,   100/  446] train loss: 0.038 train accuracy: 0.992\n",
      "[10,   200/  446] train loss: 0.040 train accuracy: 0.992\n",
      "[10,   300/  446] train loss: 0.038 train accuracy: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   400/  446] train loss: 0.037 train accuracy: 0.992\n",
      "epoch: 10 validation accuracy: 0.612\n",
      "[11,   100/  446] train loss: 0.040 train accuracy: 0.992\n",
      "[11,   200/  446] train loss: 0.054 train accuracy: 1.000\n",
      "[11,   300/  446] train loss: 0.033 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.033 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.612\n",
      "[12,   100/  446] train loss: 0.037 train accuracy: 0.984\n",
      "[12,   200/  446] train loss: 0.032 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.029 train accuracy: 0.992\n",
      "[12,   400/  446] train loss: 0.024 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.651\n",
      "[13,   100/  446] train loss: 0.035 train accuracy: 0.969\n",
      "[13,   200/  446] train loss: 0.028 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.025 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.031 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.648\n",
      "[14,   100/  446] train loss: 0.032 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.032 train accuracy: 0.984\n",
      "[14,   300/  446] train loss: 0.033 train accuracy: 1.000\n",
      "[14,   400/  446] train loss: 0.025 train accuracy: 0.984\n",
      "epoch: 14 validation accuracy: 0.655\n",
      "[15,   100/  446] train loss: 0.030 train accuracy: 0.992\n",
      "[15,   200/  446] train loss: 0.036 train accuracy: 0.992\n",
      "[15,   300/  446] train loss: 0.021 train accuracy: 1.000\n",
      "[15,   400/  446] train loss: 0.021 train accuracy: 1.000\n",
      "epoch: 15 validation accuracy: 0.689\n",
      "[16,   100/  446] train loss: 0.025 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.027 train accuracy: 1.000\n",
      "[16,   300/  446] train loss: 0.023 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.024 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.682\n",
      "[17,   100/  446] train loss: 0.026 train accuracy: 0.992\n",
      "[17,   200/  446] train loss: 0.032 train accuracy: 0.992\n",
      "[17,   300/  446] train loss: 0.026 train accuracy: 0.977\n",
      "[17,   400/  446] train loss: 0.027 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.696\n",
      "[18,   100/  446] train loss: 0.022 train accuracy: 0.992\n",
      "[18,   200/  446] train loss: 0.021 train accuracy: 1.000\n",
      "[18,   300/  446] train loss: 0.020 train accuracy: 1.000\n",
      "[18,   400/  446] train loss: 0.024 train accuracy: 0.992\n",
      "epoch: 18 validation accuracy: 0.703\n",
      "[19,   100/  446] train loss: 0.020 train accuracy: 1.000\n",
      "[19,   200/  446] train loss: 0.023 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.022 train accuracy: 0.977\n",
      "[19,   400/  446] train loss: 0.019 train accuracy: 0.984\n",
      "epoch: 19 validation accuracy: 0.727\n",
      "[20,   100/  446] train loss: 0.023 train accuracy: 0.977\n",
      "[20,   200/  446] train loss: 0.017 train accuracy: 0.992\n",
      "[20,   300/  446] train loss: 0.019 train accuracy: 1.000\n",
      "[20,   400/  446] train loss: 0.017 train accuracy: 0.992\n",
      "epoch: 20 validation accuracy: 0.722\n",
      "Training with hparamsT=5, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.103\n",
      "[1,   100/  446] train loss: 1.365 train accuracy: 1.000\n",
      "[1,   200/  446] train loss: 0.988 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 0.787 train accuracy: 1.000\n",
      "[1,   400/  446] train loss: 0.573 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.258\n",
      "[2,   100/  446] train loss: 0.497 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.394 train accuracy: 1.000\n",
      "[2,   300/  446] train loss: 0.371 train accuracy: 1.000\n",
      "[2,   400/  446] train loss: 0.344 train accuracy: 1.000\n",
      "epoch: 2 validation accuracy: 0.459\n",
      "[3,   100/  446] train loss: 0.312 train accuracy: 1.000\n",
      "[3,   200/  446] train loss: 0.271 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.333 train accuracy: 0.992\n",
      "[3,   400/  446] train loss: 0.211 train accuracy: 0.992\n",
      "epoch: 3 validation accuracy: 0.644\n",
      "[4,   100/  446] train loss: 0.191 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.182 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.161 train accuracy: 0.992\n",
      "[4,   400/  446] train loss: 0.176 train accuracy: 0.984\n",
      "epoch: 4 validation accuracy: 0.799\n",
      "[5,   100/  446] train loss: 0.133 train accuracy: 0.984\n",
      "[5,   200/  446] train loss: 0.127 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.135 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.111 train accuracy: 1.000\n",
      "epoch: 5 validation accuracy: 0.843\n",
      "[6,   100/  446] train loss: 0.106 train accuracy: 0.992\n",
      "[6,   200/  446] train loss: 0.097 train accuracy: 0.977\n",
      "[6,   300/  446] train loss: 0.086 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.095 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.862\n",
      "[7,   100/  446] train loss: 0.083 train accuracy: 1.000\n",
      "[7,   200/  446] train loss: 0.082 train accuracy: 1.000\n",
      "[7,   300/  446] train loss: 0.067 train accuracy: 0.992\n",
      "[7,   400/  446] train loss: 0.065 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.893\n",
      "[8,   100/  446] train loss: 0.068 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.064 train accuracy: 0.992\n",
      "[8,   300/  446] train loss: 0.060 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.061 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.910\n",
      "[9,   100/  446] train loss: 0.055 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.054 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.057 train accuracy: 1.000\n",
      "[9,   400/  446] train loss: 0.046 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.919\n",
      "[10,   100/  446] train loss: 0.044 train accuracy: 0.992\n",
      "[10,   200/  446] train loss: 0.043 train accuracy: 0.992\n",
      "[10,   300/  446] train loss: 0.043 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.042 train accuracy: 0.992\n",
      "epoch: 10 validation accuracy: 0.921\n",
      "[11,   100/  446] train loss: 0.037 train accuracy: 0.992\n",
      "[11,   200/  446] train loss: 0.038 train accuracy: 0.992\n",
      "[11,   300/  446] train loss: 0.041 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.036 train accuracy: 0.992\n",
      "epoch: 11 validation accuracy: 0.936\n",
      "[12,   100/  446] train loss: 0.039 train accuracy: 0.992\n",
      "[12,   200/  446] train loss: 0.036 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.036 train accuracy: 0.992\n",
      "[12,   400/  446] train loss: 0.034 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.941\n",
      "[13,   100/  446] train loss: 0.033 train accuracy: 0.969\n",
      "[13,   200/  446] train loss: 0.032 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.033 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.031 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.938\n",
      "[14,   100/  446] train loss: 0.028 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.029 train accuracy: 0.984\n",
      "[14,   300/  446] train loss: 0.032 train accuracy: 1.000\n",
      "[14,   400/  446] train loss: 0.028 train accuracy: 0.984\n",
      "epoch: 14 validation accuracy: 0.942\n",
      "[15,   100/  446] train loss: 0.026 train accuracy: 0.992\n",
      "[15,   200/  446] train loss: 0.029 train accuracy: 0.992\n",
      "[15,   300/  446] train loss: 0.025 train accuracy: 1.000\n",
      "[15,   400/  446] train loss: 0.026 train accuracy: 1.000\n",
      "epoch: 15 validation accuracy: 0.943\n",
      "[16,   100/  446] train loss: 0.028 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.030 train accuracy: 1.000\n",
      "[16,   300/  446] train loss: 0.025 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.026 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.946\n",
      "[17,   100/  446] train loss: 0.024 train accuracy: 0.992\n",
      "[17,   200/  446] train loss: 0.024 train accuracy: 0.992\n",
      "[17,   300/  446] train loss: 0.023 train accuracy: 0.977\n",
      "[17,   400/  446] train loss: 0.025 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.947\n",
      "[18,   100/  446] train loss: 0.025 train accuracy: 0.992\n",
      "[18,   200/  446] train loss: 0.024 train accuracy: 1.000\n",
      "[18,   300/  446] train loss: 0.020 train accuracy: 1.000\n",
      "[18,   400/  446] train loss: 0.024 train accuracy: 0.992\n",
      "epoch: 18 validation accuracy: 0.946\n",
      "[19,   100/  446] train loss: 0.022 train accuracy: 1.000\n",
      "[19,   200/  446] train loss: 0.024 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.019 train accuracy: 0.984\n",
      "[19,   400/  446] train loss: 0.019 train accuracy: 0.984\n",
      "epoch: 19 validation accuracy: 0.949\n",
      "[20,   100/  446] train loss: 0.020 train accuracy: 0.977\n",
      "[20,   200/  446] train loss: 0.021 train accuracy: 0.992\n",
      "[20,   300/  446] train loss: 0.019 train accuracy: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,   400/  446] train loss: 0.018 train accuracy: 0.992\n",
      "epoch: 20 validation accuracy: 0.947\n",
      "Training with hparamsT=10, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.103\n",
      "[1,   100/  446] train loss: 1.644 train accuracy: 1.000\n",
      "[1,   200/  446] train loss: 1.199 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 0.900 train accuracy: 1.000\n",
      "[1,   400/  446] train loss: 0.623 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.343\n",
      "[2,   100/  446] train loss: 0.519 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.412 train accuracy: 0.984\n",
      "[2,   300/  446] train loss: 0.373 train accuracy: 1.000\n",
      "[2,   400/  446] train loss: 0.313 train accuracy: 1.000\n",
      "epoch: 2 validation accuracy: 0.588\n",
      "[3,   100/  446] train loss: 0.313 train accuracy: 1.000\n",
      "[3,   200/  446] train loss: 0.239 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.240 train accuracy: 0.992\n",
      "[3,   400/  446] train loss: 0.215 train accuracy: 0.992\n",
      "epoch: 3 validation accuracy: 0.773\n",
      "[4,   100/  446] train loss: 0.180 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.161 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.160 train accuracy: 0.984\n",
      "[4,   400/  446] train loss: 0.154 train accuracy: 0.984\n",
      "epoch: 4 validation accuracy: 0.859\n",
      "[5,   100/  446] train loss: 0.122 train accuracy: 0.984\n",
      "[5,   200/  446] train loss: 0.144 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.126 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.103 train accuracy: 1.000\n",
      "epoch: 5 validation accuracy: 0.877\n",
      "[6,   100/  446] train loss: 0.098 train accuracy: 1.000\n",
      "[6,   200/  446] train loss: 0.087 train accuracy: 0.977\n",
      "[6,   300/  446] train loss: 0.088 train accuracy: 0.992\n",
      "[6,   400/  446] train loss: 0.077 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.918\n",
      "[7,   100/  446] train loss: 0.079 train accuracy: 1.000\n",
      "[7,   200/  446] train loss: 0.072 train accuracy: 1.000\n",
      "[7,   300/  446] train loss: 0.077 train accuracy: 0.992\n",
      "[7,   400/  446] train loss: 0.065 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.929\n",
      "[8,   100/  446] train loss: 0.072 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.068 train accuracy: 0.992\n",
      "[8,   300/  446] train loss: 0.064 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.070 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.933\n",
      "[9,   100/  446] train loss: 0.054 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.054 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.054 train accuracy: 1.000\n",
      "[9,   400/  446] train loss: 0.049 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.940\n",
      "[10,   100/  446] train loss: 0.056 train accuracy: 0.992\n",
      "[10,   200/  446] train loss: 0.047 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.042 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.047 train accuracy: 0.992\n",
      "epoch: 10 validation accuracy: 0.942\n",
      "[11,   100/  446] train loss: 0.039 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.042 train accuracy: 1.000\n",
      "[11,   300/  446] train loss: 0.040 train accuracy: 0.992\n",
      "[11,   400/  446] train loss: 0.037 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.948\n",
      "[12,   100/  446] train loss: 0.045 train accuracy: 0.992\n",
      "[12,   200/  446] train loss: 0.036 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.042 train accuracy: 0.992\n",
      "[12,   400/  446] train loss: 0.041 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.950\n",
      "[13,   100/  446] train loss: 0.038 train accuracy: 0.969\n",
      "[13,   200/  446] train loss: 0.030 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.032 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.036 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.953\n",
      "[14,   100/  446] train loss: 0.036 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.028 train accuracy: 0.984\n",
      "[14,   300/  446] train loss: 0.031 train accuracy: 1.000\n",
      "[14,   400/  446] train loss: 0.028 train accuracy: 0.984\n",
      "epoch: 14 validation accuracy: 0.950\n",
      "[15,   100/  446] train loss: 0.029 train accuracy: 0.992\n",
      "[15,   200/  446] train loss: 0.031 train accuracy: 0.992\n",
      "[15,   300/  446] train loss: 0.028 train accuracy: 1.000\n",
      "[15,   400/  446] train loss: 0.023 train accuracy: 1.000\n",
      "epoch: 15 validation accuracy: 0.957\n",
      "[16,   100/  446] train loss: 0.026 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.030 train accuracy: 1.000\n",
      "[16,   300/  446] train loss: 0.029 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.028 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.956\n",
      "[17,   100/  446] train loss: 0.026 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.026 train accuracy: 0.992\n",
      "[17,   300/  446] train loss: 0.026 train accuracy: 0.977\n",
      "[17,   400/  446] train loss: 0.027 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.955\n",
      "[18,   100/  446] train loss: 0.023 train accuracy: 0.992\n",
      "[18,   200/  446] train loss: 0.024 train accuracy: 1.000\n",
      "[18,   300/  446] train loss: 0.020 train accuracy: 1.000\n",
      "[18,   400/  446] train loss: 0.023 train accuracy: 0.992\n",
      "epoch: 18 validation accuracy: 0.956\n",
      "[19,   100/  446] train loss: 0.021 train accuracy: 1.000\n",
      "[19,   200/  446] train loss: 0.024 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.021 train accuracy: 0.984\n",
      "[19,   400/  446] train loss: 0.020 train accuracy: 0.992\n",
      "epoch: 19 validation accuracy: 0.960\n",
      "[20,   100/  446] train loss: 0.021 train accuracy: 0.977\n",
      "[20,   200/  446] train loss: 0.021 train accuracy: 0.992\n",
      "[20,   300/  446] train loss: 0.020 train accuracy: 1.000\n",
      "[20,   400/  446] train loss: 0.020 train accuracy: 0.992\n",
      "epoch: 20 validation accuracy: 0.957\n",
      "Training with hparamsT=15, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.103\n",
      "[1,   100/  446] train loss: 1.722 train accuracy: 1.000\n",
      "[1,   200/  446] train loss: 1.173 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 0.976 train accuracy: 1.000\n",
      "[1,   400/  446] train loss: 0.686 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.351\n",
      "[2,   100/  446] train loss: 0.495 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.471 train accuracy: 0.984\n",
      "[2,   300/  446] train loss: 0.364 train accuracy: 1.000\n",
      "[2,   400/  446] train loss: 0.303 train accuracy: 1.000\n",
      "epoch: 2 validation accuracy: 0.639\n",
      "[3,   100/  446] train loss: 0.291 train accuracy: 0.984\n",
      "[3,   200/  446] train loss: 0.236 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.246 train accuracy: 0.992\n",
      "[3,   400/  446] train loss: 0.208 train accuracy: 0.984\n",
      "epoch: 3 validation accuracy: 0.782\n",
      "[4,   100/  446] train loss: 0.194 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.163 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.168 train accuracy: 0.984\n",
      "[4,   400/  446] train loss: 0.153 train accuracy: 0.984\n",
      "epoch: 4 validation accuracy: 0.873\n",
      "[5,   100/  446] train loss: 0.120 train accuracy: 0.984\n",
      "[5,   200/  446] train loss: 0.137 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.127 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.103 train accuracy: 1.000\n",
      "epoch: 5 validation accuracy: 0.880\n",
      "[6,   100/  446] train loss: 0.098 train accuracy: 0.992\n",
      "[6,   200/  446] train loss: 0.088 train accuracy: 0.977\n",
      "[6,   300/  446] train loss: 0.076 train accuracy: 0.992\n",
      "[6,   400/  446] train loss: 0.076 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.926\n",
      "[7,   100/  446] train loss: 0.080 train accuracy: 1.000\n",
      "[7,   200/  446] train loss: 0.066 train accuracy: 1.000\n",
      "[7,   300/  446] train loss: 0.085 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.063 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.934\n",
      "[8,   100/  446] train loss: 0.064 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.071 train accuracy: 0.992\n",
      "[8,   300/  446] train loss: 0.060 train accuracy: 0.992\n",
      "[8,   400/  446] train loss: 0.064 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.938\n",
      "[9,   100/  446] train loss: 0.047 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.055 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.058 train accuracy: 1.000\n",
      "[9,   400/  446] train loss: 0.042 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.947\n",
      "[10,   100/  446] train loss: 0.044 train accuracy: 0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   200/  446] train loss: 0.042 train accuracy: 0.992\n",
      "[10,   300/  446] train loss: 0.039 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.046 train accuracy: 0.992\n",
      "epoch: 10 validation accuracy: 0.945\n",
      "[11,   100/  446] train loss: 0.036 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.040 train accuracy: 1.000\n",
      "[11,   300/  446] train loss: 0.039 train accuracy: 0.992\n",
      "[11,   400/  446] train loss: 0.037 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.949\n",
      "[12,   100/  446] train loss: 0.043 train accuracy: 0.984\n",
      "[12,   200/  446] train loss: 0.036 train accuracy: 0.992\n",
      "[12,   300/  446] train loss: 0.042 train accuracy: 0.992\n",
      "[12,   400/  446] train loss: 0.033 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.955\n",
      "[13,   100/  446] train loss: 0.035 train accuracy: 0.977\n",
      "[13,   200/  446] train loss: 0.033 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.033 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.032 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.952\n",
      "[14,   100/  446] train loss: 0.031 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.031 train accuracy: 0.984\n",
      "[14,   300/  446] train loss: 0.031 train accuracy: 1.000\n",
      "[14,   400/  446] train loss: 0.028 train accuracy: 0.984\n",
      "epoch: 14 validation accuracy: 0.957\n",
      "[15,   100/  446] train loss: 0.030 train accuracy: 0.992\n",
      "[15,   200/  446] train loss: 0.031 train accuracy: 0.992\n",
      "[15,   300/  446] train loss: 0.028 train accuracy: 1.000\n",
      "[15,   400/  446] train loss: 0.025 train accuracy: 1.000\n",
      "epoch: 15 validation accuracy: 0.963\n",
      "[16,   100/  446] train loss: 0.026 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.028 train accuracy: 1.000\n",
      "[16,   300/  446] train loss: 0.028 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.030 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.961\n",
      "[17,   100/  446] train loss: 0.025 train accuracy: 0.992\n",
      "[17,   200/  446] train loss: 0.027 train accuracy: 0.992\n",
      "[17,   300/  446] train loss: 0.023 train accuracy: 0.977\n",
      "[17,   400/  446] train loss: 0.025 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.961\n",
      "[18,   100/  446] train loss: 0.024 train accuracy: 0.992\n",
      "[18,   200/  446] train loss: 0.023 train accuracy: 1.000\n",
      "[18,   300/  446] train loss: 0.019 train accuracy: 1.000\n",
      "[18,   400/  446] train loss: 0.024 train accuracy: 0.992\n",
      "epoch: 18 validation accuracy: 0.960\n",
      "[19,   100/  446] train loss: 0.021 train accuracy: 1.000\n",
      "[19,   200/  446] train loss: 0.024 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.020 train accuracy: 0.984\n",
      "[19,   400/  446] train loss: 0.022 train accuracy: 0.992\n",
      "epoch: 19 validation accuracy: 0.961\n",
      "[20,   100/  446] train loss: 0.021 train accuracy: 0.977\n",
      "[20,   200/  446] train loss: 0.021 train accuracy: 0.992\n",
      "[20,   300/  446] train loss: 0.019 train accuracy: 1.000\n",
      "[20,   400/  446] train loss: 0.020 train accuracy: 0.992\n",
      "epoch: 20 validation accuracy: 0.961\n",
      "Training with hparamsT=20, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.103\n",
      "[1,   100/  446] train loss: 1.756 train accuracy: 1.000\n",
      "[1,   200/  446] train loss: 1.162 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 0.972 train accuracy: 1.000\n",
      "[1,   400/  446] train loss: 0.676 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.361\n",
      "[2,   100/  446] train loss: 0.475 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.449 train accuracy: 0.984\n",
      "[2,   300/  446] train loss: 0.314 train accuracy: 1.000\n",
      "[2,   400/  446] train loss: 0.300 train accuracy: 1.000\n",
      "epoch: 2 validation accuracy: 0.654\n",
      "[3,   100/  446] train loss: 0.249 train accuracy: 1.000\n",
      "[3,   200/  446] train loss: 0.223 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.239 train accuracy: 0.992\n",
      "[3,   400/  446] train loss: 0.184 train accuracy: 0.984\n",
      "epoch: 3 validation accuracy: 0.803\n",
      "[4,   100/  446] train loss: 0.190 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.161 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.145 train accuracy: 0.992\n",
      "[4,   400/  446] train loss: 0.145 train accuracy: 0.977\n",
      "epoch: 4 validation accuracy: 0.880\n",
      "[5,   100/  446] train loss: 0.116 train accuracy: 0.984\n",
      "[5,   200/  446] train loss: 0.130 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.106 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.107 train accuracy: 1.000\n",
      "epoch: 5 validation accuracy: 0.894\n",
      "[6,   100/  446] train loss: 0.089 train accuracy: 0.992\n",
      "[6,   200/  446] train loss: 0.083 train accuracy: 0.977\n",
      "[6,   300/  446] train loss: 0.075 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.088 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.927\n",
      "[7,   100/  446] train loss: 0.074 train accuracy: 1.000\n",
      "[7,   200/  446] train loss: 0.072 train accuracy: 1.000\n",
      "[7,   300/  446] train loss: 0.090 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.059 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.935\n",
      "[8,   100/  446] train loss: 0.065 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.061 train accuracy: 0.992\n",
      "[8,   300/  446] train loss: 0.060 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.059 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.938\n",
      "[9,   100/  446] train loss: 0.050 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.052 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.050 train accuracy: 1.000\n",
      "[9,   400/  446] train loss: 0.042 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.951\n",
      "[10,   100/  446] train loss: 0.048 train accuracy: 0.992\n",
      "[10,   200/  446] train loss: 0.044 train accuracy: 0.992\n",
      "[10,   300/  446] train loss: 0.041 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.043 train accuracy: 0.992\n",
      "epoch: 10 validation accuracy: 0.948\n",
      "[11,   100/  446] train loss: 0.033 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.042 train accuracy: 1.000\n",
      "[11,   300/  446] train loss: 0.039 train accuracy: 0.992\n",
      "[11,   400/  446] train loss: 0.033 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.953\n",
      "[12,   100/  446] train loss: 0.042 train accuracy: 0.984\n",
      "[12,   200/  446] train loss: 0.034 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.038 train accuracy: 0.992\n",
      "[12,   400/  446] train loss: 0.031 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.956\n",
      "[13,   100/  446] train loss: 0.032 train accuracy: 0.977\n",
      "[13,   200/  446] train loss: 0.033 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.032 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.034 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.952\n",
      "[14,   100/  446] train loss: 0.029 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.031 train accuracy: 0.984\n",
      "[14,   300/  446] train loss: 0.030 train accuracy: 1.000\n",
      "[14,   400/  446] train loss: 0.027 train accuracy: 0.984\n",
      "epoch: 14 validation accuracy: 0.959\n",
      "[15,   100/  446] train loss: 0.029 train accuracy: 0.992\n",
      "[15,   200/  446] train loss: 0.029 train accuracy: 0.992\n",
      "[15,   300/  446] train loss: 0.027 train accuracy: 1.000\n",
      "[15,   400/  446] train loss: 0.024 train accuracy: 1.000\n",
      "epoch: 15 validation accuracy: 0.962\n",
      "[16,   100/  446] train loss: 0.028 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.026 train accuracy: 1.000\n",
      "[16,   300/  446] train loss: 0.026 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.028 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.963\n",
      "[17,   100/  446] train loss: 0.024 train accuracy: 0.992\n",
      "[17,   200/  446] train loss: 0.025 train accuracy: 0.992\n",
      "[17,   300/  446] train loss: 0.025 train accuracy: 0.977\n",
      "[17,   400/  446] train loss: 0.029 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.963\n",
      "[18,   100/  446] train loss: 0.023 train accuracy: 0.992\n",
      "[18,   200/  446] train loss: 0.022 train accuracy: 1.000\n",
      "[18,   300/  446] train loss: 0.019 train accuracy: 1.000\n",
      "[18,   400/  446] train loss: 0.022 train accuracy: 0.992\n",
      "epoch: 18 validation accuracy: 0.961\n",
      "[19,   100/  446] train loss: 0.021 train accuracy: 1.000\n",
      "[19,   200/  446] train loss: 0.024 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.019 train accuracy: 0.977\n",
      "[19,   400/  446] train loss: 0.023 train accuracy: 0.984\n",
      "epoch: 19 validation accuracy: 0.962\n",
      "[20,   100/  446] train loss: 0.020 train accuracy: 0.977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,   200/  446] train loss: 0.021 train accuracy: 0.992\n",
      "[20,   300/  446] train loss: 0.018 train accuracy: 1.000\n",
      "[20,   400/  446] train loss: 0.022 train accuracy: 0.992\n",
      "epoch: 20 validation accuracy: 0.960\n"
     ]
    }
   ],
   "source": [
    "temperatures = [1, 2, 5, 10, 15, 20]\n",
    "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "# loss = alpha * st + (1 - alpha) * tt\n",
    "alphas = [1.0]\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['alpha'] = hparam_tuple[0]\n",
    "    hparam['T'] = hparam_tuple[1]\n",
    "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[3]\n",
    "    hparam['lr_decay'] = hparam_tuple[4]\n",
    "    hparam['momentum'] = hparam_tuple[5]\n",
    "    hparam['lr'] = hparam_tuple[6]\n",
    "    hparams_list.append(hparam)\n",
    "\n",
    "results_distill = {}\n",
    "for hparam in hparams_list:\n",
    "    print('Training with hparams' + utils.hparamToString(hparam))\n",
    "    reproducibilitySeed()\n",
    "    student_net = networks.StudentNetworkLarge()\n",
    "    student_net = student_net.to(fast_device)\n",
    "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
    "    results_distill[hparam_tuple] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
    "                                                                train_loader, val_loader, \n",
    "                                                                print_every=print_every, \n",
    "                                                                fast_device=fast_device)\n",
    "    save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    torch.save({'results' : results_distill[hparam_tuple], \n",
    "                'model_state_dict' : student_net.state_dict(), \n",
    "                'epoch' : num_epochs}, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [10, 5]\n",
    "T_scatter = [math.log(h['T']) for h in hparams_list]\n",
    "alpha_scatter = [h['alpha'] for h in hparams_list]\n",
    "colors = []\n",
    "for i in range(len(hparams_list)):\n",
    "    cur_hparam_tuple = utils.hparamDictToTuple(hparams_list[i])\n",
    "    colors.append(results_distill[cur_hparam_tuple]['val_acc'][-1])\n",
    "    \n",
    "marker_size = 100\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(T_scatter, alpha_scatter, marker_size, c=colors, edgecolors='black')\n",
    "plt.colorbar()\n",
    "for i in range(len(T_scatter)):\n",
    "    ax.annotate(str('%0.4f' % (colors[i], )), (T_scatter[i], alpha_scatter[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "color = ['r', 'b', 'g', 'm', 'y', 'k']\n",
    "for hparam, c in zip(hparams_list, color):\n",
    "    cur_results = results_distill[utils.hparamDictToTuple(hparam)]\n",
    "    plt.plot(cur_results['val_acc'], color=c, label=str(hparam['T']))\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.title('Validation Accuracy vs Epoch for different T')\n",
    "plt.savefig(summaries_path_student + 'val_acc_vs_epoch_wrt_T.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T=1, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "test accuracy:  0.3772\n",
      "\n",
      "T=2, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "test accuracy:  0.7238\n",
      "\n",
      "T=5, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "test accuracy:  0.9516\n",
      "\n",
      "T=10, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "test accuracy:  0.961\n",
      "\n",
      "T=15, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "test accuracy:  0.9605\n",
      "\n",
      "T=20, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "test accuracy:  0.9613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hparam in hparams_list:\n",
    "    load_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    load_dict = torch.load(load_path)\n",
    "    student_net = networks.StudentNetworkLarge()\n",
    "    student_net.load_state_dict(load_dict['model_state_dict'])\n",
    "    student_net = student_net.to(fast_device)\n",
    "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
    "    print(utils.hparamToString(hparam))\n",
    "    print('test accuracy: ', test_accuracy)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [5]\n",
    "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "# loss = alpha * st + (1 - alpha) * tt\n",
    "alphas = [0.8, 0.5, 0.4, 0.2]\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['alpha'] = hparam_tuple[0]\n",
    "    hparam['T'] = hparam_tuple[1]\n",
    "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[3]\n",
    "    hparam['lr_decay'] = hparam_tuple[4]\n",
    "    hparam['momentum'] = hparam_tuple[5]\n",
    "    hparam['lr'] = hparam_tuple[6]\n",
    "    hparams_list.append(hparam)\n",
    "\n",
    "results_distill = {}\n",
    "for hparam in hparams_list:\n",
    "    print('Training with hparams' + utils.hparamToString(hparam))\n",
    "    reproducibilitySeed()\n",
    "    student_net = networks.StudentNetworkLarge()\n",
    "    student_net = student_net.to(fast_device)\n",
    "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
    "    results_distill[hparam_tuple] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
    "                                                                train_loader, val_loader, \n",
    "                                                                print_every=print_every, \n",
    "                                                                fast_device=fast_device)\n",
    "    save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    torch.save({'results' : results_distill[hparam_tuple], \n",
    "                'model_state_dict' : student_net.state_dict(), \n",
    "                'epoch' : num_epochs}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [10, 5]\n",
    "T_scatter = [math.log(h['T']) for h in hparams_list]\n",
    "alpha_scatter = [h['alpha'] for h in hparams_list]\n",
    "colors = []\n",
    "for i in range(len(hparams_list)):\n",
    "    cur_hparam_tuple = utils.hparamDictToTuple(hparams_list[i])\n",
    "    colors.append(results_distill[cur_hparam_tuple]['val_acc'][-1])\n",
    "    \n",
    "marker_size = 100\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(T_scatter, alpha_scatter, marker_size, c=colors, edgecolors='black')\n",
    "plt.colorbar()\n",
    "for i in range(len(T_scatter)):\n",
    "    ax.annotate(str('%0.4f' % (colors[i], )), (T_scatter[i], alpha_scatter[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['r', 'b', 'g', 'm']\n",
    "for hparam, c in zip(hparams_list, color):\n",
    "    cur_results = results_distill[utils.hparamDictToTuple(hparam)]\n",
    "    plt.plot(cur_results['val_acc'], color=c, label=str(hparam['alpha']))\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.title('Validation Accuracy vs Epoch for different alpha')\n",
    "plt.savefig(summaries_path_student + 'val_acc_vs_epoch_wrt_alpha.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hparam in hparams_list:\n",
    "    load_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    load_dict = torch.load(load_path)\n",
    "    student_net = networks.StudentNetworkLarge()\n",
    "    student_net.load_state_dict(load_dict['model_state_dict'])\n",
    "    student_net = student_net.to(fast_device)\n",
    "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
    "    print(utils.hparamToString(hparam))\n",
    "    print('test accuracy: ', test_accuracy)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
