{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages and limit GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "import networks_cifar as networks\n",
    "import utils\n",
    "import biased_sampler\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True    # set use_gpu to True if system has gpu\n",
    "gpu_id = 1        # id of gpu to be used\n",
    "cpu_device = torch.device('cpu')\n",
    "# fast_device is where computation (training, inference) happens\n",
    "fast_device = torch.device('cpu')\n",
    "if use_gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'    # set visible devices depending on system configuration\n",
    "    fast_device = torch.device('cuda:' + str(gpu_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure reproducibility\n",
    "def reproducibilitySeed():\n",
    "    \"\"\"\n",
    "    Ensure reproducibility of results; Seeds to 0\n",
    "    \"\"\"\n",
    "    torch_init_seed = 0\n",
    "    torch.manual_seed(torch_init_seed)\n",
    "    numpy_init_seed = 0\n",
    "    np.random.seed(numpy_init_seed)\n",
    "    if use_gpu:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "reproducibilitySeed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "cifar_image_shape = (32, 32, 3)\n",
    "# Student trained without data augmentation\n",
    "transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                ]\n",
    "            )\n",
    "\n",
    "train_val_dataset = torchvision.datasets.CIFAR10(root='./CIFAR_dataset/', train=True, \n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./CIFAR_dataset/', train=False, \n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "num_train = int(1.0 * len(train_val_dataset) * 95 / 100)\n",
    "num_val = len(train_val_dataset) - num_train\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_class = 10\n",
    "class_prob = [0.0 for _ in range(num_class)]\n",
    "class_prob[7] = 0.5\n",
    "class_prob[8] = 0.5\n",
    "\n",
    "train_val_biased_sampler = biased_sampler.CIFARClassBiasedSampler(train_val_dataset, class_prob)\n",
    "train_biased_sampler = biased_sampler.CIFARClassBiasedSampler(train_dataset, class_prob)\n",
    "\n",
    "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=128, \n",
    "                                                sampler=train_val_biased_sampler, \n",
    "                                                num_workers=2)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, \n",
    "                                            sampler=train_biased_sampler, \n",
    "                                            num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path_teacher = 'CIFAR_checkpoints_teacher/'\n",
    "checkpoints_path_student = 'CIFAR_checkpoints_student_biased/'\n",
    "summaries_path_student = 'CIFAR_summaries_student_biased/'\n",
    "if not os.path.exists(checkpoints_path_student):\n",
    "    os.makedirs(checkpoints_path_student)\n",
    "if not os.path.exists(summaries_path_student):\n",
    "    os.makedirs(summaries_path_student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load teacher network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hparams used for training teacher to load the teacher network\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "# keeping dropout input = dropout hidden\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "for hparam_tuple in itertools.product(dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['dropout_input'] = hparam_tuple[0][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[0][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[1]\n",
    "    hparam['lr_decay'] = hparam_tuple[2]\n",
    "    hparam['momentum'] = hparam_tuple[3]\n",
    "    hparam['lr'] = hparam_tuple[4]\n",
    "    hparams_list.append(hparam)\n",
    "    \n",
    "load_path = checkpoints_path_teacher + utils.hparamToString(hparams_list[0]) + '.tar'\n",
    "teacher_net = networks.TeacherNetwork(cifar_image_shape, num_class)\n",
    "teacher_net.load_state_dict(torch.load(load_path, map_location=fast_device)['model_state_dict'])\n",
    "teacher_net = teacher_net.to(fast_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher test accuracy:  0.6128\n"
     ]
    }
   ],
   "source": [
    "# Calculate teacher test accuracy\n",
    "_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n",
    "print('teacher test accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train student network without distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hparamsT=1, alpha=0.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.078\n",
      "[1,   100/  372] train loss: 0.191 train accuracy: 0.961\n",
      "[1,   200/  372] train loss: 0.193 train accuracy: 0.922\n",
      "[1,   300/  372] train loss: 0.107 train accuracy: 0.977\n",
      "epoch: 1 validation accuracy: 0.174\n",
      "[2,   100/  372] train loss: 0.083 train accuracy: 0.984\n",
      "[2,   200/  372] train loss: 0.122 train accuracy: 0.969\n",
      "[2,   300/  372] train loss: 0.045 train accuracy: 0.992\n",
      "epoch: 2 validation accuracy: 0.176\n",
      "[3,   100/  372] train loss: 0.061 train accuracy: 0.984\n",
      "[3,   200/  372] train loss: 0.034 train accuracy: 0.992\n",
      "[3,   300/  372] train loss: 0.011 train accuracy: 1.000\n",
      "epoch: 3 validation accuracy: 0.181\n",
      "[4,   100/  372] train loss: 0.022 train accuracy: 0.992\n",
      "[4,   200/  372] train loss: 0.066 train accuracy: 0.969\n",
      "[4,   300/  372] train loss: 0.026 train accuracy: 0.984\n",
      "epoch: 4 validation accuracy: 0.177\n",
      "[5,   100/  372] train loss: 0.009 train accuracy: 1.000\n",
      "[5,   200/  372] train loss: 0.017 train accuracy: 0.992\n",
      "[5,   300/  372] train loss: 0.004 train accuracy: 1.000\n",
      "epoch: 5 validation accuracy: 0.179\n",
      "[6,   100/  372] train loss: 0.001 train accuracy: 1.000\n",
      "[6,   200/  372] train loss: 0.001 train accuracy: 1.000\n",
      "[6,   300/  372] train loss: 0.001 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.179\n",
      "[7,   100/  372] train loss: 0.001 train accuracy: 1.000\n",
      "[7,   200/  372] train loss: 0.001 train accuracy: 1.000\n",
      "[7,   300/  372] train loss: 0.001 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.180\n",
      "[8,   100/  372] train loss: 0.001 train accuracy: 1.000\n",
      "[8,   200/  372] train loss: 0.001 train accuracy: 1.000\n",
      "[8,   300/  372] train loss: 0.001 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.180\n",
      "[9,   100/  372] train loss: 0.001 train accuracy: 1.000\n",
      "[9,   200/  372] train loss: 0.001 train accuracy: 1.000\n",
      "[9,   300/  372] train loss: 0.001 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.180\n",
      "[10,   100/  372] train loss: 0.000 train accuracy: 1.000\n",
      "[10,   200/  372] train loss: 0.000 train accuracy: 1.000\n",
      "[10,   300/  372] train loss: 0.000 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.180\n"
     ]
    }
   ],
   "source": [
    "temperatures = [1]    # temperature for distillation loss\n",
    "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "# loss = alpha * st + (1 - alpha) * tt\n",
    "alphas = [0.0]\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "# No dropout used\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['alpha'] = hparam_tuple[0]\n",
    "    hparam['T'] = hparam_tuple[1]\n",
    "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[3]\n",
    "    hparam['lr_decay'] = hparam_tuple[4]\n",
    "    hparam['momentum'] = hparam_tuple[5]\n",
    "    hparam['lr'] = hparam_tuple[6]\n",
    "    hparams_list.append(hparam)\n",
    "\n",
    "results_no_distill = {}\n",
    "for hparam in hparams_list:\n",
    "    print('Training with hparams' + utils.hparamToString(hparam))\n",
    "    reproducibilitySeed()\n",
    "    student_net = networks.StudentNetworkLarge(cifar_image_shape, num_class)\n",
    "    student_net = student_net.to(fast_device)\n",
    "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
    "    results_no_distill[hparam_tuple] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
    "                                                                    train_loader, val_loader, \n",
    "                                                                    print_every=print_every, \n",
    "                                                                    fast_device=fast_device)\n",
    "    save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    torch.save({'results' : results_no_distill[hparam_tuple], \n",
    "                'model_state_dict' : student_net.state_dict(), \n",
    "                'epoch' : num_epochs}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student test accuracy (w/o distillation):  0.1859\n"
     ]
    }
   ],
   "source": [
    "# Calculate student test accuracy\n",
    "_, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
    "print('student test accuracy (w/o distillation): ', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [10, 5]\n",
    "weight_decay_scatter = ([math.log10(h['weight_decay']) if h['weight_decay'] > 0 else -6 for h in hparams_list])\n",
    "dropout_scatter = [int(h['dropout_input'] == 0.2) for h in hparams_list]\n",
    "colors = []\n",
    "for i in range(len(hparams_list)):\n",
    "    cur_hparam_tuple = utils.hparamDictToTuple(hparams_list[i])\n",
    "    colors.append(results_no_distill[cur_hparam_tuple]['val_acc'][-1])\n",
    "    \n",
    "marker_size = 100\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(weight_decay_scatter, dropout_scatter, marker_size, c=colors, edgecolors='black')\n",
    "plt.colorbar()\n",
    "for i in range(len(weight_decay_scatter)):\n",
    "    ax.annotate(str('%0.4f' % (colors[i], )), (weight_decay_scatter[i], dropout_scatter[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train student network using distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hparamsT=1, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.078\n",
      "[1,   100/  372] train loss: 0.364 train accuracy: 0.938\n",
      "[1,   200/  372] train loss: 0.365 train accuracy: 0.914\n",
      "[1,   300/  372] train loss: 0.261 train accuracy: 0.984\n",
      "epoch: 1 validation accuracy: 0.183\n",
      "[2,   100/  372] train loss: 0.220 train accuracy: 0.961\n",
      "[2,   200/  372] train loss: 0.230 train accuracy: 0.969\n",
      "[2,   300/  372] train loss: 0.161 train accuracy: 0.969\n",
      "epoch: 2 validation accuracy: 0.232\n",
      "[3,   100/  372] train loss: 0.181 train accuracy: 0.945\n",
      "[3,   200/  372] train loss: 0.163 train accuracy: 0.961\n",
      "[3,   300/  372] train loss: 0.146 train accuracy: 0.938\n",
      "epoch: 3 validation accuracy: 0.266\n",
      "[4,   100/  372] train loss: 0.132 train accuracy: 0.938\n",
      "[4,   200/  372] train loss: 0.108 train accuracy: 0.953\n",
      "[4,   300/  372] train loss: 0.131 train accuracy: 0.945\n",
      "epoch: 4 validation accuracy: 0.292\n",
      "[5,   100/  372] train loss: 0.115 train accuracy: 0.922\n",
      "[5,   200/  372] train loss: 0.113 train accuracy: 0.922\n",
      "[5,   300/  372] train loss: 0.097 train accuracy: 0.961\n",
      "epoch: 5 validation accuracy: 0.318\n",
      "[6,   100/  372] train loss: 0.081 train accuracy: 0.930\n",
      "[6,   200/  372] train loss: 0.084 train accuracy: 0.891\n",
      "[6,   300/  372] train loss: 0.073 train accuracy: 0.969\n",
      "epoch: 6 validation accuracy: 0.327\n",
      "[7,   100/  372] train loss: 0.069 train accuracy: 0.953\n",
      "[7,   200/  372] train loss: 0.083 train accuracy: 0.914\n",
      "[7,   300/  372] train loss: 0.067 train accuracy: 0.898\n",
      "epoch: 7 validation accuracy: 0.338\n",
      "[8,   100/  372] train loss: 0.072 train accuracy: 0.930\n",
      "[8,   200/  372] train loss: 0.056 train accuracy: 0.906\n",
      "[8,   300/  372] train loss: 0.064 train accuracy: 0.922\n",
      "epoch: 8 validation accuracy: 0.347\n",
      "[9,   100/  372] train loss: 0.049 train accuracy: 0.891\n",
      "[9,   200/  372] train loss: 0.050 train accuracy: 0.930\n",
      "[9,   300/  372] train loss: 0.046 train accuracy: 0.906\n",
      "epoch: 9 validation accuracy: 0.347\n",
      "[10,   100/  372] train loss: 0.043 train accuracy: 0.883\n",
      "[10,   200/  372] train loss: 0.046 train accuracy: 0.914\n",
      "[10,   300/  372] train loss: 0.051 train accuracy: 0.898\n",
      "epoch: 10 validation accuracy: 0.360\n",
      "[11,   100/  372] train loss: 0.036 train accuracy: 0.945\n",
      "[11,   200/  372] train loss: 0.047 train accuracy: 0.898\n",
      "[11,   300/  372] train loss: 0.047 train accuracy: 0.875\n",
      "epoch: 11 validation accuracy: 0.362\n",
      "[12,   100/  372] train loss: 0.032 train accuracy: 0.953\n",
      "[12,   200/  372] train loss: 0.046 train accuracy: 0.883\n",
      "[12,   300/  372] train loss: 0.036 train accuracy: 0.906\n",
      "epoch: 12 validation accuracy: 0.357\n",
      "[13,   100/  372] train loss: 0.033 train accuracy: 0.953\n",
      "[13,   200/  372] train loss: 0.037 train accuracy: 0.898\n",
      "[13,   300/  372] train loss: 0.028 train accuracy: 0.891\n",
      "epoch: 13 validation accuracy: 0.371\n",
      "[14,   100/  372] train loss: 0.035 train accuracy: 0.852\n",
      "[14,   200/  372] train loss: 0.034 train accuracy: 0.906\n",
      "[14,   300/  372] train loss: 0.035 train accuracy: 0.898\n",
      "epoch: 14 validation accuracy: 0.373\n",
      "[15,   100/  372] train loss: 0.027 train accuracy: 0.922\n",
      "[15,   200/  372] train loss: 0.031 train accuracy: 0.859\n",
      "[15,   300/  372] train loss: 0.026 train accuracy: 0.953\n",
      "epoch: 15 validation accuracy: 0.375\n",
      "[16,   100/  372] train loss: 0.028 train accuracy: 0.867\n",
      "[16,   200/  372] train loss: 0.028 train accuracy: 0.883\n",
      "[16,   300/  372] train loss: 0.027 train accuracy: 0.867\n",
      "epoch: 16 validation accuracy: 0.379\n",
      "[17,   100/  372] train loss: 0.026 train accuracy: 0.891\n",
      "[17,   200/  372] train loss: 0.024 train accuracy: 0.883\n",
      "[17,   300/  372] train loss: 0.027 train accuracy: 0.922\n",
      "epoch: 17 validation accuracy: 0.380\n",
      "[18,   100/  372] train loss: 0.020 train accuracy: 0.898\n",
      "[18,   200/  372] train loss: 0.020 train accuracy: 0.867\n",
      "[18,   300/  372] train loss: 0.023 train accuracy: 0.922\n",
      "epoch: 18 validation accuracy: 0.379\n",
      "[19,   100/  372] train loss: 0.023 train accuracy: 0.922\n",
      "[19,   200/  372] train loss: 0.024 train accuracy: 0.883\n",
      "[19,   300/  372] train loss: 0.020 train accuracy: 0.938\n",
      "epoch: 19 validation accuracy: 0.378\n",
      "[20,   100/  372] train loss: 0.022 train accuracy: 0.906\n",
      "[20,   200/  372] train loss: 0.024 train accuracy: 0.867\n",
      "[20,   300/  372] train loss: 0.017 train accuracy: 0.945\n",
      "epoch: 20 validation accuracy: 0.380\n",
      "Training with hparamsT=2, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.078\n",
      "[1,   100/  372] train loss: 0.939 train accuracy: 0.953\n",
      "[1,   200/  372] train loss: 0.769 train accuracy: 0.914\n",
      "[1,   300/  372] train loss: 0.610 train accuracy: 0.961\n",
      "epoch: 1 validation accuracy: 0.206\n",
      "[2,   100/  372] train loss: 0.516 train accuracy: 0.945\n",
      "[2,   200/  372] train loss: 0.453 train accuracy: 0.961\n",
      "[2,   300/  372] train loss: 0.346 train accuracy: 0.953\n",
      "epoch: 2 validation accuracy: 0.272\n",
      "[3,   100/  372] train loss: 0.331 train accuracy: 0.945\n",
      "[3,   200/  372] train loss: 0.300 train accuracy: 0.938\n",
      "[3,   300/  372] train loss: 0.259 train accuracy: 0.938\n",
      "epoch: 3 validation accuracy: 0.340\n",
      "[4,   100/  372] train loss: 0.223 train accuracy: 0.945\n",
      "[4,   200/  372] train loss: 0.197 train accuracy: 0.938\n",
      "[4,   300/  372] train loss: 0.218 train accuracy: 0.914\n",
      "epoch: 4 validation accuracy: 0.372\n",
      "[5,   100/  372] train loss: 0.170 train accuracy: 0.898\n",
      "[5,   200/  372] train loss: 0.150 train accuracy: 0.945\n",
      "[5,   300/  372] train loss: 0.152 train accuracy: 0.938\n",
      "epoch: 5 validation accuracy: 0.395\n",
      "[6,   100/  372] train loss: 0.122 train accuracy: 0.914\n",
      "[6,   200/  372] train loss: 0.125 train accuracy: 0.852\n",
      "[6,   300/  372] train loss: 0.111 train accuracy: 0.953\n",
      "epoch: 6 validation accuracy: 0.399\n",
      "[7,   100/  372] train loss: 0.104 train accuracy: 0.930\n",
      "[7,   200/  372] train loss: 0.107 train accuracy: 0.859\n",
      "[7,   300/  372] train loss: 0.091 train accuracy: 0.914\n",
      "epoch: 7 validation accuracy: 0.401\n",
      "[8,   100/  372] train loss: 0.082 train accuracy: 0.930\n",
      "[8,   200/  372] train loss: 0.074 train accuracy: 0.906\n",
      "[8,   300/  372] train loss: 0.075 train accuracy: 0.922\n",
      "epoch: 8 validation accuracy: 0.415\n",
      "[9,   100/  372] train loss: 0.065 train accuracy: 0.867\n",
      "[9,   200/  372] train loss: 0.059 train accuracy: 0.938\n",
      "[9,   300/  372] train loss: 0.057 train accuracy: 0.898\n",
      "epoch: 9 validation accuracy: 0.421\n",
      "[10,   100/  372] train loss: 0.056 train accuracy: 0.883\n",
      "[10,   200/  372] train loss: 0.053 train accuracy: 0.898\n",
      "[10,   300/  372] train loss: 0.053 train accuracy: 0.898\n",
      "epoch: 10 validation accuracy: 0.422\n",
      "[11,   100/  372] train loss: 0.045 train accuracy: 0.922\n",
      "[11,   200/  372] train loss: 0.050 train accuracy: 0.891\n",
      "[11,   300/  372] train loss: 0.050 train accuracy: 0.867\n",
      "epoch: 11 validation accuracy: 0.419\n",
      "[12,   100/  372] train loss: 0.041 train accuracy: 0.922\n",
      "[12,   200/  372] train loss: 0.040 train accuracy: 0.859\n",
      "[12,   300/  372] train loss: 0.039 train accuracy: 0.906\n",
      "epoch: 12 validation accuracy: 0.430\n",
      "[13,   100/  372] train loss: 0.037 train accuracy: 0.945\n",
      "[13,   200/  372] train loss: 0.039 train accuracy: 0.898\n",
      "[13,   300/  372] train loss: 0.035 train accuracy: 0.883\n",
      "epoch: 13 validation accuracy: 0.430\n",
      "[14,   100/  372] train loss: 0.034 train accuracy: 0.836\n",
      "[14,   200/  372] train loss: 0.033 train accuracy: 0.891\n",
      "[14,   300/  372] train loss: 0.033 train accuracy: 0.898\n",
      "epoch: 14 validation accuracy: 0.428\n",
      "[15,   100/  372] train loss: 0.031 train accuracy: 0.914\n",
      "[15,   200/  372] train loss: 0.031 train accuracy: 0.859\n",
      "[15,   300/  372] train loss: 0.029 train accuracy: 0.945\n",
      "epoch: 15 validation accuracy: 0.432\n",
      "[16,   100/  372] train loss: 0.027 train accuracy: 0.875\n",
      "[16,   200/  372] train loss: 0.027 train accuracy: 0.883\n",
      "[16,   300/  372] train loss: 0.026 train accuracy: 0.867\n",
      "epoch: 16 validation accuracy: 0.434\n",
      "[17,   100/  372] train loss: 0.028 train accuracy: 0.883\n",
      "[17,   200/  372] train loss: 0.027 train accuracy: 0.883\n",
      "[17,   300/  372] train loss: 0.023 train accuracy: 0.930\n",
      "epoch: 17 validation accuracy: 0.430\n",
      "[18,   100/  372] train loss: 0.022 train accuracy: 0.898\n",
      "[18,   200/  372] train loss: 0.020 train accuracy: 0.875\n",
      "[18,   300/  372] train loss: 0.023 train accuracy: 0.922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 validation accuracy: 0.432\n",
      "[19,   100/  372] train loss: 0.026 train accuracy: 0.922\n",
      "[19,   200/  372] train loss: 0.021 train accuracy: 0.875\n",
      "[19,   300/  372] train loss: 0.023 train accuracy: 0.914\n",
      "epoch: 19 validation accuracy: 0.434\n",
      "[20,   100/  372] train loss: 0.022 train accuracy: 0.906\n",
      "[20,   200/  372] train loss: 0.022 train accuracy: 0.859\n",
      "[20,   300/  372] train loss: 0.021 train accuracy: 0.945\n",
      "epoch: 20 validation accuracy: 0.435\n",
      "Training with hparamsT=5, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.078\n",
      "[1,   100/  372] train loss: 1.861 train accuracy: 0.945\n",
      "[1,   200/  372] train loss: 1.237 train accuracy: 0.914\n",
      "[1,   300/  372] train loss: 1.018 train accuracy: 0.977\n",
      "epoch: 1 validation accuracy: 0.258\n",
      "[2,   100/  372] train loss: 0.728 train accuracy: 0.906\n",
      "[2,   200/  372] train loss: 0.644 train accuracy: 0.938\n",
      "[2,   300/  372] train loss: 0.498 train accuracy: 0.938\n",
      "epoch: 2 validation accuracy: 0.330\n",
      "[3,   100/  372] train loss: 0.456 train accuracy: 0.898\n",
      "[3,   200/  372] train loss: 0.362 train accuracy: 0.953\n",
      "[3,   300/  372] train loss: 0.335 train accuracy: 0.922\n",
      "epoch: 3 validation accuracy: 0.389\n",
      "[4,   100/  372] train loss: 0.234 train accuracy: 0.938\n",
      "[4,   200/  372] train loss: 0.224 train accuracy: 0.930\n",
      "[4,   300/  372] train loss: 0.217 train accuracy: 0.930\n",
      "epoch: 4 validation accuracy: 0.410\n",
      "[5,   100/  372] train loss: 0.179 train accuracy: 0.898\n",
      "[5,   200/  372] train loss: 0.141 train accuracy: 0.945\n",
      "[5,   300/  372] train loss: 0.153 train accuracy: 0.938\n",
      "epoch: 5 validation accuracy: 0.440\n",
      "[6,   100/  372] train loss: 0.119 train accuracy: 0.922\n",
      "[6,   200/  372] train loss: 0.118 train accuracy: 0.891\n",
      "[6,   300/  372] train loss: 0.095 train accuracy: 0.953\n",
      "epoch: 6 validation accuracy: 0.437\n",
      "[7,   100/  372] train loss: 0.096 train accuracy: 0.930\n",
      "[7,   200/  372] train loss: 0.085 train accuracy: 0.867\n",
      "[7,   300/  372] train loss: 0.083 train accuracy: 0.930\n",
      "epoch: 7 validation accuracy: 0.440\n",
      "[8,   100/  372] train loss: 0.071 train accuracy: 0.922\n",
      "[8,   200/  372] train loss: 0.071 train accuracy: 0.930\n",
      "[8,   300/  372] train loss: 0.062 train accuracy: 0.906\n",
      "epoch: 8 validation accuracy: 0.445\n",
      "[9,   100/  372] train loss: 0.056 train accuracy: 0.883\n",
      "[9,   200/  372] train loss: 0.053 train accuracy: 0.945\n",
      "[9,   300/  372] train loss: 0.050 train accuracy: 0.883\n",
      "epoch: 9 validation accuracy: 0.453\n",
      "[10,   100/  372] train loss: 0.044 train accuracy: 0.891\n",
      "[10,   200/  372] train loss: 0.048 train accuracy: 0.914\n",
      "[10,   300/  372] train loss: 0.044 train accuracy: 0.906\n",
      "epoch: 10 validation accuracy: 0.461\n",
      "[11,   100/  372] train loss: 0.037 train accuracy: 0.945\n",
      "[11,   200/  372] train loss: 0.038 train accuracy: 0.891\n",
      "[11,   300/  372] train loss: 0.038 train accuracy: 0.875\n",
      "epoch: 11 validation accuracy: 0.462\n",
      "[12,   100/  372] train loss: 0.034 train accuracy: 0.914\n",
      "[12,   200/  372] train loss: 0.032 train accuracy: 0.875\n",
      "[12,   300/  372] train loss: 0.030 train accuracy: 0.906\n",
      "epoch: 12 validation accuracy: 0.466\n",
      "[13,   100/  372] train loss: 0.029 train accuracy: 0.938\n",
      "[13,   200/  372] train loss: 0.031 train accuracy: 0.898\n",
      "[13,   300/  372] train loss: 0.029 train accuracy: 0.898\n",
      "epoch: 13 validation accuracy: 0.457\n",
      "[14,   100/  372] train loss: 0.024 train accuracy: 0.836\n",
      "[14,   200/  372] train loss: 0.023 train accuracy: 0.898\n",
      "[14,   300/  372] train loss: 0.024 train accuracy: 0.898\n",
      "epoch: 14 validation accuracy: 0.461\n",
      "[15,   100/  372] train loss: 0.022 train accuracy: 0.930\n",
      "[15,   200/  372] train loss: 0.023 train accuracy: 0.852\n",
      "[15,   300/  372] train loss: 0.023 train accuracy: 0.953\n",
      "epoch: 15 validation accuracy: 0.470\n",
      "[16,   100/  372] train loss: 0.020 train accuracy: 0.891\n",
      "[16,   200/  372] train loss: 0.020 train accuracy: 0.883\n",
      "[16,   300/  372] train loss: 0.018 train accuracy: 0.875\n",
      "epoch: 16 validation accuracy: 0.466\n",
      "[17,   100/  372] train loss: 0.020 train accuracy: 0.883\n",
      "[17,   200/  372] train loss: 0.019 train accuracy: 0.883\n",
      "[17,   300/  372] train loss: 0.015 train accuracy: 0.922\n",
      "epoch: 17 validation accuracy: 0.463\n",
      "[18,   100/  372] train loss: 0.016 train accuracy: 0.883\n",
      "[18,   200/  372] train loss: 0.013 train accuracy: 0.867\n",
      "[18,   300/  372] train loss: 0.017 train accuracy: 0.922\n",
      "epoch: 18 validation accuracy: 0.467\n",
      "[19,   100/  372] train loss: 0.017 train accuracy: 0.922\n",
      "[19,   200/  372] train loss: 0.014 train accuracy: 0.875\n",
      "[19,   300/  372] train loss: 0.015 train accuracy: 0.922\n",
      "epoch: 19 validation accuracy: 0.467\n",
      "[20,   100/  372] train loss: 0.016 train accuracy: 0.906\n",
      "[20,   200/  372] train loss: 0.015 train accuracy: 0.852\n",
      "[20,   300/  372] train loss: 0.012 train accuracy: 0.938\n",
      "epoch: 20 validation accuracy: 0.472\n",
      "Training with hparamsT=10, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.078\n",
      "[1,   100/  372] train loss: 2.188 train accuracy: 0.945\n",
      "[1,   200/  372] train loss: 1.294 train accuracy: 0.898\n",
      "[1,   300/  372] train loss: 1.106 train accuracy: 0.969\n",
      "epoch: 1 validation accuracy: 0.281\n",
      "[2,   100/  372] train loss: 0.724 train accuracy: 0.914\n",
      "[2,   200/  372] train loss: 0.683 train accuracy: 0.938\n",
      "[2,   300/  372] train loss: 0.519 train accuracy: 0.914\n",
      "epoch: 2 validation accuracy: 0.328\n",
      "[3,   100/  372] train loss: 0.468 train accuracy: 0.891\n",
      "[3,   200/  372] train loss: 0.366 train accuracy: 0.945\n",
      "[3,   300/  372] train loss: 0.337 train accuracy: 0.922\n",
      "epoch: 3 validation accuracy: 0.386\n",
      "[4,   100/  372] train loss: 0.238 train accuracy: 0.930\n",
      "[4,   200/  372] train loss: 0.232 train accuracy: 0.914\n",
      "[4,   300/  372] train loss: 0.212 train accuracy: 0.930\n",
      "epoch: 4 validation accuracy: 0.410\n",
      "[5,   100/  372] train loss: 0.181 train accuracy: 0.883\n",
      "[5,   200/  372] train loss: 0.144 train accuracy: 0.953\n",
      "[5,   300/  372] train loss: 0.146 train accuracy: 0.914\n",
      "epoch: 5 validation accuracy: 0.434\n",
      "[6,   100/  372] train loss: 0.123 train accuracy: 0.914\n",
      "[6,   200/  372] train loss: 0.111 train accuracy: 0.875\n",
      "[6,   300/  372] train loss: 0.091 train accuracy: 0.945\n",
      "epoch: 6 validation accuracy: 0.434\n",
      "[7,   100/  372] train loss: 0.090 train accuracy: 0.922\n",
      "[7,   200/  372] train loss: 0.084 train accuracy: 0.859\n",
      "[7,   300/  372] train loss: 0.077 train accuracy: 0.922\n",
      "epoch: 7 validation accuracy: 0.450\n",
      "[8,   100/  372] train loss: 0.068 train accuracy: 0.930\n",
      "[8,   200/  372] train loss: 0.072 train accuracy: 0.922\n",
      "[8,   300/  372] train loss: 0.062 train accuracy: 0.898\n",
      "epoch: 8 validation accuracy: 0.450\n",
      "[9,   100/  372] train loss: 0.053 train accuracy: 0.883\n",
      "[9,   200/  372] train loss: 0.046 train accuracy: 0.938\n",
      "[9,   300/  372] train loss: 0.048 train accuracy: 0.867\n",
      "epoch: 9 validation accuracy: 0.453\n",
      "[10,   100/  372] train loss: 0.043 train accuracy: 0.875\n",
      "[10,   200/  372] train loss: 0.047 train accuracy: 0.914\n",
      "[10,   300/  372] train loss: 0.041 train accuracy: 0.906\n",
      "epoch: 10 validation accuracy: 0.461\n",
      "[11,   100/  372] train loss: 0.039 train accuracy: 0.930\n",
      "[11,   200/  372] train loss: 0.035 train accuracy: 0.883\n",
      "[11,   300/  372] train loss: 0.037 train accuracy: 0.867\n",
      "epoch: 11 validation accuracy: 0.462\n",
      "[12,   100/  372] train loss: 0.030 train accuracy: 0.930\n",
      "[12,   200/  372] train loss: 0.029 train accuracy: 0.875\n",
      "[12,   300/  372] train loss: 0.027 train accuracy: 0.930\n",
      "epoch: 12 validation accuracy: 0.465\n",
      "[13,   100/  372] train loss: 0.026 train accuracy: 0.938\n",
      "[13,   200/  372] train loss: 0.029 train accuracy: 0.891\n",
      "[13,   300/  372] train loss: 0.025 train accuracy: 0.898\n",
      "epoch: 13 validation accuracy: 0.462\n",
      "[14,   100/  372] train loss: 0.022 train accuracy: 0.828\n",
      "[14,   200/  372] train loss: 0.021 train accuracy: 0.898\n",
      "[14,   300/  372] train loss: 0.021 train accuracy: 0.898\n",
      "epoch: 14 validation accuracy: 0.466\n",
      "[15,   100/  372] train loss: 0.018 train accuracy: 0.922\n",
      "[15,   200/  372] train loss: 0.019 train accuracy: 0.852\n",
      "[15,   300/  372] train loss: 0.019 train accuracy: 0.938\n",
      "epoch: 15 validation accuracy: 0.464\n",
      "[16,   100/  372] train loss: 0.018 train accuracy: 0.875\n",
      "[16,   200/  372] train loss: 0.018 train accuracy: 0.883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,   300/  372] train loss: 0.016 train accuracy: 0.883\n",
      "epoch: 16 validation accuracy: 0.465\n",
      "[17,   100/  372] train loss: 0.017 train accuracy: 0.883\n",
      "[17,   200/  372] train loss: 0.017 train accuracy: 0.875\n",
      "[17,   300/  372] train loss: 0.013 train accuracy: 0.930\n",
      "epoch: 17 validation accuracy: 0.465\n",
      "[18,   100/  372] train loss: 0.014 train accuracy: 0.891\n",
      "[18,   200/  372] train loss: 0.011 train accuracy: 0.883\n",
      "[18,   300/  372] train loss: 0.014 train accuracy: 0.930\n",
      "epoch: 18 validation accuracy: 0.466\n",
      "[19,   100/  372] train loss: 0.014 train accuracy: 0.922\n",
      "[19,   200/  372] train loss: 0.011 train accuracy: 0.883\n",
      "[19,   300/  372] train loss: 0.010 train accuracy: 0.930\n",
      "epoch: 19 validation accuracy: 0.466\n",
      "[20,   100/  372] train loss: 0.012 train accuracy: 0.906\n",
      "[20,   200/  372] train loss: 0.012 train accuracy: 0.859\n",
      "[20,   300/  372] train loss: 0.011 train accuracy: 0.945\n",
      "epoch: 20 validation accuracy: 0.466\n",
      "Training with hparamsT=15, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.078\n",
      "[1,   100/  372] train loss: 2.288 train accuracy: 0.922\n",
      "[1,   200/  372] train loss: 1.301 train accuracy: 0.898\n",
      "[1,   300/  372] train loss: 1.135 train accuracy: 0.969\n",
      "epoch: 1 validation accuracy: 0.280\n",
      "[2,   100/  372] train loss: 0.737 train accuracy: 0.906\n",
      "[2,   200/  372] train loss: 0.664 train accuracy: 0.945\n",
      "[2,   300/  372] train loss: 0.525 train accuracy: 0.906\n",
      "epoch: 2 validation accuracy: 0.323\n",
      "[3,   100/  372] train loss: 0.464 train accuracy: 0.891\n",
      "[3,   200/  372] train loss: 0.369 train accuracy: 0.938\n",
      "[3,   300/  372] train loss: 0.324 train accuracy: 0.914\n",
      "epoch: 3 validation accuracy: 0.387\n",
      "[4,   100/  372] train loss: 0.236 train accuracy: 0.930\n",
      "[4,   200/  372] train loss: 0.249 train accuracy: 0.922\n",
      "[4,   300/  372] train loss: 0.206 train accuracy: 0.914\n",
      "epoch: 4 validation accuracy: 0.422\n",
      "[5,   100/  372] train loss: 0.176 train accuracy: 0.875\n",
      "[5,   200/  372] train loss: 0.140 train accuracy: 0.945\n",
      "[5,   300/  372] train loss: 0.148 train accuracy: 0.938\n",
      "epoch: 5 validation accuracy: 0.438\n",
      "[6,   100/  372] train loss: 0.120 train accuracy: 0.922\n",
      "[6,   200/  372] train loss: 0.107 train accuracy: 0.883\n",
      "[6,   300/  372] train loss: 0.087 train accuracy: 0.969\n",
      "epoch: 6 validation accuracy: 0.443\n",
      "[7,   100/  372] train loss: 0.089 train accuracy: 0.953\n",
      "[7,   200/  372] train loss: 0.081 train accuracy: 0.852\n",
      "[7,   300/  372] train loss: 0.073 train accuracy: 0.922\n",
      "epoch: 7 validation accuracy: 0.452\n",
      "[8,   100/  372] train loss: 0.070 train accuracy: 0.930\n",
      "[8,   200/  372] train loss: 0.067 train accuracy: 0.922\n",
      "[8,   300/  372] train loss: 0.063 train accuracy: 0.898\n",
      "epoch: 8 validation accuracy: 0.454\n",
      "[9,   100/  372] train loss: 0.052 train accuracy: 0.883\n",
      "[9,   200/  372] train loss: 0.047 train accuracy: 0.938\n",
      "[9,   300/  372] train loss: 0.050 train accuracy: 0.875\n",
      "epoch: 9 validation accuracy: 0.457\n",
      "[10,   100/  372] train loss: 0.041 train accuracy: 0.875\n",
      "[10,   200/  372] train loss: 0.043 train accuracy: 0.922\n",
      "[10,   300/  372] train loss: 0.041 train accuracy: 0.906\n",
      "epoch: 10 validation accuracy: 0.460\n",
      "[11,   100/  372] train loss: 0.037 train accuracy: 0.938\n",
      "[11,   200/  372] train loss: 0.034 train accuracy: 0.883\n",
      "[11,   300/  372] train loss: 0.035 train accuracy: 0.875\n",
      "epoch: 11 validation accuracy: 0.461\n",
      "[12,   100/  372] train loss: 0.030 train accuracy: 0.906\n",
      "[12,   200/  372] train loss: 0.028 train accuracy: 0.867\n",
      "[12,   300/  372] train loss: 0.028 train accuracy: 0.914\n",
      "epoch: 12 validation accuracy: 0.464\n",
      "[13,   100/  372] train loss: 0.026 train accuracy: 0.953\n",
      "[13,   200/  372] train loss: 0.029 train accuracy: 0.906\n",
      "[13,   300/  372] train loss: 0.023 train accuracy: 0.898\n",
      "epoch: 13 validation accuracy: 0.463\n",
      "[14,   100/  372] train loss: 0.021 train accuracy: 0.836\n",
      "[14,   200/  372] train loss: 0.021 train accuracy: 0.898\n",
      "[14,   300/  372] train loss: 0.020 train accuracy: 0.906\n",
      "epoch: 14 validation accuracy: 0.463\n",
      "[15,   100/  372] train loss: 0.019 train accuracy: 0.922\n",
      "[15,   200/  372] train loss: 0.019 train accuracy: 0.852\n",
      "[15,   300/  372] train loss: 0.020 train accuracy: 0.953\n",
      "epoch: 15 validation accuracy: 0.464\n",
      "[16,   100/  372] train loss: 0.016 train accuracy: 0.859\n",
      "[16,   200/  372] train loss: 0.017 train accuracy: 0.883\n",
      "[16,   300/  372] train loss: 0.015 train accuracy: 0.875\n",
      "epoch: 16 validation accuracy: 0.466\n",
      "[17,   100/  372] train loss: 0.016 train accuracy: 0.883\n",
      "[17,   200/  372] train loss: 0.016 train accuracy: 0.875\n",
      "[17,   300/  372] train loss: 0.013 train accuracy: 0.898\n",
      "epoch: 17 validation accuracy: 0.464\n",
      "[18,   100/  372] train loss: 0.014 train accuracy: 0.891\n",
      "[18,   200/  372] train loss: 0.012 train accuracy: 0.875\n",
      "[18,   300/  372] train loss: 0.013 train accuracy: 0.922\n",
      "epoch: 18 validation accuracy: 0.465\n",
      "[19,   100/  372] train loss: 0.013 train accuracy: 0.922\n",
      "[19,   200/  372] train loss: 0.010 train accuracy: 0.875\n",
      "[19,   300/  372] train loss: 0.011 train accuracy: 0.930\n",
      "epoch: 19 validation accuracy: 0.464\n",
      "[20,   100/  372] train loss: 0.012 train accuracy: 0.906\n",
      "[20,   200/  372] train loss: 0.013 train accuracy: 0.867\n",
      "[20,   300/  372] train loss: 0.010 train accuracy: 0.945\n",
      "epoch: 20 validation accuracy: 0.466\n",
      "Training with hparamsT=20, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.078\n",
      "[1,   100/  372] train loss: 2.340 train accuracy: 0.930\n",
      "[1,   200/  372] train loss: 1.305 train accuracy: 0.898\n",
      "[1,   300/  372] train loss: 1.144 train accuracy: 0.953\n",
      "epoch: 1 validation accuracy: 0.282\n",
      "[2,   100/  372] train loss: 0.730 train accuracy: 0.898\n",
      "[2,   200/  372] train loss: 0.668 train accuracy: 0.945\n",
      "[2,   300/  372] train loss: 0.521 train accuracy: 0.906\n",
      "epoch: 2 validation accuracy: 0.332\n",
      "[3,   100/  372] train loss: 0.461 train accuracy: 0.875\n",
      "[3,   200/  372] train loss: 0.362 train accuracy: 0.938\n",
      "[3,   300/  372] train loss: 0.321 train accuracy: 0.898\n",
      "epoch: 3 validation accuracy: 0.390\n",
      "[4,   100/  372] train loss: 0.231 train accuracy: 0.922\n",
      "[4,   200/  372] train loss: 0.243 train accuracy: 0.930\n",
      "[4,   300/  372] train loss: 0.208 train accuracy: 0.922\n",
      "epoch: 4 validation accuracy: 0.424\n",
      "[5,   100/  372] train loss: 0.172 train accuracy: 0.883\n",
      "[5,   200/  372] train loss: 0.139 train accuracy: 0.914\n",
      "[5,   300/  372] train loss: 0.151 train accuracy: 0.930\n",
      "epoch: 5 validation accuracy: 0.437\n",
      "[6,   100/  372] train loss: 0.121 train accuracy: 0.922\n",
      "[6,   200/  372] train loss: 0.107 train accuracy: 0.875\n",
      "[6,   300/  372] train loss: 0.091 train accuracy: 0.961\n",
      "epoch: 6 validation accuracy: 0.446\n",
      "[7,   100/  372] train loss: 0.086 train accuracy: 0.922\n",
      "[7,   200/  372] train loss: 0.081 train accuracy: 0.852\n",
      "[7,   300/  372] train loss: 0.070 train accuracy: 0.930\n",
      "epoch: 7 validation accuracy: 0.450\n",
      "[8,   100/  372] train loss: 0.068 train accuracy: 0.930\n",
      "[8,   200/  372] train loss: 0.070 train accuracy: 0.930\n",
      "[8,   300/  372] train loss: 0.061 train accuracy: 0.906\n",
      "epoch: 8 validation accuracy: 0.451\n",
      "[9,   100/  372] train loss: 0.051 train accuracy: 0.883\n",
      "[9,   200/  372] train loss: 0.045 train accuracy: 0.930\n",
      "[9,   300/  372] train loss: 0.049 train accuracy: 0.875\n",
      "epoch: 9 validation accuracy: 0.462\n",
      "[10,   100/  372] train loss: 0.043 train accuracy: 0.914\n",
      "[10,   200/  372] train loss: 0.046 train accuracy: 0.906\n",
      "[10,   300/  372] train loss: 0.039 train accuracy: 0.898\n",
      "epoch: 10 validation accuracy: 0.462\n",
      "[11,   100/  372] train loss: 0.037 train accuracy: 0.945\n",
      "[11,   200/  372] train loss: 0.034 train accuracy: 0.898\n",
      "[11,   300/  372] train loss: 0.035 train accuracy: 0.883\n",
      "epoch: 11 validation accuracy: 0.466\n",
      "[12,   100/  372] train loss: 0.028 train accuracy: 0.906\n",
      "[12,   200/  372] train loss: 0.026 train accuracy: 0.883\n",
      "[12,   300/  372] train loss: 0.025 train accuracy: 0.914\n",
      "epoch: 12 validation accuracy: 0.469\n",
      "[13,   100/  372] train loss: 0.025 train accuracy: 0.938\n",
      "[13,   200/  372] train loss: 0.029 train accuracy: 0.906\n",
      "[13,   300/  372] train loss: 0.024 train accuracy: 0.914\n",
      "epoch: 13 validation accuracy: 0.465\n",
      "[14,   100/  372] train loss: 0.020 train accuracy: 0.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,   200/  372] train loss: 0.021 train accuracy: 0.883\n",
      "[14,   300/  372] train loss: 0.019 train accuracy: 0.891\n",
      "epoch: 14 validation accuracy: 0.463\n",
      "[15,   100/  372] train loss: 0.019 train accuracy: 0.930\n",
      "[15,   200/  372] train loss: 0.019 train accuracy: 0.852\n",
      "[15,   300/  372] train loss: 0.019 train accuracy: 0.945\n",
      "epoch: 15 validation accuracy: 0.465\n",
      "[16,   100/  372] train loss: 0.016 train accuracy: 0.859\n",
      "[16,   200/  372] train loss: 0.017 train accuracy: 0.883\n",
      "[16,   300/  372] train loss: 0.015 train accuracy: 0.875\n",
      "epoch: 16 validation accuracy: 0.465\n",
      "[17,   100/  372] train loss: 0.017 train accuracy: 0.891\n",
      "[17,   200/  372] train loss: 0.014 train accuracy: 0.875\n",
      "[17,   300/  372] train loss: 0.013 train accuracy: 0.914\n",
      "epoch: 17 validation accuracy: 0.466\n",
      "[18,   100/  372] train loss: 0.013 train accuracy: 0.883\n",
      "[18,   200/  372] train loss: 0.012 train accuracy: 0.875\n",
      "[18,   300/  372] train loss: 0.013 train accuracy: 0.922\n",
      "epoch: 18 validation accuracy: 0.463\n",
      "[19,   100/  372] train loss: 0.012 train accuracy: 0.914\n",
      "[19,   200/  372] train loss: 0.010 train accuracy: 0.875\n",
      "[19,   300/  372] train loss: 0.010 train accuracy: 0.922\n",
      "epoch: 19 validation accuracy: 0.464\n",
      "[20,   100/  372] train loss: 0.012 train accuracy: 0.898\n",
      "[20,   200/  372] train loss: 0.012 train accuracy: 0.867\n",
      "[20,   300/  372] train loss: 0.010 train accuracy: 0.945\n",
      "epoch: 20 validation accuracy: 0.470\n"
     ]
    }
   ],
   "source": [
    "temperatures = [1, 2, 5, 10, 15, 20]\n",
    "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "# loss = alpha * st + (1 - alpha) * tt\n",
    "alphas = [1.0]\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['alpha'] = hparam_tuple[0]\n",
    "    hparam['T'] = hparam_tuple[1]\n",
    "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[3]\n",
    "    hparam['lr_decay'] = hparam_tuple[4]\n",
    "    hparam['momentum'] = hparam_tuple[5]\n",
    "    hparam['lr'] = hparam_tuple[6]\n",
    "    hparams_list.append(hparam)\n",
    "\n",
    "results_distill = {}\n",
    "for hparam in hparams_list:\n",
    "    print('Training with hparams' + utils.hparamToString(hparam))\n",
    "    reproducibilitySeed()\n",
    "    student_net = networks.StudentNetworkLarge(cifar_image_shape, num_class)\n",
    "    student_net = student_net.to(fast_device)\n",
    "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
    "    results_distill[hparam_tuple] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
    "                                                                train_loader, val_loader, \n",
    "                                                                print_every=print_every, \n",
    "                                                                fast_device=fast_device)\n",
    "    save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    torch.save({'results' : results_distill[hparam_tuple], \n",
    "                'model_state_dict' : student_net.state_dict(), \n",
    "                'epoch' : num_epochs}, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [10, 5]\n",
    "T_scatter = [math.log(h['T']) for h in hparams_list]\n",
    "alpha_scatter = [h['alpha'] for h in hparams_list]\n",
    "colors = []\n",
    "for i in range(len(hparams_list)):\n",
    "    cur_hparam_tuple = utils.hparamDictToTuple(hparams_list[i])\n",
    "    colors.append(results_distill[cur_hparam_tuple]['val_acc'][-1])\n",
    "    \n",
    "marker_size = 100\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(T_scatter, alpha_scatter, marker_size, c=colors, edgecolors='black')\n",
    "plt.colorbar()\n",
    "for i in range(len(T_scatter)):\n",
    "    ax.annotate(str('%0.4f' % (colors[i], )), (T_scatter[i], alpha_scatter[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "color = ['r', 'b', 'g', 'm', 'y', 'k']\n",
    "for hparam, c in zip(hparams_list, color):\n",
    "    cur_results = results_distill[utils.hparamDictToTuple(hparam)]\n",
    "    plt.plot(cur_results['val_acc'], color=c, label=str(hparam['T']))\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.title('Validation Accuracy vs Epoch for different T')\n",
    "plt.savefig(summaries_path_student + 'val_acc_vs_epoch_wrt_T.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hparam in hparams_list:\n",
    "    load_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    load_dict = torch.load(load_path)\n",
    "    student_net = networks.StudentNetwork()\n",
    "    student_net.load_state_dict(load_dict['model_state_dict'])\n",
    "    student_net = student_net.to(fast_device)\n",
    "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
    "    print(utils.hparamToString(hparam))\n",
    "    print('test accuracy: ', test_accuracy)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [5]\n",
    "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "# loss = alpha * st + (1 - alpha) * tt\n",
    "alphas = [0.8, 0.5, 0.4, 0.2]\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['alpha'] = hparam_tuple[0]\n",
    "    hparam['T'] = hparam_tuple[1]\n",
    "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[3]\n",
    "    hparam['lr_decay'] = hparam_tuple[4]\n",
    "    hparam['momentum'] = hparam_tuple[5]\n",
    "    hparam['lr'] = hparam_tuple[6]\n",
    "    hparams_list.append(hparam)\n",
    "\n",
    "results_distill = {}\n",
    "for hparam in hparams_list:\n",
    "    print('Training with hparams' + utils.hparamToString(hparam))\n",
    "    reproducibilitySeed()\n",
    "    student_net = networks.StudentNetwork()\n",
    "    student_net = student_net.to(fast_device)\n",
    "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
    "    results_distill[hparam_tuple] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
    "                                                                train_loader, val_loader, \n",
    "                                                                print_every=print_every, \n",
    "                                                                fast_device=fast_device)\n",
    "    save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    torch.save({'results' : results_distill[hparam_tuple], \n",
    "                'model_state_dict' : student_net.state_dict(), \n",
    "                'epoch' : num_epochs}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [10, 5]\n",
    "T_scatter = [math.log(h['T']) for h in hparams_list]\n",
    "alpha_scatter = [h['alpha'] for h in hparams_list]\n",
    "colors = []\n",
    "for i in range(len(hparams_list)):\n",
    "    cur_hparam_tuple = utils.hparamDictToTuple(hparams_list[i])\n",
    "    colors.append(results_distill[cur_hparam_tuple]['val_acc'][-1])\n",
    "    \n",
    "marker_size = 100\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(T_scatter, alpha_scatter, marker_size, c=colors, edgecolors='black')\n",
    "plt.colorbar()\n",
    "for i in range(len(T_scatter)):\n",
    "    ax.annotate(str('%0.4f' % (colors[i], )), (T_scatter[i], alpha_scatter[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['r', 'b', 'g', 'm']\n",
    "for hparam, c in zip(hparams_list, color):\n",
    "    cur_results = results_distill[utils.hparamDictToTuple(hparam)]\n",
    "    plt.plot(cur_results['val_acc'], color=c, label=str(hparam['alpha']))\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.title('Validation Accuracy vs Epoch for different alpha')\n",
    "plt.savefig(summaries_path_student + 'val_acc_vs_epoch_wrt_alpha.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hparam in hparams_list:\n",
    "    load_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    load_dict = torch.load(load_path)\n",
    "    student_net = networks.StudentNetwork()\n",
    "    student_net.load_state_dict(load_dict['model_state_dict'])\n",
    "    student_net = student_net.to(fast_device)\n",
    "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
    "    print(utils.hparamToString(hparam))\n",
    "    print('test accuracy: ', test_accuracy)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
