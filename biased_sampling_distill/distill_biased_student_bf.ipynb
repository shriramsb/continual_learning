{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages and limit GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "import networks\n",
    "import utils\n",
    "import biased_sampler\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True    # set use_gpu to True if system has gpu\n",
    "gpu_id = 1        # id of gpu to be used\n",
    "cpu_device = torch.device('cpu')\n",
    "# fast_device is where computation (training, inference) happens\n",
    "fast_device = torch.device('cpu')\n",
    "if use_gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'    # set visible devices depending on system configuration\n",
    "    fast_device = torch.device('cuda:' + str(gpu_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure reproducibility\n",
    "def reproducibilitySeed():\n",
    "    \"\"\"\n",
    "    Ensure reproducibility of results; Seeds to 0\n",
    "    \"\"\"\n",
    "    torch_init_seed = 0\n",
    "    torch.manual_seed(torch_init_seed)\n",
    "    numpy_init_seed = 0\n",
    "    np.random.seed(numpy_init_seed)\n",
    "    if use_gpu:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "reproducibilitySeed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Student trained without data augmentation\n",
    "transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5), (0.5, 0.5))\n",
    "                ]\n",
    "            )\n",
    "\n",
    "train_val_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=True, \n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=False, \n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "num_train = int(1.0 * len(train_val_dataset) * 95 / 100)\n",
    "num_val = len(train_val_dataset) - num_train\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_class = 10\n",
    "class_prob = [0.0 for _ in range(num_class)]\n",
    "class_prob[7] = 0.5\n",
    "class_prob[8] = 0.5\n",
    "\n",
    "train_val_biased_sampler = biased_sampler.MNISTClassBiasedSampler(train_val_dataset, class_prob)\n",
    "train_biased_sampler = biased_sampler.MNISTClassBiasedSampler(train_dataset, class_prob)\n",
    "\n",
    "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=128, \n",
    "                                                sampler=train_val_biased_sampler, \n",
    "                                                num_workers=2)\n",
    "train_val_balanced_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=128, shuffle=True, \n",
    "                                                        num_workers=2)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, \n",
    "                                            sampler=train_biased_sampler, \n",
    "                                            num_workers=2)\n",
    "train_balanced_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
    "                                                    num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path_teacher = 'checkpoints_teacher/'\n",
    "checkpoints_path_student = 'checkpoints_student_biased_bf/'\n",
    "summaries_path_student = 'summaries_student_biased_bf/'\n",
    "if not os.path.exists(checkpoints_path_student):\n",
    "    os.makedirs(checkpoints_path_student)\n",
    "if not os.path.exists(summaries_path_student):\n",
    "    os.makedirs(summaries_path_student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load teacher network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hparams used for training teacher to load the teacher network\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "# keeping dropout input = dropout hidden\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "for hparam_tuple in itertools.product(dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['dropout_input'] = hparam_tuple[0][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[0][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[1]\n",
    "    hparam['lr_decay'] = hparam_tuple[2]\n",
    "    hparam['momentum'] = hparam_tuple[3]\n",
    "    hparam['lr'] = hparam_tuple[4]\n",
    "    hparams_list.append(hparam)\n",
    "    \n",
    "load_path = checkpoints_path_teacher + utils.hparamToString(hparams_list[0]) + '_final.tar'\n",
    "teacher_net = networks.TeacherNetwork()\n",
    "teacher_net.load_state_dict(torch.load(load_path, map_location=fast_device)['model_state_dict'])\n",
    "teacher_net = teacher_net.to(fast_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher test accuracy:  0.9892\n"
     ]
    }
   ],
   "source": [
    "# Calculate teacher test accuracy\n",
    "_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n",
    "print('teacher test accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train student network without distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "num_epochs_bf = 20\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hparamsT=1, alpha=0.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.100\n",
      "[1,   100/  446] train loss: 0.029 train accuracy: 0.992\n",
      "[1,   200/  446] train loss: 0.017 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 0.039 train accuracy: 0.984\n",
      "[1,   400/  446] train loss: 0.006 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.197\n",
      "[2,   100/  446] train loss: 0.005 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.005 train accuracy: 1.000\n",
      "[2,   300/  446] train loss: 0.019 train accuracy: 0.992\n",
      "[2,   400/  446] train loss: 0.015 train accuracy: 0.992\n",
      "epoch: 2 validation accuracy: 0.197\n",
      "[3,   100/  446] train loss: 0.007 train accuracy: 1.000\n",
      "[3,   200/  446] train loss: 0.004 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.017 train accuracy: 0.992\n",
      "[3,   400/  446] train loss: 0.029 train accuracy: 0.992\n",
      "epoch: 3 validation accuracy: 0.197\n",
      "[4,   100/  446] train loss: 0.025 train accuracy: 0.984\n",
      "[4,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.006 train accuracy: 1.000\n",
      "epoch: 4 validation accuracy: 0.197\n",
      "[5,   100/  446] train loss: 0.019 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.002 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.005 train accuracy: 1.000\n",
      "epoch: 5 validation accuracy: 0.197\n",
      "[6,   100/  446] train loss: 0.004 train accuracy: 1.000\n",
      "[6,   200/  446] train loss: 0.005 train accuracy: 1.000\n",
      "[6,   300/  446] train loss: 0.004 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.002 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.197\n",
      "[7,   100/  446] train loss: 0.009 train accuracy: 0.992\n",
      "[7,   200/  446] train loss: 0.017 train accuracy: 0.992\n",
      "[7,   300/  446] train loss: 0.002 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.005 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.197\n",
      "[8,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.006 train accuracy: 1.000\n",
      "[8,   300/  446] train loss: 0.008 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.004 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.198\n",
      "[9,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.006 train accuracy: 1.000\n",
      "[9,   400/  446] train loss: 0.002 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.198\n",
      "[10,   100/  446] train loss: 0.009 train accuracy: 1.000\n",
      "[10,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.002 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.004 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.197\n",
      "[11,   100/  446] train loss: 0.003 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.003 train accuracy: 1.000\n",
      "[11,   300/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.002 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.197\n",
      "[12,   100/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.003 train accuracy: 1.000\n",
      "[12,   400/  446] train loss: 0.002 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.198\n",
      "[13,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[13,   200/  446] train loss: 0.003 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.003 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.002 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.198\n",
      "[14,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.002 train accuracy: 1.000\n",
      "[14,   300/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[14,   400/  446] train loss: 0.002 train accuracy: 1.000\n",
      "epoch: 14 validation accuracy: 0.198\n",
      "[15,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[15,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[15,   300/  446] train loss: 0.008 train accuracy: 1.000\n",
      "[15,   400/  446] train loss: 0.002 train accuracy: 1.000\n",
      "epoch: 15 validation accuracy: 0.198\n",
      "[16,   100/  446] train loss: 0.002 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[16,   300/  446] train loss: 0.003 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.001 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.198\n",
      "[17,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.003 train accuracy: 1.000\n",
      "[17,   300/  446] train loss: 0.003 train accuracy: 1.000\n",
      "[17,   400/  446] train loss: 0.004 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.198\n",
      "[18,   100/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.003 train accuracy: 1.000\n",
      "[18,   300/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[18,   400/  446] train loss: 0.002 train accuracy: 1.000\n",
      "epoch: 18 validation accuracy: 0.198\n",
      "[19,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[19,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.000 train accuracy: 1.000\n",
      "[19,   400/  446] train loss: 0.000 train accuracy: 1.000\n",
      "epoch: 19 validation accuracy: 0.198\n",
      "[20,   100/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[20,   200/  446] train loss: 0.001 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.003 train accuracy: 1.000\n",
      "[20,   400/  446] train loss: 0.001 train accuracy: 1.000\n",
      "epoch: 20 validation accuracy: 0.198\n",
      "epoch: 0 validation accuracy: 0.198\n",
      "[1,   100/  446] train loss: 0.809 train accuracy: 0.750\n",
      "[1,   200/  446] train loss: 0.580 train accuracy: 0.875\n",
      "[1,   300/  446] train loss: 0.560 train accuracy: 0.828\n",
      "[1,   400/  446] train loss: 0.536 train accuracy: 0.852\n",
      "epoch: 1 validation accuracy: 0.853\n",
      "[2,   100/  446] train loss: 0.562 train accuracy: 0.820\n",
      "[2,   200/  446] train loss: 0.511 train accuracy: 0.875\n",
      "[2,   300/  446] train loss: 0.456 train accuracy: 0.867\n",
      "[2,   400/  446] train loss: 0.473 train accuracy: 0.875\n",
      "epoch: 2 validation accuracy: 0.889\n",
      "[3,   100/  446] train loss: 0.435 train accuracy: 0.875\n",
      "[3,   200/  446] train loss: 0.321 train accuracy: 0.930\n",
      "[3,   300/  446] train loss: 0.417 train accuracy: 0.891\n",
      "[3,   400/  446] train loss: 0.587 train accuracy: 0.805\n",
      "epoch: 3 validation accuracy: 0.888\n",
      "[4,   100/  446] train loss: 0.377 train accuracy: 0.906\n",
      "[4,   200/  446] train loss: 0.358 train accuracy: 0.891\n",
      "[4,   300/  446] train loss: 0.343 train accuracy: 0.898\n",
      "[4,   400/  446] train loss: 0.396 train accuracy: 0.883\n",
      "epoch: 4 validation accuracy: 0.895\n",
      "[5,   100/  446] train loss: 0.374 train accuracy: 0.875\n",
      "[5,   200/  446] train loss: 0.363 train accuracy: 0.898\n",
      "[5,   300/  446] train loss: 0.347 train accuracy: 0.898\n",
      "[5,   400/  446] train loss: 0.417 train accuracy: 0.867\n",
      "epoch: 5 validation accuracy: 0.895\n",
      "[6,   100/  446] train loss: 0.420 train accuracy: 0.859\n",
      "[6,   200/  446] train loss: 0.426 train accuracy: 0.859\n",
      "[6,   300/  446] train loss: 0.386 train accuracy: 0.883\n",
      "[6,   400/  446] train loss: 0.337 train accuracy: 0.914\n",
      "epoch: 6 validation accuracy: 0.899\n",
      "[7,   100/  446] train loss: 0.394 train accuracy: 0.852\n",
      "[7,   200/  446] train loss: 0.365 train accuracy: 0.844\n",
      "[7,   300/  446] train loss: 0.297 train accuracy: 0.906\n",
      "[7,   400/  446] train loss: 0.360 train accuracy: 0.891\n",
      "epoch: 7 validation accuracy: 0.904\n",
      "[8,   100/  446] train loss: 0.320 train accuracy: 0.953\n",
      "[8,   200/  446] train loss: 0.358 train accuracy: 0.898\n",
      "[8,   300/  446] train loss: 0.230 train accuracy: 0.945\n",
      "[8,   400/  446] train loss: 0.317 train accuracy: 0.922\n",
      "epoch: 8 validation accuracy: 0.908\n",
      "[9,   100/  446] train loss: 0.206 train accuracy: 0.945\n",
      "[9,   200/  446] train loss: 0.168 train accuracy: 0.961\n",
      "[9,   300/  446] train loss: 0.357 train accuracy: 0.906\n",
      "[9,   400/  446] train loss: 0.387 train accuracy: 0.844\n",
      "epoch: 9 validation accuracy: 0.905\n",
      "[10,   100/  446] train loss: 0.337 train accuracy: 0.883\n",
      "[10,   200/  446] train loss: 0.221 train accuracy: 0.953\n",
      "[10,   300/  446] train loss: 0.320 train accuracy: 0.891\n",
      "[10,   400/  446] train loss: 0.409 train accuracy: 0.875\n",
      "epoch: 10 validation accuracy: 0.906\n",
      "[11,   100/  446] train loss: 0.248 train accuracy: 0.945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,   200/  446] train loss: 0.213 train accuracy: 0.945\n",
      "[11,   300/  446] train loss: 0.310 train accuracy: 0.891\n",
      "[11,   400/  446] train loss: 0.361 train accuracy: 0.898\n",
      "epoch: 11 validation accuracy: 0.909\n",
      "[12,   100/  446] train loss: 0.241 train accuracy: 0.945\n",
      "[12,   200/  446] train loss: 0.230 train accuracy: 0.930\n",
      "[12,   300/  446] train loss: 0.323 train accuracy: 0.906\n",
      "[12,   400/  446] train loss: 0.217 train accuracy: 0.938\n",
      "epoch: 12 validation accuracy: 0.912\n",
      "[13,   100/  446] train loss: 0.342 train accuracy: 0.898\n",
      "[13,   200/  446] train loss: 0.321 train accuracy: 0.891\n",
      "[13,   300/  446] train loss: 0.264 train accuracy: 0.930\n",
      "[13,   400/  446] train loss: 0.341 train accuracy: 0.906\n",
      "epoch: 13 validation accuracy: 0.912\n",
      "[14,   100/  446] train loss: 0.398 train accuracy: 0.867\n",
      "[14,   200/  446] train loss: 0.223 train accuracy: 0.914\n",
      "[14,   300/  446] train loss: 0.358 train accuracy: 0.859\n",
      "[14,   400/  446] train loss: 0.276 train accuracy: 0.906\n",
      "epoch: 14 validation accuracy: 0.915\n",
      "[15,   100/  446] train loss: 0.420 train accuracy: 0.891\n",
      "[15,   200/  446] train loss: 0.230 train accuracy: 0.945\n",
      "[15,   300/  446] train loss: 0.251 train accuracy: 0.945\n",
      "[15,   400/  446] train loss: 0.329 train accuracy: 0.883\n",
      "epoch: 15 validation accuracy: 0.912\n",
      "[16,   100/  446] train loss: 0.254 train accuracy: 0.938\n",
      "[16,   200/  446] train loss: 0.544 train accuracy: 0.828\n",
      "[16,   300/  446] train loss: 0.285 train accuracy: 0.914\n",
      "[16,   400/  446] train loss: 0.295 train accuracy: 0.906\n",
      "epoch: 16 validation accuracy: 0.915\n",
      "[17,   100/  446] train loss: 0.227 train accuracy: 0.922\n",
      "[17,   200/  446] train loss: 0.283 train accuracy: 0.898\n",
      "[17,   300/  446] train loss: 0.220 train accuracy: 0.953\n",
      "[17,   400/  446] train loss: 0.302 train accuracy: 0.891\n",
      "epoch: 17 validation accuracy: 0.916\n",
      "[18,   100/  446] train loss: 0.238 train accuracy: 0.930\n",
      "[18,   200/  446] train loss: 0.231 train accuracy: 0.945\n",
      "[18,   300/  446] train loss: 0.246 train accuracy: 0.945\n",
      "[18,   400/  446] train loss: 0.167 train accuracy: 0.961\n",
      "epoch: 18 validation accuracy: 0.915\n",
      "[19,   100/  446] train loss: 0.225 train accuracy: 0.930\n",
      "[19,   200/  446] train loss: 0.265 train accuracy: 0.938\n",
      "[19,   300/  446] train loss: 0.287 train accuracy: 0.938\n",
      "[19,   400/  446] train loss: 0.243 train accuracy: 0.938\n",
      "epoch: 19 validation accuracy: 0.913\n",
      "[20,   100/  446] train loss: 0.301 train accuracy: 0.914\n",
      "[20,   200/  446] train loss: 0.179 train accuracy: 0.969\n",
      "[20,   300/  446] train loss: 0.239 train accuracy: 0.922\n",
      "[20,   400/  446] train loss: 0.330 train accuracy: 0.906\n",
      "epoch: 20 validation accuracy: 0.915\n"
     ]
    }
   ],
   "source": [
    "temperatures = [1]    # temperature for distillation loss\n",
    "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "# loss = alpha * st + (1 - alpha) * tt\n",
    "alphas = [0.0]\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "# No dropout used\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['alpha'] = hparam_tuple[0]\n",
    "    hparam['T'] = hparam_tuple[1]\n",
    "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[3]\n",
    "    hparam['lr_decay'] = hparam_tuple[4]\n",
    "    hparam['momentum'] = hparam_tuple[5]\n",
    "    hparam['lr'] = hparam_tuple[6]\n",
    "    hparams_list.append(hparam)\n",
    "\n",
    "results_no_distill = {}\n",
    "for hparam in hparams_list:\n",
    "    print('Training with hparams' + utils.hparamToString(hparam))\n",
    "    reproducibilitySeed()\n",
    "    student_net = networks.StudentNetwork()\n",
    "    student_net = student_net.to(fast_device)\n",
    "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
    "    results_no_distill[hparam_tuple] = [None, None]\n",
    "    results_no_distill[hparam_tuple][0] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
    "                                                                    train_loader, val_loader, \n",
    "                                                                    print_every=print_every, \n",
    "                                                                    fast_device=fast_device)\n",
    "    results_no_distill[hparam_tuple][1] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs_bf, \n",
    "                                                                    train_balanced_loader, val_loader, \n",
    "                                                                    print_every=print_every, \n",
    "                                                                    fast_device=fast_device, \n",
    "                                                                    only_penultimate_train=True)\n",
    "    save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    torch.save({'results' : results_no_distill[hparam_tuple], \n",
    "                'model_state_dict' : student_net.state_dict(), \n",
    "                'epoch' : num_epochs}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T=1, alpha=0.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot validation accuracy \n",
    "for hparam in hparams_list:\n",
    "    print(utils.hparamToString(hparam))\n",
    "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
    "    val_acc = results_no_distill[hparam_tuple][0]['val_acc'] + results_no_distill[hparam_tuple][1]['val_acc']\n",
    "    plt.plot(val_acc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T=1, alpha=0.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "test accuracy:  0.9204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hparam in hparams_list:\n",
    "    load_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    load_dict = torch.load(load_path)\n",
    "    student_net = networks.StudentNetwork()\n",
    "    student_net.load_state_dict(load_dict['model_state_dict'])\n",
    "    student_net = student_net.to(fast_device)\n",
    "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
    "    print(utils.hparamToString(hparam))\n",
    "    print('test accuracy: ', test_accuracy)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [10, 5]\n",
    "weight_decay_scatter = ([math.log10(h['weight_decay']) if h['weight_decay'] > 0 else -6 for h in hparams_list])\n",
    "dropout_scatter = [int(h['dropout_input'] == 0.2) for h in hparams_list]\n",
    "colors = []\n",
    "for i in range(len(hparams_list)):\n",
    "    cur_hparam_tuple = utils.hparamDictToTuple(hparams_list[i])\n",
    "    colors.append(results_no_distill[cur_hparam_tuple]['val_acc'][-1])\n",
    "    \n",
    "marker_size = 100\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(weight_decay_scatter, dropout_scatter, marker_size, c=colors, edgecolors='black')\n",
    "plt.colorbar()\n",
    "for i in range(len(weight_decay_scatter)):\n",
    "    ax.annotate(str('%0.4f' % (colors[i], )), (weight_decay_scatter[i], dropout_scatter[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train student network using distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "num_epochs_bf = 20\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hparamsT=1, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.100\n",
      "[1,   100/  446] train loss: 0.089 train accuracy: 0.992\n",
      "[1,   200/  446] train loss: 0.032 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 0.058 train accuracy: 0.984\n",
      "[1,   400/  446] train loss: 0.057 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.197\n",
      "[2,   100/  446] train loss: 0.017 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.031 train accuracy: 1.000\n",
      "[2,   300/  446] train loss: 0.047 train accuracy: 0.992\n",
      "[2,   400/  446] train loss: 0.033 train accuracy: 1.000\n",
      "epoch: 2 validation accuracy: 0.198\n",
      "[3,   100/  446] train loss: 0.031 train accuracy: 1.000\n",
      "[3,   200/  446] train loss: 0.032 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.052 train accuracy: 1.000\n",
      "[3,   400/  446] train loss: 0.057 train accuracy: 0.992\n",
      "epoch: 3 validation accuracy: 0.203\n",
      "[4,   100/  446] train loss: 0.042 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.035 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.037 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.027 train accuracy: 0.992\n",
      "epoch: 4 validation accuracy: 0.206\n",
      "[5,   100/  446] train loss: 0.026 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.006 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.022 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.021 train accuracy: 0.992\n",
      "epoch: 5 validation accuracy: 0.220\n",
      "[6,   100/  446] train loss: 0.019 train accuracy: 1.000\n",
      "[6,   200/  446] train loss: 0.042 train accuracy: 1.000\n",
      "[6,   300/  446] train loss: 0.036 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.023 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.251\n",
      "[7,   100/  446] train loss: 0.049 train accuracy: 0.992\n",
      "[7,   200/  446] train loss: 0.022 train accuracy: 0.992\n",
      "[7,   300/  446] train loss: 0.025 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.022 train accuracy: 0.984\n",
      "epoch: 7 validation accuracy: 0.261\n",
      "[8,   100/  446] train loss: 0.034 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.021 train accuracy: 0.992\n",
      "[8,   300/  446] train loss: 0.022 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.019 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.264\n",
      "[9,   100/  446] train loss: 0.008 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.010 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.032 train accuracy: 0.992\n",
      "[9,   400/  446] train loss: 0.016 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.276\n",
      "[10,   100/  446] train loss: 0.039 train accuracy: 0.992\n",
      "[10,   200/  446] train loss: 0.009 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.015 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.035 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.300\n",
      "[11,   100/  446] train loss: 0.018 train accuracy: 0.992\n",
      "[11,   200/  446] train loss: 0.033 train accuracy: 1.000\n",
      "[11,   300/  446] train loss: 0.009 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.008 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.298\n",
      "[12,   100/  446] train loss: 0.018 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.010 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.029 train accuracy: 0.992\n",
      "[12,   400/  446] train loss: 0.017 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.319\n",
      "[13,   100/  446] train loss: 0.013 train accuracy: 1.000\n",
      "[13,   200/  446] train loss: 0.019 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.020 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.016 train accuracy: 0.992\n",
      "epoch: 13 validation accuracy: 0.321\n",
      "[14,   100/  446] train loss: 0.014 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.027 train accuracy: 1.000\n",
      "[14,   300/  446] train loss: 0.015 train accuracy: 0.992\n",
      "[14,   400/  446] train loss: 0.006 train accuracy: 1.000\n",
      "epoch: 14 validation accuracy: 0.329\n",
      "[15,   100/  446] train loss: 0.017 train accuracy: 1.000\n",
      "[15,   200/  446] train loss: 0.019 train accuracy: 1.000\n",
      "[15,   300/  446] train loss: 0.022 train accuracy: 0.984\n",
      "[15,   400/  446] train loss: 0.017 train accuracy: 0.992\n",
      "epoch: 15 validation accuracy: 0.338\n",
      "[16,   100/  446] train loss: 0.029 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.013 train accuracy: 0.984\n",
      "[16,   300/  446] train loss: 0.011 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.018 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.314\n",
      "[17,   100/  446] train loss: 0.024 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.012 train accuracy: 1.000\n",
      "[17,   300/  446] train loss: 0.015 train accuracy: 0.992\n",
      "[17,   400/  446] train loss: 0.016 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.347\n",
      "[18,   100/  446] train loss: 0.016 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.025 train accuracy: 0.992\n",
      "[18,   300/  446] train loss: 0.012 train accuracy: 0.992\n",
      "[18,   400/  446] train loss: 0.016 train accuracy: 1.000\n",
      "epoch: 18 validation accuracy: 0.355\n",
      "[19,   100/  446] train loss: 0.012 train accuracy: 0.992\n",
      "[19,   200/  446] train loss: 0.010 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.021 train accuracy: 0.992\n",
      "[19,   400/  446] train loss: 0.016 train accuracy: 1.000\n",
      "epoch: 19 validation accuracy: 0.351\n",
      "[20,   100/  446] train loss: 0.013 train accuracy: 0.992\n",
      "[20,   200/  446] train loss: 0.014 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.009 train accuracy: 0.992\n",
      "[20,   400/  446] train loss: 0.010 train accuracy: 1.000\n",
      "epoch: 20 validation accuracy: 0.353\n",
      "epoch: 0 validation accuracy: 0.353\n",
      "[1,   100/  446] train loss: 0.434 train accuracy: 0.836\n",
      "[1,   200/  446] train loss: 0.343 train accuracy: 0.922\n",
      "[1,   300/  446] train loss: 0.374 train accuracy: 0.898\n",
      "[1,   400/  446] train loss: 0.285 train accuracy: 0.891\n",
      "epoch: 1 validation accuracy: 0.902\n",
      "[2,   100/  446] train loss: 0.339 train accuracy: 0.867\n",
      "[2,   200/  446] train loss: 0.224 train accuracy: 0.922\n",
      "[2,   300/  446] train loss: 0.264 train accuracy: 0.891\n",
      "[2,   400/  446] train loss: 0.328 train accuracy: 0.906\n",
      "epoch: 2 validation accuracy: 0.909\n",
      "[3,   100/  446] train loss: 0.326 train accuracy: 0.906\n",
      "[3,   200/  446] train loss: 0.181 train accuracy: 0.938\n",
      "[3,   300/  446] train loss: 0.331 train accuracy: 0.898\n",
      "[3,   400/  446] train loss: 0.335 train accuracy: 0.852\n",
      "epoch: 3 validation accuracy: 0.913\n",
      "[4,   100/  446] train loss: 0.298 train accuracy: 0.906\n",
      "[4,   200/  446] train loss: 0.208 train accuracy: 0.922\n",
      "[4,   300/  446] train loss: 0.250 train accuracy: 0.906\n",
      "[4,   400/  446] train loss: 0.294 train accuracy: 0.906\n",
      "epoch: 4 validation accuracy: 0.916\n",
      "[5,   100/  446] train loss: 0.246 train accuracy: 0.906\n",
      "[5,   200/  446] train loss: 0.263 train accuracy: 0.914\n",
      "[5,   300/  446] train loss: 0.217 train accuracy: 0.922\n",
      "[5,   400/  446] train loss: 0.246 train accuracy: 0.914\n",
      "epoch: 5 validation accuracy: 0.918\n",
      "[6,   100/  446] train loss: 0.337 train accuracy: 0.883\n",
      "[6,   200/  446] train loss: 0.271 train accuracy: 0.906\n",
      "[6,   300/  446] train loss: 0.238 train accuracy: 0.922\n",
      "[6,   400/  446] train loss: 0.171 train accuracy: 0.930\n",
      "epoch: 6 validation accuracy: 0.924\n",
      "[7,   100/  446] train loss: 0.221 train accuracy: 0.906\n",
      "[7,   200/  446] train loss: 0.196 train accuracy: 0.914\n",
      "[7,   300/  446] train loss: 0.178 train accuracy: 0.945\n",
      "[7,   400/  446] train loss: 0.239 train accuracy: 0.906\n",
      "epoch: 7 validation accuracy: 0.926\n",
      "[8,   100/  446] train loss: 0.206 train accuracy: 0.945\n",
      "[8,   200/  446] train loss: 0.212 train accuracy: 0.953\n",
      "[8,   300/  446] train loss: 0.142 train accuracy: 0.961\n",
      "[8,   400/  446] train loss: 0.170 train accuracy: 0.938\n",
      "epoch: 8 validation accuracy: 0.925\n",
      "[9,   100/  446] train loss: 0.125 train accuracy: 0.961\n",
      "[9,   200/  446] train loss: 0.114 train accuracy: 0.984\n",
      "[9,   300/  446] train loss: 0.201 train accuracy: 0.922\n",
      "[9,   400/  446] train loss: 0.295 train accuracy: 0.891\n",
      "epoch: 9 validation accuracy: 0.927\n",
      "[10,   100/  446] train loss: 0.206 train accuracy: 0.914\n",
      "[10,   200/  446] train loss: 0.147 train accuracy: 0.961\n",
      "[10,   300/  446] train loss: 0.205 train accuracy: 0.906\n",
      "[10,   400/  446] train loss: 0.214 train accuracy: 0.914\n",
      "epoch: 10 validation accuracy: 0.928\n",
      "[11,   100/  446] train loss: 0.165 train accuracy: 0.945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,   200/  446] train loss: 0.151 train accuracy: 0.961\n",
      "[11,   300/  446] train loss: 0.212 train accuracy: 0.906\n",
      "[11,   400/  446] train loss: 0.271 train accuracy: 0.898\n",
      "epoch: 11 validation accuracy: 0.927\n",
      "[12,   100/  446] train loss: 0.177 train accuracy: 0.953\n",
      "[12,   200/  446] train loss: 0.158 train accuracy: 0.938\n",
      "[12,   300/  446] train loss: 0.202 train accuracy: 0.938\n",
      "[12,   400/  446] train loss: 0.133 train accuracy: 0.953\n",
      "epoch: 12 validation accuracy: 0.928\n",
      "[13,   100/  446] train loss: 0.203 train accuracy: 0.914\n",
      "[13,   200/  446] train loss: 0.192 train accuracy: 0.906\n",
      "[13,   300/  446] train loss: 0.170 train accuracy: 0.945\n",
      "[13,   400/  446] train loss: 0.189 train accuracy: 0.945\n",
      "epoch: 13 validation accuracy: 0.930\n",
      "[14,   100/  446] train loss: 0.258 train accuracy: 0.883\n",
      "[14,   200/  446] train loss: 0.174 train accuracy: 0.938\n",
      "[14,   300/  446] train loss: 0.226 train accuracy: 0.922\n",
      "[14,   400/  446] train loss: 0.192 train accuracy: 0.930\n",
      "epoch: 14 validation accuracy: 0.929\n",
      "[15,   100/  446] train loss: 0.270 train accuracy: 0.898\n",
      "[15,   200/  446] train loss: 0.153 train accuracy: 0.953\n",
      "[15,   300/  446] train loss: 0.170 train accuracy: 0.938\n",
      "[15,   400/  446] train loss: 0.187 train accuracy: 0.914\n",
      "epoch: 15 validation accuracy: 0.932\n",
      "[16,   100/  446] train loss: 0.181 train accuracy: 0.938\n",
      "[16,   200/  446] train loss: 0.367 train accuracy: 0.867\n",
      "[16,   300/  446] train loss: 0.177 train accuracy: 0.938\n",
      "[16,   400/  446] train loss: 0.201 train accuracy: 0.922\n",
      "epoch: 16 validation accuracy: 0.933\n",
      "[17,   100/  446] train loss: 0.118 train accuracy: 0.945\n",
      "[17,   200/  446] train loss: 0.187 train accuracy: 0.930\n",
      "[17,   300/  446] train loss: 0.181 train accuracy: 0.945\n",
      "[17,   400/  446] train loss: 0.187 train accuracy: 0.914\n",
      "epoch: 17 validation accuracy: 0.931\n",
      "[18,   100/  446] train loss: 0.157 train accuracy: 0.945\n",
      "[18,   200/  446] train loss: 0.157 train accuracy: 0.938\n",
      "[18,   300/  446] train loss: 0.159 train accuracy: 0.930\n",
      "[18,   400/  446] train loss: 0.128 train accuracy: 0.953\n",
      "epoch: 18 validation accuracy: 0.932\n",
      "[19,   100/  446] train loss: 0.107 train accuracy: 0.969\n",
      "[19,   200/  446] train loss: 0.175 train accuracy: 0.953\n",
      "[19,   300/  446] train loss: 0.175 train accuracy: 0.953\n",
      "[19,   400/  446] train loss: 0.183 train accuracy: 0.922\n",
      "epoch: 19 validation accuracy: 0.933\n",
      "[20,   100/  446] train loss: 0.197 train accuracy: 0.922\n",
      "[20,   200/  446] train loss: 0.114 train accuracy: 0.961\n",
      "[20,   300/  446] train loss: 0.178 train accuracy: 0.930\n",
      "[20,   400/  446] train loss: 0.224 train accuracy: 0.906\n",
      "epoch: 20 validation accuracy: 0.934\n",
      "Training with hparamsT=2, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.100\n",
      "[1,   100/  446] train loss: 0.404 train accuracy: 0.984\n",
      "[1,   200/  446] train loss: 0.215 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 0.260 train accuracy: 0.992\n",
      "[1,   400/  446] train loss: 0.226 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.199\n",
      "[2,   100/  446] train loss: 0.113 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.177 train accuracy: 1.000\n",
      "[2,   300/  446] train loss: 0.196 train accuracy: 0.992\n",
      "[2,   400/  446] train loss: 0.145 train accuracy: 1.000\n",
      "epoch: 2 validation accuracy: 0.249\n",
      "[3,   100/  446] train loss: 0.157 train accuracy: 1.000\n",
      "[3,   200/  446] train loss: 0.133 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.164 train accuracy: 1.000\n",
      "[3,   400/  446] train loss: 0.156 train accuracy: 0.992\n",
      "epoch: 3 validation accuracy: 0.300\n",
      "[4,   100/  446] train loss: 0.139 train accuracy: 1.000\n",
      "[4,   200/  446] train loss: 0.144 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.154 train accuracy: 0.992\n",
      "[4,   400/  446] train loss: 0.130 train accuracy: 1.000\n",
      "epoch: 4 validation accuracy: 0.324\n",
      "[5,   100/  446] train loss: 0.107 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.062 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.091 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.097 train accuracy: 0.984\n",
      "epoch: 5 validation accuracy: 0.386\n",
      "[6,   100/  446] train loss: 0.117 train accuracy: 1.000\n",
      "[6,   200/  446] train loss: 0.102 train accuracy: 1.000\n",
      "[6,   300/  446] train loss: 0.122 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.076 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.442\n",
      "[7,   100/  446] train loss: 0.115 train accuracy: 0.977\n",
      "[7,   200/  446] train loss: 0.085 train accuracy: 0.992\n",
      "[7,   300/  446] train loss: 0.101 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.080 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.473\n",
      "[8,   100/  446] train loss: 0.092 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.090 train accuracy: 0.992\n",
      "[8,   300/  446] train loss: 0.097 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.064 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.480\n",
      "[9,   100/  446] train loss: 0.051 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.053 train accuracy: 0.992\n",
      "[9,   300/  446] train loss: 0.077 train accuracy: 0.984\n",
      "[9,   400/  446] train loss: 0.076 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.498\n",
      "[10,   100/  446] train loss: 0.085 train accuracy: 0.992\n",
      "[10,   200/  446] train loss: 0.050 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.055 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.085 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.538\n",
      "[11,   100/  446] train loss: 0.068 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.087 train accuracy: 1.000\n",
      "[11,   300/  446] train loss: 0.062 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.047 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.557\n",
      "[12,   100/  446] train loss: 0.062 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.057 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.065 train accuracy: 0.992\n",
      "[12,   400/  446] train loss: 0.056 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.565\n",
      "[13,   100/  446] train loss: 0.065 train accuracy: 1.000\n",
      "[13,   200/  446] train loss: 0.060 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.075 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.051 train accuracy: 0.992\n",
      "epoch: 13 validation accuracy: 0.576\n",
      "[14,   100/  446] train loss: 0.061 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.059 train accuracy: 1.000\n",
      "[14,   300/  446] train loss: 0.056 train accuracy: 0.992\n",
      "[14,   400/  446] train loss: 0.033 train accuracy: 1.000\n",
      "epoch: 14 validation accuracy: 0.581\n",
      "[15,   100/  446] train loss: 0.049 train accuracy: 0.992\n",
      "[15,   200/  446] train loss: 0.040 train accuracy: 1.000\n",
      "[15,   300/  446] train loss: 0.051 train accuracy: 0.977\n",
      "[15,   400/  446] train loss: 0.058 train accuracy: 0.992\n",
      "epoch: 15 validation accuracy: 0.578\n",
      "[16,   100/  446] train loss: 0.047 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.044 train accuracy: 0.984\n",
      "[16,   300/  446] train loss: 0.041 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.049 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.593\n",
      "[17,   100/  446] train loss: 0.053 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.049 train accuracy: 1.000\n",
      "[17,   300/  446] train loss: 0.042 train accuracy: 0.984\n",
      "[17,   400/  446] train loss: 0.049 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.603\n",
      "[18,   100/  446] train loss: 0.048 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.045 train accuracy: 0.992\n",
      "[18,   300/  446] train loss: 0.038 train accuracy: 0.992\n",
      "[18,   400/  446] train loss: 0.035 train accuracy: 0.992\n",
      "epoch: 18 validation accuracy: 0.606\n",
      "[19,   100/  446] train loss: 0.038 train accuracy: 0.992\n",
      "[19,   200/  446] train loss: 0.028 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.051 train accuracy: 0.992\n",
      "[19,   400/  446] train loss: 0.039 train accuracy: 1.000\n",
      "epoch: 19 validation accuracy: 0.612\n",
      "[20,   100/  446] train loss: 0.044 train accuracy: 0.992\n",
      "[20,   200/  446] train loss: 0.042 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.038 train accuracy: 0.992\n",
      "[20,   400/  446] train loss: 0.040 train accuracy: 1.000\n",
      "epoch: 20 validation accuracy: 0.618\n",
      "epoch: 0 validation accuracy: 0.618\n",
      "[1,   100/  446] train loss: 0.736 train accuracy: 0.914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200/  446] train loss: 0.566 train accuracy: 0.945\n",
      "[1,   300/  446] train loss: 0.683 train accuracy: 0.938\n",
      "[1,   400/  446] train loss: 0.563 train accuracy: 0.922\n",
      "epoch: 1 validation accuracy: 0.937\n",
      "[2,   100/  446] train loss: 0.590 train accuracy: 0.898\n",
      "[2,   200/  446] train loss: 0.404 train accuracy: 0.938\n",
      "[2,   300/  446] train loss: 0.540 train accuracy: 0.922\n",
      "[2,   400/  446] train loss: 0.530 train accuracy: 0.938\n",
      "epoch: 2 validation accuracy: 0.943\n",
      "[3,   100/  446] train loss: 0.630 train accuracy: 0.930\n",
      "[3,   200/  446] train loss: 0.297 train accuracy: 0.984\n",
      "[3,   300/  446] train loss: 0.635 train accuracy: 0.945\n",
      "[3,   400/  446] train loss: 0.578 train accuracy: 0.906\n",
      "epoch: 3 validation accuracy: 0.945\n",
      "[4,   100/  446] train loss: 0.518 train accuracy: 0.922\n",
      "[4,   200/  446] train loss: 0.443 train accuracy: 0.953\n",
      "[4,   300/  446] train loss: 0.351 train accuracy: 0.938\n",
      "[4,   400/  446] train loss: 0.544 train accuracy: 0.898\n",
      "epoch: 4 validation accuracy: 0.948\n",
      "[5,   100/  446] train loss: 0.451 train accuracy: 0.938\n",
      "[5,   200/  446] train loss: 0.405 train accuracy: 0.969\n",
      "[5,   300/  446] train loss: 0.409 train accuracy: 0.945\n",
      "[5,   400/  446] train loss: 0.394 train accuracy: 0.969\n",
      "epoch: 5 validation accuracy: 0.949\n",
      "[6,   100/  446] train loss: 0.486 train accuracy: 0.938\n",
      "[6,   200/  446] train loss: 0.487 train accuracy: 0.953\n",
      "[6,   300/  446] train loss: 0.386 train accuracy: 0.953\n",
      "[6,   400/  446] train loss: 0.287 train accuracy: 0.953\n",
      "epoch: 6 validation accuracy: 0.950\n",
      "[7,   100/  446] train loss: 0.359 train accuracy: 0.945\n",
      "[7,   200/  446] train loss: 0.318 train accuracy: 0.961\n",
      "[7,   300/  446] train loss: 0.387 train accuracy: 0.961\n",
      "[7,   400/  446] train loss: 0.337 train accuracy: 0.945\n",
      "epoch: 7 validation accuracy: 0.952\n",
      "[8,   100/  446] train loss: 0.302 train accuracy: 0.969\n",
      "[8,   200/  446] train loss: 0.290 train accuracy: 0.977\n",
      "[8,   300/  446] train loss: 0.316 train accuracy: 0.977\n",
      "[8,   400/  446] train loss: 0.286 train accuracy: 0.977\n",
      "epoch: 8 validation accuracy: 0.949\n",
      "[9,   100/  446] train loss: 0.260 train accuracy: 0.984\n",
      "[9,   200/  446] train loss: 0.198 train accuracy: 0.992\n",
      "[9,   300/  446] train loss: 0.269 train accuracy: 0.961\n",
      "[9,   400/  446] train loss: 0.385 train accuracy: 0.938\n",
      "epoch: 9 validation accuracy: 0.950\n",
      "[10,   100/  446] train loss: 0.393 train accuracy: 0.945\n",
      "[10,   200/  446] train loss: 0.304 train accuracy: 0.984\n",
      "[10,   300/  446] train loss: 0.381 train accuracy: 0.945\n",
      "[10,   400/  446] train loss: 0.304 train accuracy: 0.953\n",
      "epoch: 10 validation accuracy: 0.951\n",
      "[11,   100/  446] train loss: 0.247 train accuracy: 0.977\n",
      "[11,   200/  446] train loss: 0.350 train accuracy: 0.953\n",
      "[11,   300/  446] train loss: 0.367 train accuracy: 0.961\n",
      "[11,   400/  446] train loss: 0.317 train accuracy: 0.961\n",
      "epoch: 11 validation accuracy: 0.953\n",
      "[12,   100/  446] train loss: 0.352 train accuracy: 0.953\n",
      "[12,   200/  446] train loss: 0.270 train accuracy: 0.961\n",
      "[12,   300/  446] train loss: 0.266 train accuracy: 0.969\n",
      "[12,   400/  446] train loss: 0.205 train accuracy: 0.969\n",
      "epoch: 12 validation accuracy: 0.952\n",
      "[13,   100/  446] train loss: 0.359 train accuracy: 0.945\n",
      "[13,   200/  446] train loss: 0.345 train accuracy: 0.930\n",
      "[13,   300/  446] train loss: 0.282 train accuracy: 0.977\n",
      "[13,   400/  446] train loss: 0.339 train accuracy: 0.969\n",
      "epoch: 13 validation accuracy: 0.954\n",
      "[14,   100/  446] train loss: 0.533 train accuracy: 0.922\n",
      "[14,   200/  446] train loss: 0.320 train accuracy: 0.977\n",
      "[14,   300/  446] train loss: 0.364 train accuracy: 0.945\n",
      "[14,   400/  446] train loss: 0.371 train accuracy: 0.977\n",
      "epoch: 14 validation accuracy: 0.954\n",
      "[15,   100/  446] train loss: 0.398 train accuracy: 0.953\n",
      "[15,   200/  446] train loss: 0.274 train accuracy: 0.969\n",
      "[15,   300/  446] train loss: 0.284 train accuracy: 0.969\n",
      "[15,   400/  446] train loss: 0.256 train accuracy: 0.969\n",
      "epoch: 15 validation accuracy: 0.954\n",
      "[16,   100/  446] train loss: 0.349 train accuracy: 0.945\n",
      "[16,   200/  446] train loss: 0.629 train accuracy: 0.938\n",
      "[16,   300/  446] train loss: 0.337 train accuracy: 0.953\n",
      "[16,   400/  446] train loss: 0.361 train accuracy: 0.961\n",
      "epoch: 16 validation accuracy: 0.955\n",
      "[17,   100/  446] train loss: 0.230 train accuracy: 0.977\n",
      "[17,   200/  446] train loss: 0.349 train accuracy: 0.938\n",
      "[17,   300/  446] train loss: 0.223 train accuracy: 0.984\n",
      "[17,   400/  446] train loss: 0.364 train accuracy: 0.945\n",
      "epoch: 17 validation accuracy: 0.954\n",
      "[18,   100/  446] train loss: 0.277 train accuracy: 0.977\n",
      "[18,   200/  446] train loss: 0.292 train accuracy: 0.969\n",
      "[18,   300/  446] train loss: 0.286 train accuracy: 0.969\n",
      "[18,   400/  446] train loss: 0.251 train accuracy: 0.977\n",
      "epoch: 18 validation accuracy: 0.955\n",
      "[19,   100/  446] train loss: 0.304 train accuracy: 0.969\n",
      "[19,   200/  446] train loss: 0.298 train accuracy: 0.969\n",
      "[19,   300/  446] train loss: 0.330 train accuracy: 0.961\n",
      "[19,   400/  446] train loss: 0.349 train accuracy: 0.945\n",
      "epoch: 19 validation accuracy: 0.956\n",
      "[20,   100/  446] train loss: 0.324 train accuracy: 0.961\n",
      "[20,   200/  446] train loss: 0.213 train accuracy: 0.984\n",
      "[20,   300/  446] train loss: 0.301 train accuracy: 0.977\n",
      "[20,   400/  446] train loss: 0.312 train accuracy: 0.969\n",
      "epoch: 20 validation accuracy: 0.956\n",
      "Training with hparamsT=5, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.100\n",
      "[1,   100/  446] train loss: 1.324 train accuracy: 0.992\n",
      "[1,   200/  446] train loss: 0.912 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 0.884 train accuracy: 1.000\n",
      "[1,   400/  446] train loss: 0.711 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.293\n",
      "[2,   100/  446] train loss: 0.582 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.532 train accuracy: 1.000\n",
      "[2,   300/  446] train loss: 0.518 train accuracy: 0.992\n",
      "[2,   400/  446] train loss: 0.482 train accuracy: 0.992\n",
      "epoch: 2 validation accuracy: 0.424\n",
      "[3,   100/  446] train loss: 0.441 train accuracy: 1.000\n",
      "[3,   200/  446] train loss: 0.373 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.354 train accuracy: 1.000\n",
      "[3,   400/  446] train loss: 0.347 train accuracy: 0.992\n",
      "epoch: 3 validation accuracy: 0.577\n",
      "[4,   100/  446] train loss: 0.386 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.279 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.277 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.260 train accuracy: 0.992\n",
      "epoch: 4 validation accuracy: 0.620\n",
      "[5,   100/  446] train loss: 0.270 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.182 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.213 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.243 train accuracy: 0.992\n",
      "epoch: 5 validation accuracy: 0.670\n",
      "[6,   100/  446] train loss: 0.259 train accuracy: 0.992\n",
      "[6,   200/  446] train loss: 0.195 train accuracy: 1.000\n",
      "[6,   300/  446] train loss: 0.197 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.170 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.761\n",
      "[7,   100/  446] train loss: 0.212 train accuracy: 0.977\n",
      "[7,   200/  446] train loss: 0.183 train accuracy: 0.992\n",
      "[7,   300/  446] train loss: 0.192 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.178 train accuracy: 0.992\n",
      "epoch: 7 validation accuracy: 0.811\n",
      "[8,   100/  446] train loss: 0.189 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.164 train accuracy: 0.992\n",
      "[8,   300/  446] train loss: 0.174 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.145 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.820\n",
      "[9,   100/  446] train loss: 0.126 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.133 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.133 train accuracy: 0.992\n",
      "[9,   400/  446] train loss: 0.163 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.839\n",
      "[10,   100/  446] train loss: 0.126 train accuracy: 0.992\n",
      "[10,   200/  446] train loss: 0.099 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.111 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.132 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.858\n",
      "[11,   100/  446] train loss: 0.118 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.127 train accuracy: 0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,   300/  446] train loss: 0.134 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.109 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.866\n",
      "[12,   100/  446] train loss: 0.115 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.101 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.103 train accuracy: 1.000\n",
      "[12,   400/  446] train loss: 0.112 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.871\n",
      "[13,   100/  446] train loss: 0.106 train accuracy: 1.000\n",
      "[13,   200/  446] train loss: 0.093 train accuracy: 0.992\n",
      "[13,   300/  446] train loss: 0.122 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.100 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.881\n",
      "[14,   100/  446] train loss: 0.109 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.106 train accuracy: 1.000\n",
      "[14,   300/  446] train loss: 0.101 train accuracy: 0.992\n",
      "[14,   400/  446] train loss: 0.093 train accuracy: 1.000\n",
      "epoch: 14 validation accuracy: 0.894\n",
      "[15,   100/  446] train loss: 0.098 train accuracy: 0.992\n",
      "[15,   200/  446] train loss: 0.110 train accuracy: 1.000\n",
      "[15,   300/  446] train loss: 0.098 train accuracy: 0.977\n",
      "[15,   400/  446] train loss: 0.099 train accuracy: 0.992\n",
      "epoch: 15 validation accuracy: 0.895\n",
      "[16,   100/  446] train loss: 0.097 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.072 train accuracy: 0.992\n",
      "[16,   300/  446] train loss: 0.082 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.090 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.900\n",
      "[17,   100/  446] train loss: 0.086 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.088 train accuracy: 1.000\n",
      "[17,   300/  446] train loss: 0.075 train accuracy: 0.984\n",
      "[17,   400/  446] train loss: 0.086 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.899\n",
      "[18,   100/  446] train loss: 0.079 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.088 train accuracy: 0.992\n",
      "[18,   300/  446] train loss: 0.083 train accuracy: 0.992\n",
      "[18,   400/  446] train loss: 0.074 train accuracy: 0.992\n",
      "epoch: 18 validation accuracy: 0.903\n",
      "[19,   100/  446] train loss: 0.076 train accuracy: 0.992\n",
      "[19,   200/  446] train loss: 0.080 train accuracy: 0.992\n",
      "[19,   300/  446] train loss: 0.082 train accuracy: 0.992\n",
      "[19,   400/  446] train loss: 0.075 train accuracy: 1.000\n",
      "epoch: 19 validation accuracy: 0.909\n",
      "[20,   100/  446] train loss: 0.076 train accuracy: 0.992\n",
      "[20,   200/  446] train loss: 0.075 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.064 train accuracy: 0.992\n",
      "[20,   400/  446] train loss: 0.073 train accuracy: 0.992\n",
      "epoch: 20 validation accuracy: 0.907\n",
      "epoch: 0 validation accuracy: 0.907\n",
      "[1,   100/  446] train loss: 0.908 train accuracy: 0.953\n",
      "[1,   200/  446] train loss: 0.834 train accuracy: 0.961\n",
      "[1,   300/  446] train loss: 0.881 train accuracy: 0.953\n",
      "[1,   400/  446] train loss: 0.700 train accuracy: 0.953\n",
      "epoch: 1 validation accuracy: 0.969\n",
      "[2,   100/  446] train loss: 0.751 train accuracy: 0.938\n",
      "[2,   200/  446] train loss: 0.548 train accuracy: 0.945\n",
      "[2,   300/  446] train loss: 0.777 train accuracy: 0.945\n",
      "[2,   400/  446] train loss: 0.685 train accuracy: 0.961\n",
      "epoch: 2 validation accuracy: 0.971\n",
      "[3,   100/  446] train loss: 0.756 train accuracy: 0.953\n",
      "[3,   200/  446] train loss: 0.543 train accuracy: 0.992\n",
      "[3,   300/  446] train loss: 0.761 train accuracy: 0.977\n",
      "[3,   400/  446] train loss: 0.717 train accuracy: 0.961\n",
      "epoch: 3 validation accuracy: 0.969\n",
      "[4,   100/  446] train loss: 0.625 train accuracy: 0.977\n",
      "[4,   200/  446] train loss: 0.626 train accuracy: 0.953\n",
      "[4,   300/  446] train loss: 0.550 train accuracy: 0.953\n",
      "[4,   400/  446] train loss: 0.716 train accuracy: 0.953\n",
      "epoch: 4 validation accuracy: 0.970\n",
      "[5,   100/  446] train loss: 0.805 train accuracy: 0.945\n",
      "[5,   200/  446] train loss: 0.655 train accuracy: 0.977\n",
      "[5,   300/  446] train loss: 0.597 train accuracy: 0.969\n",
      "[5,   400/  446] train loss: 0.654 train accuracy: 0.977\n",
      "epoch: 5 validation accuracy: 0.971\n",
      "[6,   100/  446] train loss: 0.686 train accuracy: 0.945\n",
      "[6,   200/  446] train loss: 0.691 train accuracy: 0.969\n",
      "[6,   300/  446] train loss: 0.674 train accuracy: 0.961\n",
      "[6,   400/  446] train loss: 0.560 train accuracy: 0.969\n",
      "epoch: 6 validation accuracy: 0.971\n",
      "[7,   100/  446] train loss: 0.597 train accuracy: 0.977\n",
      "[7,   200/  446] train loss: 0.635 train accuracy: 0.969\n",
      "[7,   300/  446] train loss: 0.679 train accuracy: 0.977\n",
      "[7,   400/  446] train loss: 0.670 train accuracy: 0.977\n",
      "epoch: 7 validation accuracy: 0.971\n",
      "[8,   100/  446] train loss: 0.585 train accuracy: 0.984\n",
      "[8,   200/  446] train loss: 0.581 train accuracy: 0.969\n",
      "[8,   300/  446] train loss: 0.582 train accuracy: 0.992\n",
      "[8,   400/  446] train loss: 0.518 train accuracy: 0.984\n",
      "epoch: 8 validation accuracy: 0.972\n",
      "[9,   100/  446] train loss: 0.663 train accuracy: 0.984\n",
      "[9,   200/  446] train loss: 0.489 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.563 train accuracy: 0.953\n",
      "[9,   400/  446] train loss: 0.610 train accuracy: 0.953\n",
      "epoch: 9 validation accuracy: 0.972\n",
      "[10,   100/  446] train loss: 0.598 train accuracy: 0.977\n",
      "[10,   200/  446] train loss: 0.623 train accuracy: 0.992\n",
      "[10,   300/  446] train loss: 0.619 train accuracy: 0.969\n",
      "[10,   400/  446] train loss: 0.585 train accuracy: 0.977\n",
      "epoch: 10 validation accuracy: 0.971\n",
      "[11,   100/  446] train loss: 0.503 train accuracy: 0.984\n",
      "[11,   200/  446] train loss: 0.610 train accuracy: 0.992\n",
      "[11,   300/  446] train loss: 0.594 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.635 train accuracy: 0.984\n",
      "epoch: 11 validation accuracy: 0.972\n",
      "[12,   100/  446] train loss: 0.535 train accuracy: 0.977\n",
      "[12,   200/  446] train loss: 0.570 train accuracy: 0.977\n",
      "[12,   300/  446] train loss: 0.589 train accuracy: 0.977\n",
      "[12,   400/  446] train loss: 0.495 train accuracy: 0.984\n",
      "epoch: 12 validation accuracy: 0.972\n",
      "[13,   100/  446] train loss: 0.573 train accuracy: 0.953\n",
      "[13,   200/  446] train loss: 0.586 train accuracy: 0.969\n",
      "[13,   300/  446] train loss: 0.555 train accuracy: 0.984\n",
      "[13,   400/  446] train loss: 0.614 train accuracy: 0.984\n",
      "epoch: 13 validation accuracy: 0.972\n",
      "[14,   100/  446] train loss: 0.666 train accuracy: 0.961\n",
      "[14,   200/  446] train loss: 0.569 train accuracy: 0.992\n",
      "[14,   300/  446] train loss: 0.694 train accuracy: 0.969\n",
      "[14,   400/  446] train loss: 0.631 train accuracy: 0.969\n",
      "epoch: 14 validation accuracy: 0.971\n",
      "[15,   100/  446] train loss: 0.673 train accuracy: 0.953\n",
      "[15,   200/  446] train loss: 0.572 train accuracy: 0.969\n",
      "[15,   300/  446] train loss: 0.535 train accuracy: 0.969\n",
      "[15,   400/  446] train loss: 0.578 train accuracy: 1.000\n",
      "epoch: 15 validation accuracy: 0.972\n",
      "[16,   100/  446] train loss: 0.586 train accuracy: 0.961\n",
      "[16,   200/  446] train loss: 0.705 train accuracy: 0.945\n",
      "[16,   300/  446] train loss: 0.537 train accuracy: 0.969\n",
      "[16,   400/  446] train loss: 0.563 train accuracy: 0.961\n",
      "epoch: 16 validation accuracy: 0.972\n",
      "[17,   100/  446] train loss: 0.564 train accuracy: 0.961\n",
      "[17,   200/  446] train loss: 0.608 train accuracy: 0.969\n",
      "[17,   300/  446] train loss: 0.468 train accuracy: 0.984\n",
      "[17,   400/  446] train loss: 0.662 train accuracy: 0.961\n",
      "epoch: 17 validation accuracy: 0.972\n",
      "[18,   100/  446] train loss: 0.684 train accuracy: 0.984\n",
      "[18,   200/  446] train loss: 0.570 train accuracy: 0.977\n",
      "[18,   300/  446] train loss: 0.605 train accuracy: 0.969\n",
      "[18,   400/  446] train loss: 0.624 train accuracy: 0.961\n",
      "epoch: 18 validation accuracy: 0.973\n",
      "[19,   100/  446] train loss: 0.622 train accuracy: 0.961\n",
      "[19,   200/  446] train loss: 0.591 train accuracy: 0.984\n",
      "[19,   300/  446] train loss: 0.538 train accuracy: 0.961\n",
      "[19,   400/  446] train loss: 0.546 train accuracy: 0.961\n",
      "epoch: 19 validation accuracy: 0.972\n",
      "[20,   100/  446] train loss: 0.651 train accuracy: 0.992\n",
      "[20,   200/  446] train loss: 0.626 train accuracy: 0.992\n",
      "[20,   300/  446] train loss: 0.662 train accuracy: 0.969\n",
      "[20,   400/  446] train loss: 0.590 train accuracy: 0.984\n",
      "epoch: 20 validation accuracy: 0.972\n",
      "Training with hparamsT=10, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.100\n",
      "[1,   100/  446] train loss: 1.640 train accuracy: 0.992\n",
      "[1,   200/  446] train loss: 1.197 train accuracy: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300/  446] train loss: 1.058 train accuracy: 0.992\n",
      "[1,   400/  446] train loss: 0.779 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.342\n",
      "[2,   100/  446] train loss: 0.715 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.564 train accuracy: 1.000\n",
      "[2,   300/  446] train loss: 0.593 train accuracy: 1.000\n",
      "[2,   400/  446] train loss: 0.552 train accuracy: 0.992\n",
      "epoch: 2 validation accuracy: 0.499\n",
      "[3,   100/  446] train loss: 0.442 train accuracy: 1.000\n",
      "[3,   200/  446] train loss: 0.402 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.398 train accuracy: 1.000\n",
      "[3,   400/  446] train loss: 0.275 train accuracy: 0.992\n",
      "epoch: 3 validation accuracy: 0.659\n",
      "[4,   100/  446] train loss: 0.372 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.300 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.314 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.308 train accuracy: 0.992\n",
      "epoch: 4 validation accuracy: 0.752\n",
      "[5,   100/  446] train loss: 0.259 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.222 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.239 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.226 train accuracy: 0.984\n",
      "epoch: 5 validation accuracy: 0.795\n",
      "[6,   100/  446] train loss: 0.235 train accuracy: 1.000\n",
      "[6,   200/  446] train loss: 0.208 train accuracy: 1.000\n",
      "[6,   300/  446] train loss: 0.215 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.192 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.822\n",
      "[7,   100/  446] train loss: 0.212 train accuracy: 1.000\n",
      "[7,   200/  446] train loss: 0.202 train accuracy: 0.992\n",
      "[7,   300/  446] train loss: 0.188 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.186 train accuracy: 0.992\n",
      "epoch: 7 validation accuracy: 0.860\n",
      "[8,   100/  446] train loss: 0.185 train accuracy: 0.992\n",
      "[8,   200/  446] train loss: 0.180 train accuracy: 0.992\n",
      "[8,   300/  446] train loss: 0.195 train accuracy: 0.992\n",
      "[8,   400/  446] train loss: 0.154 train accuracy: 0.992\n",
      "epoch: 8 validation accuracy: 0.866\n",
      "[9,   100/  446] train loss: 0.144 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.147 train accuracy: 0.992\n",
      "[9,   300/  446] train loss: 0.138 train accuracy: 0.992\n",
      "[9,   400/  446] train loss: 0.168 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.885\n",
      "[10,   100/  446] train loss: 0.142 train accuracy: 0.992\n",
      "[10,   200/  446] train loss: 0.122 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.121 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.140 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.889\n",
      "[11,   100/  446] train loss: 0.134 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.149 train accuracy: 0.992\n",
      "[11,   300/  446] train loss: 0.145 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.116 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.913\n",
      "[12,   100/  446] train loss: 0.127 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.113 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.130 train accuracy: 1.000\n",
      "[12,   400/  446] train loss: 0.122 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.913\n",
      "[13,   100/  446] train loss: 0.107 train accuracy: 1.000\n",
      "[13,   200/  446] train loss: 0.109 train accuracy: 0.984\n",
      "[13,   300/  446] train loss: 0.121 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.108 train accuracy: 0.992\n",
      "epoch: 13 validation accuracy: 0.918\n",
      "[14,   100/  446] train loss: 0.124 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.111 train accuracy: 1.000\n",
      "[14,   300/  446] train loss: 0.136 train accuracy: 0.992\n",
      "[14,   400/  446] train loss: 0.096 train accuracy: 1.000\n",
      "epoch: 14 validation accuracy: 0.919\n",
      "[15,   100/  446] train loss: 0.110 train accuracy: 0.984\n",
      "[15,   200/  446] train loss: 0.113 train accuracy: 1.000\n",
      "[15,   300/  446] train loss: 0.112 train accuracy: 0.984\n",
      "[15,   400/  446] train loss: 0.123 train accuracy: 0.992\n",
      "epoch: 15 validation accuracy: 0.924\n",
      "[16,   100/  446] train loss: 0.115 train accuracy: 0.992\n",
      "[16,   200/  446] train loss: 0.094 train accuracy: 0.984\n",
      "[16,   300/  446] train loss: 0.102 train accuracy: 0.992\n",
      "[16,   400/  446] train loss: 0.096 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.917\n",
      "[17,   100/  446] train loss: 0.100 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.113 train accuracy: 0.992\n",
      "[17,   300/  446] train loss: 0.084 train accuracy: 0.984\n",
      "[17,   400/  446] train loss: 0.102 train accuracy: 0.992\n",
      "epoch: 17 validation accuracy: 0.931\n",
      "[18,   100/  446] train loss: 0.090 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.102 train accuracy: 0.992\n",
      "[18,   300/  446] train loss: 0.091 train accuracy: 0.992\n",
      "[18,   400/  446] train loss: 0.088 train accuracy: 0.992\n",
      "epoch: 18 validation accuracy: 0.930\n",
      "[19,   100/  446] train loss: 0.098 train accuracy: 0.992\n",
      "[19,   200/  446] train loss: 0.103 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.100 train accuracy: 0.992\n",
      "[19,   400/  446] train loss: 0.082 train accuracy: 1.000\n",
      "epoch: 19 validation accuracy: 0.930\n",
      "[20,   100/  446] train loss: 0.087 train accuracy: 0.992\n",
      "[20,   200/  446] train loss: 0.088 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.082 train accuracy: 0.992\n",
      "[20,   400/  446] train loss: 0.084 train accuracy: 0.992\n",
      "epoch: 20 validation accuracy: 0.932\n",
      "epoch: 0 validation accuracy: 0.932\n",
      "[1,   100/  446] train loss: 0.966 train accuracy: 0.953\n",
      "[1,   200/  446] train loss: 0.914 train accuracy: 0.977\n",
      "[1,   300/  446] train loss: 0.880 train accuracy: 0.977\n",
      "[1,   400/  446] train loss: 0.828 train accuracy: 0.961\n",
      "epoch: 1 validation accuracy: 0.970\n",
      "[2,   100/  446] train loss: 0.792 train accuracy: 0.953\n",
      "[2,   200/  446] train loss: 0.715 train accuracy: 0.969\n",
      "[2,   300/  446] train loss: 0.764 train accuracy: 0.961\n",
      "[2,   400/  446] train loss: 0.864 train accuracy: 0.977\n",
      "epoch: 2 validation accuracy: 0.973\n",
      "[3,   100/  446] train loss: 0.858 train accuracy: 0.977\n",
      "[3,   200/  446] train loss: 0.617 train accuracy: 0.992\n",
      "[3,   300/  446] train loss: 0.845 train accuracy: 0.984\n",
      "[3,   400/  446] train loss: 0.813 train accuracy: 0.953\n",
      "epoch: 3 validation accuracy: 0.972\n",
      "[4,   100/  446] train loss: 0.820 train accuracy: 0.977\n",
      "[4,   200/  446] train loss: 0.761 train accuracy: 0.969\n",
      "[4,   300/  446] train loss: 0.719 train accuracy: 0.969\n",
      "[4,   400/  446] train loss: 0.923 train accuracy: 0.961\n",
      "epoch: 4 validation accuracy: 0.972\n",
      "[5,   100/  446] train loss: 0.887 train accuracy: 0.969\n",
      "[5,   200/  446] train loss: 0.816 train accuracy: 0.977\n",
      "[5,   300/  446] train loss: 0.714 train accuracy: 0.977\n",
      "[5,   400/  446] train loss: 0.844 train accuracy: 0.984\n",
      "epoch: 5 validation accuracy: 0.973\n",
      "[6,   100/  446] train loss: 0.791 train accuracy: 0.977\n",
      "[6,   200/  446] train loss: 0.835 train accuracy: 0.953\n",
      "[6,   300/  446] train loss: 0.799 train accuracy: 0.961\n",
      "[6,   400/  446] train loss: 0.748 train accuracy: 0.969\n",
      "epoch: 6 validation accuracy: 0.971\n",
      "[7,   100/  446] train loss: 0.682 train accuracy: 0.961\n",
      "[7,   200/  446] train loss: 0.779 train accuracy: 0.984\n",
      "[7,   300/  446] train loss: 0.722 train accuracy: 0.977\n",
      "[7,   400/  446] train loss: 0.835 train accuracy: 0.969\n",
      "epoch: 7 validation accuracy: 0.973\n",
      "[8,   100/  446] train loss: 0.708 train accuracy: 0.992\n",
      "[8,   200/  446] train loss: 0.705 train accuracy: 0.977\n",
      "[8,   300/  446] train loss: 0.722 train accuracy: 0.984\n",
      "[8,   400/  446] train loss: 0.597 train accuracy: 0.984\n",
      "epoch: 8 validation accuracy: 0.974\n",
      "[9,   100/  446] train loss: 0.721 train accuracy: 0.984\n",
      "[9,   200/  446] train loss: 0.724 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.666 train accuracy: 0.953\n",
      "[9,   400/  446] train loss: 0.812 train accuracy: 0.961\n",
      "epoch: 9 validation accuracy: 0.973\n",
      "[10,   100/  446] train loss: 0.743 train accuracy: 0.984\n",
      "[10,   200/  446] train loss: 0.834 train accuracy: 0.992\n",
      "[10,   300/  446] train loss: 0.658 train accuracy: 0.969\n",
      "[10,   400/  446] train loss: 0.744 train accuracy: 0.977\n",
      "epoch: 10 validation accuracy: 0.973\n",
      "[11,   100/  446] train loss: 0.685 train accuracy: 0.984\n",
      "[11,   200/  446] train loss: 0.710 train accuracy: 0.969\n",
      "[11,   300/  446] train loss: 0.706 train accuracy: 0.992\n",
      "[11,   400/  446] train loss: 0.857 train accuracy: 0.984\n",
      "epoch: 11 validation accuracy: 0.973\n",
      "[12,   100/  446] train loss: 0.665 train accuracy: 0.977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,   200/  446] train loss: 0.702 train accuracy: 0.984\n",
      "[12,   300/  446] train loss: 0.700 train accuracy: 0.977\n",
      "[12,   400/  446] train loss: 0.639 train accuracy: 0.992\n",
      "epoch: 12 validation accuracy: 0.975\n",
      "[13,   100/  446] train loss: 0.669 train accuracy: 0.961\n",
      "[13,   200/  446] train loss: 0.773 train accuracy: 0.961\n",
      "[13,   300/  446] train loss: 0.649 train accuracy: 0.992\n",
      "[13,   400/  446] train loss: 0.810 train accuracy: 0.992\n",
      "epoch: 13 validation accuracy: 0.974\n",
      "[14,   100/  446] train loss: 0.767 train accuracy: 0.961\n",
      "[14,   200/  446] train loss: 0.718 train accuracy: 0.992\n",
      "[14,   300/  446] train loss: 0.819 train accuracy: 0.961\n",
      "[14,   400/  446] train loss: 0.727 train accuracy: 0.977\n",
      "epoch: 14 validation accuracy: 0.974\n",
      "[15,   100/  446] train loss: 0.791 train accuracy: 0.945\n",
      "[15,   200/  446] train loss: 0.718 train accuracy: 0.977\n",
      "[15,   300/  446] train loss: 0.673 train accuracy: 0.977\n",
      "[15,   400/  446] train loss: 0.740 train accuracy: 0.977\n",
      "epoch: 15 validation accuracy: 0.973\n",
      "[16,   100/  446] train loss: 0.734 train accuracy: 0.961\n",
      "[16,   200/  446] train loss: 0.840 train accuracy: 0.953\n",
      "[16,   300/  446] train loss: 0.741 train accuracy: 0.961\n",
      "[16,   400/  446] train loss: 0.694 train accuracy: 0.977\n",
      "epoch: 16 validation accuracy: 0.975\n",
      "[17,   100/  446] train loss: 0.722 train accuracy: 0.961\n",
      "[17,   200/  446] train loss: 0.826 train accuracy: 0.969\n",
      "[17,   300/  446] train loss: 0.756 train accuracy: 0.977\n",
      "[17,   400/  446] train loss: 0.772 train accuracy: 0.961\n",
      "epoch: 17 validation accuracy: 0.974\n",
      "[18,   100/  446] train loss: 0.822 train accuracy: 0.977\n",
      "[18,   200/  446] train loss: 0.755 train accuracy: 0.984\n",
      "[18,   300/  446] train loss: 0.750 train accuracy: 0.984\n",
      "[18,   400/  446] train loss: 0.731 train accuracy: 0.984\n",
      "epoch: 18 validation accuracy: 0.973\n",
      "[19,   100/  446] train loss: 0.789 train accuracy: 0.953\n",
      "[19,   200/  446] train loss: 0.717 train accuracy: 0.984\n",
      "[19,   300/  446] train loss: 0.616 train accuracy: 0.969\n",
      "[19,   400/  446] train loss: 0.656 train accuracy: 0.969\n",
      "epoch: 19 validation accuracy: 0.973\n",
      "[20,   100/  446] train loss: 0.818 train accuracy: 0.984\n",
      "[20,   200/  446] train loss: 0.784 train accuracy: 0.984\n",
      "[20,   300/  446] train loss: 0.771 train accuracy: 0.977\n",
      "[20,   400/  446] train loss: 0.741 train accuracy: 0.984\n",
      "epoch: 20 validation accuracy: 0.973\n",
      "Training with hparamsT=15, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.100\n",
      "[1,   100/  446] train loss: 1.833 train accuracy: 0.984\n",
      "[1,   200/  446] train loss: 1.331 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 1.083 train accuracy: 0.992\n",
      "[1,   400/  446] train loss: 0.814 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.369\n",
      "[2,   100/  446] train loss: 0.680 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.565 train accuracy: 1.000\n",
      "[2,   300/  446] train loss: 0.550 train accuracy: 0.992\n",
      "[2,   400/  446] train loss: 0.552 train accuracy: 0.992\n",
      "epoch: 2 validation accuracy: 0.534\n",
      "[3,   100/  446] train loss: 0.444 train accuracy: 0.992\n",
      "[3,   200/  446] train loss: 0.363 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.373 train accuracy: 1.000\n",
      "[3,   400/  446] train loss: 0.305 train accuracy: 0.992\n",
      "epoch: 3 validation accuracy: 0.708\n",
      "[4,   100/  446] train loss: 0.365 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.302 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.291 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.281 train accuracy: 0.992\n",
      "epoch: 4 validation accuracy: 0.778\n",
      "[5,   100/  446] train loss: 0.258 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.198 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.245 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.223 train accuracy: 0.984\n",
      "epoch: 5 validation accuracy: 0.811\n",
      "[6,   100/  446] train loss: 0.240 train accuracy: 0.992\n",
      "[6,   200/  446] train loss: 0.195 train accuracy: 1.000\n",
      "[6,   300/  446] train loss: 0.191 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.187 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.860\n",
      "[7,   100/  446] train loss: 0.202 train accuracy: 0.977\n",
      "[7,   200/  446] train loss: 0.196 train accuracy: 0.992\n",
      "[7,   300/  446] train loss: 0.179 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.176 train accuracy: 0.992\n",
      "epoch: 7 validation accuracy: 0.873\n",
      "[8,   100/  446] train loss: 0.169 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.201 train accuracy: 0.984\n",
      "[8,   300/  446] train loss: 0.206 train accuracy: 0.992\n",
      "[8,   400/  446] train loss: 0.155 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.894\n",
      "[9,   100/  446] train loss: 0.141 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.160 train accuracy: 0.992\n",
      "[9,   300/  446] train loss: 0.148 train accuracy: 0.992\n",
      "[9,   400/  446] train loss: 0.176 train accuracy: 0.992\n",
      "epoch: 9 validation accuracy: 0.903\n",
      "[10,   100/  446] train loss: 0.137 train accuracy: 0.984\n",
      "[10,   200/  446] train loss: 0.129 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.117 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.130 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.919\n",
      "[11,   100/  446] train loss: 0.129 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.131 train accuracy: 0.992\n",
      "[11,   300/  446] train loss: 0.129 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.119 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.922\n",
      "[12,   100/  446] train loss: 0.125 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.107 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.118 train accuracy: 1.000\n",
      "[12,   400/  446] train loss: 0.124 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.921\n",
      "[13,   100/  446] train loss: 0.108 train accuracy: 1.000\n",
      "[13,   200/  446] train loss: 0.105 train accuracy: 0.984\n",
      "[13,   300/  446] train loss: 0.132 train accuracy: 0.992\n",
      "[13,   400/  446] train loss: 0.120 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.926\n",
      "[14,   100/  446] train loss: 0.123 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.117 train accuracy: 1.000\n",
      "[14,   300/  446] train loss: 0.122 train accuracy: 0.992\n",
      "[14,   400/  446] train loss: 0.099 train accuracy: 1.000\n",
      "epoch: 14 validation accuracy: 0.930\n",
      "[15,   100/  446] train loss: 0.112 train accuracy: 0.977\n",
      "[15,   200/  446] train loss: 0.106 train accuracy: 1.000\n",
      "[15,   300/  446] train loss: 0.105 train accuracy: 0.969\n",
      "[15,   400/  446] train loss: 0.109 train accuracy: 0.992\n",
      "epoch: 15 validation accuracy: 0.928\n",
      "[16,   100/  446] train loss: 0.103 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.096 train accuracy: 0.984\n",
      "[16,   300/  446] train loss: 0.097 train accuracy: 0.992\n",
      "[16,   400/  446] train loss: 0.092 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.929\n",
      "[17,   100/  446] train loss: 0.103 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.104 train accuracy: 1.000\n",
      "[17,   300/  446] train loss: 0.088 train accuracy: 0.984\n",
      "[17,   400/  446] train loss: 0.105 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.938\n",
      "[18,   100/  446] train loss: 0.087 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.103 train accuracy: 0.992\n",
      "[18,   300/  446] train loss: 0.095 train accuracy: 0.992\n",
      "[18,   400/  446] train loss: 0.092 train accuracy: 0.992\n",
      "epoch: 18 validation accuracy: 0.938\n",
      "[19,   100/  446] train loss: 0.097 train accuracy: 0.992\n",
      "[19,   200/  446] train loss: 0.092 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.092 train accuracy: 0.992\n",
      "[19,   400/  446] train loss: 0.088 train accuracy: 0.984\n",
      "epoch: 19 validation accuracy: 0.939\n",
      "[20,   100/  446] train loss: 0.083 train accuracy: 1.000\n",
      "[20,   200/  446] train loss: 0.086 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.085 train accuracy: 0.984\n",
      "[20,   400/  446] train loss: 0.078 train accuracy: 0.992\n",
      "epoch: 20 validation accuracy: 0.939\n",
      "epoch: 0 validation accuracy: 0.939\n",
      "[1,   100/  446] train loss: 0.869 train accuracy: 0.945\n",
      "[1,   200/  446] train loss: 0.861 train accuracy: 0.969\n",
      "[1,   300/  446] train loss: 0.814 train accuracy: 0.992\n",
      "[1,   400/  446] train loss: 0.767 train accuracy: 0.953\n",
      "epoch: 1 validation accuracy: 0.975\n",
      "[2,   100/  446] train loss: 0.729 train accuracy: 0.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   200/  446] train loss: 0.645 train accuracy: 0.969\n",
      "[2,   300/  446] train loss: 0.737 train accuracy: 0.961\n",
      "[2,   400/  446] train loss: 0.800 train accuracy: 0.969\n",
      "epoch: 2 validation accuracy: 0.975\n",
      "[3,   100/  446] train loss: 0.803 train accuracy: 0.969\n",
      "[3,   200/  446] train loss: 0.567 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.764 train accuracy: 0.992\n",
      "[3,   400/  446] train loss: 0.765 train accuracy: 0.945\n",
      "epoch: 3 validation accuracy: 0.974\n",
      "[4,   100/  446] train loss: 0.742 train accuracy: 0.969\n",
      "[4,   200/  446] train loss: 0.640 train accuracy: 0.969\n",
      "[4,   300/  446] train loss: 0.605 train accuracy: 0.984\n",
      "[4,   400/  446] train loss: 0.806 train accuracy: 0.961\n",
      "epoch: 4 validation accuracy: 0.975\n",
      "[5,   100/  446] train loss: 0.865 train accuracy: 0.969\n",
      "[5,   200/  446] train loss: 0.816 train accuracy: 0.969\n",
      "[5,   300/  446] train loss: 0.700 train accuracy: 0.961\n",
      "[5,   400/  446] train loss: 0.717 train accuracy: 0.984\n",
      "epoch: 5 validation accuracy: 0.974\n",
      "[6,   100/  446] train loss: 0.742 train accuracy: 0.977\n",
      "[6,   200/  446] train loss: 0.700 train accuracy: 0.961\n",
      "[6,   300/  446] train loss: 0.724 train accuracy: 0.953\n",
      "[6,   400/  446] train loss: 0.655 train accuracy: 0.969\n",
      "epoch: 6 validation accuracy: 0.973\n",
      "[7,   100/  446] train loss: 0.680 train accuracy: 0.953\n",
      "[7,   200/  446] train loss: 0.740 train accuracy: 0.984\n",
      "[7,   300/  446] train loss: 0.686 train accuracy: 0.984\n",
      "[7,   400/  446] train loss: 0.794 train accuracy: 0.969\n",
      "epoch: 7 validation accuracy: 0.975\n",
      "[8,   100/  446] train loss: 0.705 train accuracy: 0.992\n",
      "[8,   200/  446] train loss: 0.707 train accuracy: 0.977\n",
      "[8,   300/  446] train loss: 0.710 train accuracy: 0.984\n",
      "[8,   400/  446] train loss: 0.558 train accuracy: 0.984\n",
      "epoch: 8 validation accuracy: 0.974\n",
      "[9,   100/  446] train loss: 0.719 train accuracy: 0.984\n",
      "[9,   200/  446] train loss: 0.631 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.592 train accuracy: 0.961\n",
      "[9,   400/  446] train loss: 0.785 train accuracy: 0.977\n",
      "epoch: 9 validation accuracy: 0.975\n",
      "[10,   100/  446] train loss: 0.618 train accuracy: 0.984\n",
      "[10,   200/  446] train loss: 0.691 train accuracy: 0.992\n",
      "[10,   300/  446] train loss: 0.679 train accuracy: 0.945\n",
      "[10,   400/  446] train loss: 0.712 train accuracy: 0.969\n",
      "epoch: 10 validation accuracy: 0.976\n",
      "[11,   100/  446] train loss: 0.650 train accuracy: 0.992\n",
      "[11,   200/  446] train loss: 0.662 train accuracy: 0.984\n",
      "[11,   300/  446] train loss: 0.644 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.846 train accuracy: 0.984\n",
      "epoch: 11 validation accuracy: 0.975\n",
      "[12,   100/  446] train loss: 0.675 train accuracy: 0.977\n",
      "[12,   200/  446] train loss: 0.607 train accuracy: 0.984\n",
      "[12,   300/  446] train loss: 0.701 train accuracy: 0.969\n",
      "[12,   400/  446] train loss: 0.609 train accuracy: 0.992\n",
      "epoch: 12 validation accuracy: 0.976\n",
      "[13,   100/  446] train loss: 0.682 train accuracy: 0.961\n",
      "[13,   200/  446] train loss: 0.679 train accuracy: 0.961\n",
      "[13,   300/  446] train loss: 0.630 train accuracy: 0.984\n",
      "[13,   400/  446] train loss: 0.712 train accuracy: 0.992\n",
      "epoch: 13 validation accuracy: 0.977\n",
      "[14,   100/  446] train loss: 0.743 train accuracy: 0.945\n",
      "[14,   200/  446] train loss: 0.646 train accuracy: 0.969\n",
      "[14,   300/  446] train loss: 0.743 train accuracy: 0.984\n",
      "[14,   400/  446] train loss: 0.732 train accuracy: 0.977\n",
      "epoch: 14 validation accuracy: 0.975\n",
      "[15,   100/  446] train loss: 0.730 train accuracy: 0.961\n",
      "[15,   200/  446] train loss: 0.646 train accuracy: 0.977\n",
      "[15,   300/  446] train loss: 0.589 train accuracy: 0.961\n",
      "[15,   400/  446] train loss: 0.673 train accuracy: 1.000\n",
      "epoch: 15 validation accuracy: 0.976\n",
      "[16,   100/  446] train loss: 0.674 train accuracy: 0.961\n",
      "[16,   200/  446] train loss: 0.789 train accuracy: 0.945\n",
      "[16,   300/  446] train loss: 0.694 train accuracy: 0.969\n",
      "[16,   400/  446] train loss: 0.657 train accuracy: 0.969\n",
      "epoch: 16 validation accuracy: 0.975\n",
      "[17,   100/  446] train loss: 0.719 train accuracy: 0.961\n",
      "[17,   200/  446] train loss: 0.760 train accuracy: 0.977\n",
      "[17,   300/  446] train loss: 0.633 train accuracy: 0.984\n",
      "[17,   400/  446] train loss: 0.725 train accuracy: 0.953\n",
      "epoch: 17 validation accuracy: 0.975\n",
      "[18,   100/  446] train loss: 0.713 train accuracy: 0.984\n",
      "[18,   200/  446] train loss: 0.659 train accuracy: 0.984\n",
      "[18,   300/  446] train loss: 0.746 train accuracy: 0.977\n",
      "[18,   400/  446] train loss: 0.689 train accuracy: 0.984\n",
      "epoch: 18 validation accuracy: 0.976\n",
      "[19,   100/  446] train loss: 0.750 train accuracy: 0.977\n",
      "[19,   200/  446] train loss: 0.734 train accuracy: 0.992\n",
      "[19,   300/  446] train loss: 0.671 train accuracy: 0.977\n",
      "[19,   400/  446] train loss: 0.629 train accuracy: 0.961\n",
      "epoch: 19 validation accuracy: 0.976\n",
      "[20,   100/  446] train loss: 0.777 train accuracy: 0.977\n",
      "[20,   200/  446] train loss: 0.718 train accuracy: 0.992\n",
      "[20,   300/  446] train loss: 0.693 train accuracy: 0.977\n",
      "[20,   400/  446] train loss: 0.755 train accuracy: 0.984\n",
      "epoch: 20 validation accuracy: 0.975\n",
      "Training with hparamsT=20, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.100\n",
      "[1,   100/  446] train loss: 1.797 train accuracy: 1.000\n",
      "[1,   200/  446] train loss: 1.382 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 1.084 train accuracy: 0.992\n",
      "[1,   400/  446] train loss: 0.808 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.349\n",
      "[2,   100/  446] train loss: 0.663 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.547 train accuracy: 1.000\n",
      "[2,   300/  446] train loss: 0.534 train accuracy: 1.000\n",
      "[2,   400/  446] train loss: 0.548 train accuracy: 0.992\n",
      "epoch: 2 validation accuracy: 0.540\n",
      "[3,   100/  446] train loss: 0.430 train accuracy: 0.992\n",
      "[3,   200/  446] train loss: 0.361 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.373 train accuracy: 1.000\n",
      "[3,   400/  446] train loss: 0.287 train accuracy: 0.992\n",
      "epoch: 3 validation accuracy: 0.712\n",
      "[4,   100/  446] train loss: 0.343 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.307 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.268 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.286 train accuracy: 0.992\n",
      "epoch: 4 validation accuracy: 0.786\n",
      "[5,   100/  446] train loss: 0.249 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.215 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.246 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.208 train accuracy: 0.992\n",
      "epoch: 5 validation accuracy: 0.823\n",
      "[6,   100/  446] train loss: 0.235 train accuracy: 0.992\n",
      "[6,   200/  446] train loss: 0.188 train accuracy: 1.000\n",
      "[6,   300/  446] train loss: 0.197 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.170 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.862\n",
      "[7,   100/  446] train loss: 0.202 train accuracy: 0.977\n",
      "[7,   200/  446] train loss: 0.196 train accuracy: 0.992\n",
      "[7,   300/  446] train loss: 0.167 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.177 train accuracy: 0.992\n",
      "epoch: 7 validation accuracy: 0.885\n",
      "[8,   100/  446] train loss: 0.152 train accuracy: 0.992\n",
      "[8,   200/  446] train loss: 0.177 train accuracy: 0.984\n",
      "[8,   300/  446] train loss: 0.211 train accuracy: 0.992\n",
      "[8,   400/  446] train loss: 0.166 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.897\n",
      "[9,   100/  446] train loss: 0.139 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.150 train accuracy: 0.992\n",
      "[9,   300/  446] train loss: 0.137 train accuracy: 0.992\n",
      "[9,   400/  446] train loss: 0.155 train accuracy: 0.992\n",
      "epoch: 9 validation accuracy: 0.909\n",
      "[10,   100/  446] train loss: 0.133 train accuracy: 0.984\n",
      "[10,   200/  446] train loss: 0.122 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.112 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.122 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.917\n",
      "[11,   100/  446] train loss: 0.123 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.127 train accuracy: 0.992\n",
      "[11,   300/  446] train loss: 0.114 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.120 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.924\n",
      "[12,   100/  446] train loss: 0.120 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.103 train accuracy: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,   300/  446] train loss: 0.116 train accuracy: 0.992\n",
      "[12,   400/  446] train loss: 0.128 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.929\n",
      "[13,   100/  446] train loss: 0.108 train accuracy: 1.000\n",
      "[13,   200/  446] train loss: 0.099 train accuracy: 0.992\n",
      "[13,   300/  446] train loss: 0.113 train accuracy: 0.992\n",
      "[13,   400/  446] train loss: 0.110 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.928\n",
      "[14,   100/  446] train loss: 0.119 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.101 train accuracy: 1.000\n",
      "[14,   300/  446] train loss: 0.118 train accuracy: 0.992\n",
      "[14,   400/  446] train loss: 0.095 train accuracy: 1.000\n",
      "epoch: 14 validation accuracy: 0.930\n",
      "[15,   100/  446] train loss: 0.111 train accuracy: 0.977\n",
      "[15,   200/  446] train loss: 0.103 train accuracy: 1.000\n",
      "[15,   300/  446] train loss: 0.103 train accuracy: 0.984\n",
      "[15,   400/  446] train loss: 0.106 train accuracy: 0.992\n",
      "epoch: 15 validation accuracy: 0.930\n",
      "[16,   100/  446] train loss: 0.110 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.092 train accuracy: 0.984\n",
      "[16,   300/  446] train loss: 0.098 train accuracy: 0.992\n",
      "[16,   400/  446] train loss: 0.089 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.934\n",
      "[17,   100/  446] train loss: 0.107 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.102 train accuracy: 0.992\n",
      "[17,   300/  446] train loss: 0.077 train accuracy: 0.984\n",
      "[17,   400/  446] train loss: 0.098 train accuracy: 0.992\n",
      "epoch: 17 validation accuracy: 0.939\n",
      "[18,   100/  446] train loss: 0.088 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.097 train accuracy: 0.992\n",
      "[18,   300/  446] train loss: 0.083 train accuracy: 0.992\n",
      "[18,   400/  446] train loss: 0.086 train accuracy: 0.992\n",
      "epoch: 18 validation accuracy: 0.941\n",
      "[19,   100/  446] train loss: 0.087 train accuracy: 0.992\n",
      "[19,   200/  446] train loss: 0.087 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.095 train accuracy: 0.992\n",
      "[19,   400/  446] train loss: 0.077 train accuracy: 0.992\n",
      "epoch: 19 validation accuracy: 0.941\n",
      "[20,   100/  446] train loss: 0.081 train accuracy: 0.992\n",
      "[20,   200/  446] train loss: 0.084 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.082 train accuracy: 0.992\n",
      "[20,   400/  446] train loss: 0.075 train accuracy: 0.992\n",
      "epoch: 20 validation accuracy: 0.942\n",
      "epoch: 0 validation accuracy: 0.942\n",
      "[1,   100/  446] train loss: 0.892 train accuracy: 0.953\n",
      "[1,   200/  446] train loss: 0.876 train accuracy: 0.969\n",
      "[1,   300/  446] train loss: 0.807 train accuracy: 0.984\n",
      "[1,   400/  446] train loss: 0.721 train accuracy: 0.969\n",
      "epoch: 1 validation accuracy: 0.975\n",
      "[2,   100/  446] train loss: 0.701 train accuracy: 0.953\n",
      "[2,   200/  446] train loss: 0.698 train accuracy: 0.969\n",
      "[2,   300/  446] train loss: 0.711 train accuracy: 0.961\n",
      "[2,   400/  446] train loss: 0.788 train accuracy: 0.969\n",
      "epoch: 2 validation accuracy: 0.975\n",
      "[3,   100/  446] train loss: 0.731 train accuracy: 0.969\n",
      "[3,   200/  446] train loss: 0.562 train accuracy: 0.992\n",
      "[3,   300/  446] train loss: 0.767 train accuracy: 0.992\n",
      "[3,   400/  446] train loss: 0.716 train accuracy: 0.938\n",
      "epoch: 3 validation accuracy: 0.976\n",
      "[4,   100/  446] train loss: 0.744 train accuracy: 0.969\n",
      "[4,   200/  446] train loss: 0.630 train accuracy: 0.961\n",
      "[4,   300/  446] train loss: 0.571 train accuracy: 0.969\n",
      "[4,   400/  446] train loss: 0.821 train accuracy: 0.969\n",
      "epoch: 4 validation accuracy: 0.975\n",
      "[5,   100/  446] train loss: 0.830 train accuracy: 0.969\n",
      "[5,   200/  446] train loss: 0.714 train accuracy: 0.969\n",
      "[5,   300/  446] train loss: 0.674 train accuracy: 0.953\n",
      "[5,   400/  446] train loss: 0.662 train accuracy: 0.984\n",
      "epoch: 5 validation accuracy: 0.975\n",
      "[6,   100/  446] train loss: 0.669 train accuracy: 0.969\n",
      "[6,   200/  446] train loss: 0.672 train accuracy: 0.953\n",
      "[6,   300/  446] train loss: 0.703 train accuracy: 0.961\n",
      "[6,   400/  446] train loss: 0.668 train accuracy: 0.977\n",
      "epoch: 6 validation accuracy: 0.975\n",
      "[7,   100/  446] train loss: 0.662 train accuracy: 0.961\n",
      "[7,   200/  446] train loss: 0.742 train accuracy: 0.984\n",
      "[7,   300/  446] train loss: 0.721 train accuracy: 0.977\n",
      "[7,   400/  446] train loss: 0.744 train accuracy: 0.977\n",
      "epoch: 7 validation accuracy: 0.975\n",
      "[8,   100/  446] train loss: 0.683 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.638 train accuracy: 0.984\n",
      "[8,   300/  446] train loss: 0.674 train accuracy: 0.984\n",
      "[8,   400/  446] train loss: 0.558 train accuracy: 0.992\n",
      "epoch: 8 validation accuracy: 0.976\n",
      "[9,   100/  446] train loss: 0.674 train accuracy: 0.984\n",
      "[9,   200/  446] train loss: 0.637 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.593 train accuracy: 0.961\n",
      "[9,   400/  446] train loss: 0.703 train accuracy: 0.977\n",
      "epoch: 9 validation accuracy: 0.975\n",
      "[10,   100/  446] train loss: 0.599 train accuracy: 0.984\n",
      "[10,   200/  446] train loss: 0.645 train accuracy: 0.984\n",
      "[10,   300/  446] train loss: 0.724 train accuracy: 0.961\n",
      "[10,   400/  446] train loss: 0.699 train accuracy: 0.977\n",
      "epoch: 10 validation accuracy: 0.976\n",
      "[11,   100/  446] train loss: 0.614 train accuracy: 0.992\n",
      "[11,   200/  446] train loss: 0.622 train accuracy: 0.977\n",
      "[11,   300/  446] train loss: 0.638 train accuracy: 0.984\n",
      "[11,   400/  446] train loss: 0.783 train accuracy: 0.992\n",
      "epoch: 11 validation accuracy: 0.976\n",
      "[12,   100/  446] train loss: 0.622 train accuracy: 0.977\n",
      "[12,   200/  446] train loss: 0.637 train accuracy: 0.977\n",
      "[12,   300/  446] train loss: 0.657 train accuracy: 0.969\n",
      "[12,   400/  446] train loss: 0.652 train accuracy: 0.992\n",
      "epoch: 12 validation accuracy: 0.977\n",
      "[13,   100/  446] train loss: 0.631 train accuracy: 0.953\n",
      "[13,   200/  446] train loss: 0.660 train accuracy: 0.961\n",
      "[13,   300/  446] train loss: 0.635 train accuracy: 0.992\n",
      "[13,   400/  446] train loss: 0.774 train accuracy: 0.977\n",
      "epoch: 13 validation accuracy: 0.976\n",
      "[14,   100/  446] train loss: 0.632 train accuracy: 0.953\n",
      "[14,   200/  446] train loss: 0.626 train accuracy: 0.992\n",
      "[14,   300/  446] train loss: 0.757 train accuracy: 0.977\n",
      "[14,   400/  446] train loss: 0.732 train accuracy: 0.969\n",
      "epoch: 14 validation accuracy: 0.975\n",
      "[15,   100/  446] train loss: 0.686 train accuracy: 0.969\n",
      "[15,   200/  446] train loss: 0.606 train accuracy: 0.984\n",
      "[15,   300/  446] train loss: 0.580 train accuracy: 0.977\n",
      "[15,   400/  446] train loss: 0.637 train accuracy: 0.984\n",
      "epoch: 15 validation accuracy: 0.976\n",
      "[16,   100/  446] train loss: 0.634 train accuracy: 0.953\n",
      "[16,   200/  446] train loss: 0.702 train accuracy: 0.938\n",
      "[16,   300/  446] train loss: 0.692 train accuracy: 0.977\n",
      "[16,   400/  446] train loss: 0.657 train accuracy: 0.961\n",
      "epoch: 16 validation accuracy: 0.976\n",
      "[17,   100/  446] train loss: 0.636 train accuracy: 0.961\n",
      "[17,   200/  446] train loss: 0.735 train accuracy: 0.961\n",
      "[17,   300/  446] train loss: 0.596 train accuracy: 0.969\n",
      "[17,   400/  446] train loss: 0.699 train accuracy: 0.961\n",
      "epoch: 17 validation accuracy: 0.976\n",
      "[18,   100/  446] train loss: 0.715 train accuracy: 0.992\n",
      "[18,   200/  446] train loss: 0.667 train accuracy: 0.977\n",
      "[18,   300/  446] train loss: 0.681 train accuracy: 0.977\n",
      "[18,   400/  446] train loss: 0.635 train accuracy: 0.977\n",
      "epoch: 18 validation accuracy: 0.976\n",
      "[19,   100/  446] train loss: 0.706 train accuracy: 0.969\n",
      "[19,   200/  446] train loss: 0.673 train accuracy: 0.984\n",
      "[19,   300/  446] train loss: 0.630 train accuracy: 0.969\n",
      "[19,   400/  446] train loss: 0.613 train accuracy: 0.969\n",
      "epoch: 19 validation accuracy: 0.975\n",
      "[20,   100/  446] train loss: 0.788 train accuracy: 0.992\n",
      "[20,   200/  446] train loss: 0.662 train accuracy: 0.984\n",
      "[20,   300/  446] train loss: 0.653 train accuracy: 0.969\n",
      "[20,   400/  446] train loss: 0.774 train accuracy: 0.977\n",
      "epoch: 20 validation accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "temperatures = [1, 2, 5, 10, 15, 20]\n",
    "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "# loss = alpha * st + (1 - alpha) * tt\n",
    "alphas = [1.0]\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['alpha'] = hparam_tuple[0]\n",
    "    hparam['T'] = hparam_tuple[1]\n",
    "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[3]\n",
    "    hparam['lr_decay'] = hparam_tuple[4]\n",
    "    hparam['momentum'] = hparam_tuple[5]\n",
    "    hparam['lr'] = hparam_tuple[6]\n",
    "    hparams_list.append(hparam)\n",
    "\n",
    "results_distill = {}\n",
    "for hparam in hparams_list:\n",
    "    print('Training with hparams' + utils.hparamToString(hparam))\n",
    "    reproducibilitySeed()\n",
    "    student_net = networks.StudentNetwork()\n",
    "    student_net = student_net.to(fast_device)\n",
    "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
    "    results_distill[hparam_tuple] = [None, None]\n",
    "    results_distill[hparam_tuple][0] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
    "                                                                    train_loader, val_loader, \n",
    "                                                                    print_every=print_every, \n",
    "                                                                    fast_device=fast_device)\n",
    "    results_distill[hparam_tuple][1] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs_bf, \n",
    "                                                                    train_balanced_loader, val_loader, \n",
    "                                                                    print_every=print_every, \n",
    "                                                                    fast_device=fast_device, \n",
    "                                                                    only_penultimate_train=True)\n",
    "    save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    torch.save({'results' : results_distill[hparam_tuple], \n",
    "                'model_state_dict' : student_net.state_dict(), \n",
    "                'epoch' : num_epochs}, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [10, 5]\n",
    "T_scatter = [math.log(h['T']) for h in hparams_list]\n",
    "alpha_scatter = [h['alpha'] for h in hparams_list]\n",
    "colors = []\n",
    "for i in range(len(hparams_list)):\n",
    "    cur_hparam_tuple = utils.hparamDictToTuple(hparams_list[i])\n",
    "    colors.append(results_distill[cur_hparam_tuple]['val_acc'][-1])\n",
    "    \n",
    "marker_size = 100\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(T_scatter, alpha_scatter, marker_size, c=colors, edgecolors='black')\n",
    "plt.colorbar()\n",
    "for i in range(len(T_scatter)):\n",
    "    ax.annotate(str('%0.4f' % (colors[i], )), (T_scatter[i], alpha_scatter[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "color = ['r', 'b', 'g', 'm', 'y', 'k']\n",
    "for hparam, c in zip(hparams_list, color):\n",
    "    cur_results = results_distill[utils.hparamDictToTuple(hparam)]\n",
    "    val_acc = cur_results[0]['val_acc'] + cur_results[1]['val_acc']\n",
    "    plt.plot(val_acc, color=c, label=str(hparam['T']))\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.title('Validation Accuracy vs Epoch for different T')\n",
    "plt.savefig(summaries_path_student + 'val_acc_vs_epoch_wrt_T.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hparam in hparams_list:\n",
    "    load_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    load_dict = torch.load(load_path)\n",
    "    student_net = networks.StudentNetwork()\n",
    "    student_net.load_state_dict(load_dict['model_state_dict'])\n",
    "    student_net = student_net.to(fast_device)\n",
    "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
    "    print(utils.hparamToString(hparam))\n",
    "    print('test accuracy: ', test_accuracy)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "num_epochs_bf = 20\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hparamsT=5, alpha=0.8, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.100\n",
      "[1,   100/  446] train loss: 1.107 train accuracy: 0.992\n",
      "[1,   200/  446] train loss: 0.794 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 0.741 train accuracy: 0.992\n",
      "[1,   400/  446] train loss: 0.556 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.259\n",
      "[2,   100/  446] train loss: 0.477 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.469 train accuracy: 1.000\n",
      "[2,   300/  446] train loss: 0.500 train accuracy: 0.992\n",
      "[2,   400/  446] train loss: 0.411 train accuracy: 1.000\n",
      "epoch: 2 validation accuracy: 0.345\n",
      "[3,   100/  446] train loss: 0.383 train accuracy: 1.000\n",
      "[3,   200/  446] train loss: 0.328 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.318 train accuracy: 1.000\n",
      "[3,   400/  446] train loss: 0.246 train accuracy: 1.000\n",
      "epoch: 3 validation accuracy: 0.487\n",
      "[4,   100/  446] train loss: 0.375 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.274 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.249 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.238 train accuracy: 1.000\n",
      "epoch: 4 validation accuracy: 0.563\n",
      "[5,   100/  446] train loss: 0.259 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.173 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.226 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.248 train accuracy: 0.992\n",
      "epoch: 5 validation accuracy: 0.606\n",
      "[6,   100/  446] train loss: 0.226 train accuracy: 0.992\n",
      "[6,   200/  446] train loss: 0.182 train accuracy: 1.000\n",
      "[6,   300/  446] train loss: 0.171 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.144 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.695\n",
      "[7,   100/  446] train loss: 0.215 train accuracy: 0.977\n",
      "[7,   200/  446] train loss: 0.176 train accuracy: 0.992\n",
      "[7,   300/  446] train loss: 0.175 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.167 train accuracy: 0.992\n",
      "epoch: 7 validation accuracy: 0.730\n",
      "[8,   100/  446] train loss: 0.158 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.152 train accuracy: 0.992\n",
      "[8,   300/  446] train loss: 0.158 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.116 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.761\n",
      "[9,   100/  446] train loss: 0.121 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.129 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.122 train accuracy: 1.000\n",
      "[9,   400/  446] train loss: 0.141 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.789\n",
      "[10,   100/  446] train loss: 0.123 train accuracy: 0.992\n",
      "[10,   200/  446] train loss: 0.097 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.104 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.118 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.805\n",
      "[11,   100/  446] train loss: 0.112 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.122 train accuracy: 0.992\n",
      "[11,   300/  446] train loss: 0.110 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.095 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.807\n",
      "[12,   100/  446] train loss: 0.114 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.091 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.104 train accuracy: 1.000\n",
      "[12,   400/  446] train loss: 0.118 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.823\n",
      "[13,   100/  446] train loss: 0.105 train accuracy: 1.000\n",
      "[13,   200/  446] train loss: 0.096 train accuracy: 0.992\n",
      "[13,   300/  446] train loss: 0.112 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.095 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.835\n",
      "[14,   100/  446] train loss: 0.105 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.102 train accuracy: 1.000\n",
      "[14,   300/  446] train loss: 0.109 train accuracy: 0.992\n",
      "[14,   400/  446] train loss: 0.087 train accuracy: 1.000\n",
      "epoch: 14 validation accuracy: 0.847\n",
      "[15,   100/  446] train loss: 0.089 train accuracy: 0.984\n",
      "[15,   200/  446] train loss: 0.087 train accuracy: 1.000\n",
      "[15,   300/  446] train loss: 0.099 train accuracy: 0.984\n",
      "[15,   400/  446] train loss: 0.093 train accuracy: 0.992\n",
      "epoch: 15 validation accuracy: 0.839\n",
      "[16,   100/  446] train loss: 0.087 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.075 train accuracy: 0.992\n",
      "[16,   300/  446] train loss: 0.084 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.094 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.855\n",
      "[17,   100/  446] train loss: 0.083 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.090 train accuracy: 1.000\n",
      "[17,   300/  446] train loss: 0.076 train accuracy: 0.992\n",
      "[17,   400/  446] train loss: 0.088 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.860\n",
      "[18,   100/  446] train loss: 0.075 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.085 train accuracy: 0.992\n",
      "[18,   300/  446] train loss: 0.083 train accuracy: 0.992\n",
      "[18,   400/  446] train loss: 0.070 train accuracy: 1.000\n",
      "epoch: 18 validation accuracy: 0.867\n",
      "[19,   100/  446] train loss: 0.078 train accuracy: 0.992\n",
      "[19,   200/  446] train loss: 0.073 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.089 train accuracy: 0.992\n",
      "[19,   400/  446] train loss: 0.077 train accuracy: 1.000\n",
      "epoch: 19 validation accuracy: 0.870\n",
      "[20,   100/  446] train loss: 0.070 train accuracy: 1.000\n",
      "[20,   200/  446] train loss: 0.071 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.071 train accuracy: 0.992\n",
      "[20,   400/  446] train loss: 0.070 train accuracy: 1.000\n",
      "epoch: 20 validation accuracy: 0.872\n",
      "epoch: 0 validation accuracy: 0.872\n",
      "[1,   100/  446] train loss: 0.942 train accuracy: 0.953\n",
      "[1,   200/  446] train loss: 0.802 train accuracy: 0.961\n",
      "[1,   300/  446] train loss: 0.822 train accuracy: 0.961\n",
      "[1,   400/  446] train loss: 0.659 train accuracy: 0.945\n",
      "epoch: 1 validation accuracy: 0.966\n",
      "[2,   100/  446] train loss: 0.712 train accuracy: 0.953\n",
      "[2,   200/  446] train loss: 0.576 train accuracy: 0.969\n",
      "[2,   300/  446] train loss: 0.723 train accuracy: 0.945\n",
      "[2,   400/  446] train loss: 0.704 train accuracy: 0.953\n",
      "epoch: 2 validation accuracy: 0.967\n",
      "[3,   100/  446] train loss: 0.781 train accuracy: 0.953\n",
      "[3,   200/  446] train loss: 0.482 train accuracy: 0.992\n",
      "[3,   300/  446] train loss: 0.725 train accuracy: 0.984\n",
      "[3,   400/  446] train loss: 0.691 train accuracy: 0.938\n",
      "epoch: 3 validation accuracy: 0.969\n",
      "[4,   100/  446] train loss: 0.655 train accuracy: 0.977\n",
      "[4,   200/  446] train loss: 0.596 train accuracy: 0.961\n",
      "[4,   300/  446] train loss: 0.490 train accuracy: 0.961\n",
      "[4,   400/  446] train loss: 0.762 train accuracy: 0.945\n",
      "epoch: 4 validation accuracy: 0.967\n",
      "[5,   100/  446] train loss: 0.716 train accuracy: 0.953\n",
      "[5,   200/  446] train loss: 0.605 train accuracy: 0.977\n",
      "[5,   300/  446] train loss: 0.576 train accuracy: 0.961\n",
      "[5,   400/  446] train loss: 0.616 train accuracy: 0.984\n",
      "epoch: 5 validation accuracy: 0.969\n",
      "[6,   100/  446] train loss: 0.664 train accuracy: 0.938\n",
      "[6,   200/  446] train loss: 0.669 train accuracy: 0.953\n",
      "[6,   300/  446] train loss: 0.609 train accuracy: 0.945\n",
      "[6,   400/  446] train loss: 0.689 train accuracy: 0.961\n",
      "epoch: 6 validation accuracy: 0.969\n",
      "[7,   100/  446] train loss: 0.559 train accuracy: 0.961\n",
      "[7,   200/  446] train loss: 0.568 train accuracy: 0.984\n",
      "[7,   300/  446] train loss: 0.566 train accuracy: 0.977\n",
      "[7,   400/  446] train loss: 0.627 train accuracy: 0.961\n",
      "epoch: 7 validation accuracy: 0.971\n",
      "[8,   100/  446] train loss: 0.508 train accuracy: 0.984\n",
      "[8,   200/  446] train loss: 0.533 train accuracy: 0.969\n",
      "[8,   300/  446] train loss: 0.537 train accuracy: 0.977\n",
      "[8,   400/  446] train loss: 0.436 train accuracy: 0.984\n",
      "epoch: 8 validation accuracy: 0.970\n",
      "[9,   100/  446] train loss: 0.660 train accuracy: 0.977\n",
      "[9,   200/  446] train loss: 0.489 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.505 train accuracy: 0.977\n",
      "[9,   400/  446] train loss: 0.581 train accuracy: 0.953\n",
      "epoch: 9 validation accuracy: 0.971\n",
      "[10,   100/  446] train loss: 0.480 train accuracy: 0.984\n",
      "[10,   200/  446] train loss: 0.586 train accuracy: 0.992\n",
      "[10,   300/  446] train loss: 0.579 train accuracy: 0.961\n",
      "[10,   400/  446] train loss: 0.536 train accuracy: 0.969\n",
      "epoch: 10 validation accuracy: 0.971\n",
      "[11,   100/  446] train loss: 0.473 train accuracy: 0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,   200/  446] train loss: 0.531 train accuracy: 0.984\n",
      "[11,   300/  446] train loss: 0.441 train accuracy: 0.992\n",
      "[11,   400/  446] train loss: 0.554 train accuracy: 0.984\n",
      "epoch: 11 validation accuracy: 0.971\n",
      "[12,   100/  446] train loss: 0.506 train accuracy: 0.961\n",
      "[12,   200/  446] train loss: 0.514 train accuracy: 0.977\n",
      "[12,   300/  446] train loss: 0.552 train accuracy: 0.961\n",
      "[12,   400/  446] train loss: 0.507 train accuracy: 0.984\n",
      "epoch: 12 validation accuracy: 0.970\n",
      "[13,   100/  446] train loss: 0.531 train accuracy: 0.953\n",
      "[13,   200/  446] train loss: 0.579 train accuracy: 0.938\n",
      "[13,   300/  446] train loss: 0.512 train accuracy: 0.984\n",
      "[13,   400/  446] train loss: 0.584 train accuracy: 0.977\n",
      "epoch: 13 validation accuracy: 0.971\n",
      "[14,   100/  446] train loss: 0.660 train accuracy: 0.953\n",
      "[14,   200/  446] train loss: 0.528 train accuracy: 0.977\n",
      "[14,   300/  446] train loss: 0.632 train accuracy: 0.977\n",
      "[14,   400/  446] train loss: 0.600 train accuracy: 0.977\n",
      "epoch: 14 validation accuracy: 0.972\n",
      "[15,   100/  446] train loss: 0.603 train accuracy: 0.969\n",
      "[15,   200/  446] train loss: 0.518 train accuracy: 0.969\n",
      "[15,   300/  446] train loss: 0.494 train accuracy: 0.977\n",
      "[15,   400/  446] train loss: 0.522 train accuracy: 0.984\n",
      "epoch: 15 validation accuracy: 0.972\n",
      "[16,   100/  446] train loss: 0.541 train accuracy: 0.953\n",
      "[16,   200/  446] train loss: 0.701 train accuracy: 0.953\n",
      "[16,   300/  446] train loss: 0.524 train accuracy: 0.969\n",
      "[16,   400/  446] train loss: 0.591 train accuracy: 0.945\n",
      "epoch: 16 validation accuracy: 0.970\n",
      "[17,   100/  446] train loss: 0.509 train accuracy: 0.977\n",
      "[17,   200/  446] train loss: 0.614 train accuracy: 0.961\n",
      "[17,   300/  446] train loss: 0.444 train accuracy: 0.977\n",
      "[17,   400/  446] train loss: 0.654 train accuracy: 0.961\n",
      "epoch: 17 validation accuracy: 0.970\n",
      "[18,   100/  446] train loss: 0.633 train accuracy: 0.977\n",
      "[18,   200/  446] train loss: 0.506 train accuracy: 0.969\n",
      "[18,   300/  446] train loss: 0.562 train accuracy: 0.969\n",
      "[18,   400/  446] train loss: 0.544 train accuracy: 0.969\n",
      "epoch: 18 validation accuracy: 0.971\n",
      "[19,   100/  446] train loss: 0.593 train accuracy: 0.961\n",
      "[19,   200/  446] train loss: 0.515 train accuracy: 0.992\n",
      "[19,   300/  446] train loss: 0.500 train accuracy: 0.969\n",
      "[19,   400/  446] train loss: 0.462 train accuracy: 0.969\n",
      "epoch: 19 validation accuracy: 0.972\n",
      "[20,   100/  446] train loss: 0.646 train accuracy: 0.992\n",
      "[20,   200/  446] train loss: 0.508 train accuracy: 0.984\n",
      "[20,   300/  446] train loss: 0.537 train accuracy: 0.969\n",
      "[20,   400/  446] train loss: 0.521 train accuracy: 0.961\n",
      "epoch: 20 validation accuracy: 0.973\n",
      "Training with hparamsT=5, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.100\n",
      "[1,   100/  446] train loss: 0.773 train accuracy: 0.992\n",
      "[1,   200/  446] train loss: 0.523 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 0.520 train accuracy: 0.992\n",
      "[1,   400/  446] train loss: 0.401 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.210\n",
      "[2,   100/  446] train loss: 0.355 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.372 train accuracy: 1.000\n",
      "[2,   300/  446] train loss: 0.363 train accuracy: 0.992\n",
      "[2,   400/  446] train loss: 0.320 train accuracy: 1.000\n",
      "epoch: 2 validation accuracy: 0.261\n",
      "[3,   100/  446] train loss: 0.296 train accuracy: 1.000\n",
      "[3,   200/  446] train loss: 0.277 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.275 train accuracy: 1.000\n",
      "[3,   400/  446] train loss: 0.224 train accuracy: 1.000\n",
      "epoch: 3 validation accuracy: 0.332\n",
      "[4,   100/  446] train loss: 0.296 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.232 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.212 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.221 train accuracy: 1.000\n",
      "epoch: 4 validation accuracy: 0.405\n",
      "[5,   100/  446] train loss: 0.223 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.144 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.178 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.208 train accuracy: 0.992\n",
      "epoch: 5 validation accuracy: 0.449\n",
      "[6,   100/  446] train loss: 0.182 train accuracy: 1.000\n",
      "[6,   200/  446] train loss: 0.162 train accuracy: 1.000\n",
      "[6,   300/  446] train loss: 0.158 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.128 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.500\n",
      "[7,   100/  446] train loss: 0.193 train accuracy: 1.000\n",
      "[7,   200/  446] train loss: 0.146 train accuracy: 0.992\n",
      "[7,   300/  446] train loss: 0.154 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.154 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.572\n",
      "[8,   100/  446] train loss: 0.144 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.143 train accuracy: 1.000\n",
      "[8,   300/  446] train loss: 0.147 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.123 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.595\n",
      "[9,   100/  446] train loss: 0.102 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.107 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.115 train accuracy: 1.000\n",
      "[9,   400/  446] train loss: 0.123 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.638\n",
      "[10,   100/  446] train loss: 0.109 train accuracy: 1.000\n",
      "[10,   200/  446] train loss: 0.082 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.095 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.110 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.656\n",
      "[11,   100/  446] train loss: 0.104 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.120 train accuracy: 1.000\n",
      "[11,   300/  446] train loss: 0.106 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.089 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.689\n",
      "[12,   100/  446] train loss: 0.109 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.082 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.092 train accuracy: 1.000\n",
      "[12,   400/  446] train loss: 0.101 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.705\n",
      "[13,   100/  446] train loss: 0.098 train accuracy: 1.000\n",
      "[13,   200/  446] train loss: 0.084 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.098 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.085 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.714\n",
      "[14,   100/  446] train loss: 0.093 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.093 train accuracy: 1.000\n",
      "[14,   300/  446] train loss: 0.093 train accuracy: 0.992\n",
      "[14,   400/  446] train loss: 0.068 train accuracy: 1.000\n",
      "epoch: 14 validation accuracy: 0.749\n",
      "[15,   100/  446] train loss: 0.085 train accuracy: 1.000\n",
      "[15,   200/  446] train loss: 0.077 train accuracy: 1.000\n",
      "[15,   300/  446] train loss: 0.094 train accuracy: 0.984\n",
      "[15,   400/  446] train loss: 0.089 train accuracy: 0.992\n",
      "epoch: 15 validation accuracy: 0.750\n",
      "[16,   100/  446] train loss: 0.074 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.071 train accuracy: 1.000\n",
      "[16,   300/  446] train loss: 0.073 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.077 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.756\n",
      "[17,   100/  446] train loss: 0.081 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.080 train accuracy: 1.000\n",
      "[17,   300/  446] train loss: 0.067 train accuracy: 1.000\n",
      "[17,   400/  446] train loss: 0.069 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.771\n",
      "[18,   100/  446] train loss: 0.068 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.078 train accuracy: 0.992\n",
      "[18,   300/  446] train loss: 0.063 train accuracy: 1.000\n",
      "[18,   400/  446] train loss: 0.061 train accuracy: 1.000\n",
      "epoch: 18 validation accuracy: 0.781\n",
      "[19,   100/  446] train loss: 0.076 train accuracy: 0.992\n",
      "[19,   200/  446] train loss: 0.062 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.081 train accuracy: 1.000\n",
      "[19,   400/  446] train loss: 0.070 train accuracy: 1.000\n",
      "epoch: 19 validation accuracy: 0.780\n",
      "[20,   100/  446] train loss: 0.067 train accuracy: 1.000\n",
      "[20,   200/  446] train loss: 0.066 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.059 train accuracy: 1.000\n",
      "[20,   400/  446] train loss: 0.063 train accuracy: 1.000\n",
      "epoch: 20 validation accuracy: 0.792\n",
      "epoch: 0 validation accuracy: 0.792\n",
      "[1,   100/  446] train loss: 0.796 train accuracy: 0.953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200/  446] train loss: 0.671 train accuracy: 0.961\n",
      "[1,   300/  446] train loss: 0.656 train accuracy: 0.961\n",
      "[1,   400/  446] train loss: 0.571 train accuracy: 0.945\n",
      "epoch: 1 validation accuracy: 0.959\n",
      "[2,   100/  446] train loss: 0.586 train accuracy: 0.945\n",
      "[2,   200/  446] train loss: 0.503 train accuracy: 0.953\n",
      "[2,   300/  446] train loss: 0.633 train accuracy: 0.930\n",
      "[2,   400/  446] train loss: 0.558 train accuracy: 0.961\n",
      "epoch: 2 validation accuracy: 0.965\n",
      "[3,   100/  446] train loss: 0.635 train accuracy: 0.953\n",
      "[3,   200/  446] train loss: 0.354 train accuracy: 0.992\n",
      "[3,   300/  446] train loss: 0.530 train accuracy: 0.992\n",
      "[3,   400/  446] train loss: 0.579 train accuracy: 0.930\n",
      "epoch: 3 validation accuracy: 0.965\n",
      "[4,   100/  446] train loss: 0.544 train accuracy: 0.969\n",
      "[4,   200/  446] train loss: 0.468 train accuracy: 0.953\n",
      "[4,   300/  446] train loss: 0.404 train accuracy: 0.961\n",
      "[4,   400/  446] train loss: 0.587 train accuracy: 0.930\n",
      "epoch: 4 validation accuracy: 0.968\n",
      "[5,   100/  446] train loss: 0.550 train accuracy: 0.953\n",
      "[5,   200/  446] train loss: 0.511 train accuracy: 0.969\n",
      "[5,   300/  446] train loss: 0.474 train accuracy: 0.953\n",
      "[5,   400/  446] train loss: 0.433 train accuracy: 0.992\n",
      "epoch: 5 validation accuracy: 0.968\n",
      "[6,   100/  446] train loss: 0.552 train accuracy: 0.945\n",
      "[6,   200/  446] train loss: 0.544 train accuracy: 0.961\n",
      "[6,   300/  446] train loss: 0.476 train accuracy: 0.961\n",
      "[6,   400/  446] train loss: 0.477 train accuracy: 0.977\n",
      "epoch: 6 validation accuracy: 0.968\n",
      "[7,   100/  446] train loss: 0.459 train accuracy: 0.977\n",
      "[7,   200/  446] train loss: 0.471 train accuracy: 0.977\n",
      "[7,   300/  446] train loss: 0.475 train accuracy: 0.969\n",
      "[7,   400/  446] train loss: 0.447 train accuracy: 0.961\n",
      "epoch: 7 validation accuracy: 0.968\n",
      "[8,   100/  446] train loss: 0.372 train accuracy: 0.977\n",
      "[8,   200/  446] train loss: 0.399 train accuracy: 0.969\n",
      "[8,   300/  446] train loss: 0.410 train accuracy: 0.969\n",
      "[8,   400/  446] train loss: 0.362 train accuracy: 0.977\n",
      "epoch: 8 validation accuracy: 0.968\n",
      "[9,   100/  446] train loss: 0.447 train accuracy: 0.984\n",
      "[9,   200/  446] train loss: 0.330 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.381 train accuracy: 0.977\n",
      "[9,   400/  446] train loss: 0.471 train accuracy: 0.953\n",
      "epoch: 9 validation accuracy: 0.969\n",
      "[10,   100/  446] train loss: 0.405 train accuracy: 0.977\n",
      "[10,   200/  446] train loss: 0.453 train accuracy: 0.984\n",
      "[10,   300/  446] train loss: 0.458 train accuracy: 0.945\n",
      "[10,   400/  446] train loss: 0.451 train accuracy: 0.969\n",
      "epoch: 10 validation accuracy: 0.969\n",
      "[11,   100/  446] train loss: 0.351 train accuracy: 0.992\n",
      "[11,   200/  446] train loss: 0.422 train accuracy: 0.969\n",
      "[11,   300/  446] train loss: 0.361 train accuracy: 0.992\n",
      "[11,   400/  446] train loss: 0.421 train accuracy: 0.992\n",
      "epoch: 11 validation accuracy: 0.969\n",
      "[12,   100/  446] train loss: 0.390 train accuracy: 0.969\n",
      "[12,   200/  446] train loss: 0.447 train accuracy: 0.977\n",
      "[12,   300/  446] train loss: 0.451 train accuracy: 0.977\n",
      "[12,   400/  446] train loss: 0.407 train accuracy: 0.977\n",
      "epoch: 12 validation accuracy: 0.969\n",
      "[13,   100/  446] train loss: 0.435 train accuracy: 0.961\n",
      "[13,   200/  446] train loss: 0.465 train accuracy: 0.938\n",
      "[13,   300/  446] train loss: 0.359 train accuracy: 0.984\n",
      "[13,   400/  446] train loss: 0.438 train accuracy: 0.984\n",
      "epoch: 13 validation accuracy: 0.969\n",
      "[14,   100/  446] train loss: 0.550 train accuracy: 0.914\n",
      "[14,   200/  446] train loss: 0.405 train accuracy: 0.977\n",
      "[14,   300/  446] train loss: 0.477 train accuracy: 0.969\n",
      "[14,   400/  446] train loss: 0.466 train accuracy: 0.984\n",
      "epoch: 14 validation accuracy: 0.969\n",
      "[15,   100/  446] train loss: 0.507 train accuracy: 0.969\n",
      "[15,   200/  446] train loss: 0.365 train accuracy: 0.961\n",
      "[15,   300/  446] train loss: 0.381 train accuracy: 0.977\n",
      "[15,   400/  446] train loss: 0.380 train accuracy: 0.984\n",
      "epoch: 15 validation accuracy: 0.969\n",
      "[16,   100/  446] train loss: 0.424 train accuracy: 0.953\n",
      "[16,   200/  446] train loss: 0.539 train accuracy: 0.945\n",
      "[16,   300/  446] train loss: 0.482 train accuracy: 0.969\n",
      "[16,   400/  446] train loss: 0.414 train accuracy: 0.953\n",
      "epoch: 16 validation accuracy: 0.969\n",
      "[17,   100/  446] train loss: 0.386 train accuracy: 0.977\n",
      "[17,   200/  446] train loss: 0.495 train accuracy: 0.945\n",
      "[17,   300/  446] train loss: 0.380 train accuracy: 0.984\n",
      "[17,   400/  446] train loss: 0.475 train accuracy: 0.961\n",
      "epoch: 17 validation accuracy: 0.969\n",
      "[18,   100/  446] train loss: 0.424 train accuracy: 0.977\n",
      "[18,   200/  446] train loss: 0.378 train accuracy: 0.977\n",
      "[18,   300/  446] train loss: 0.433 train accuracy: 0.977\n",
      "[18,   400/  446] train loss: 0.453 train accuracy: 0.969\n",
      "epoch: 18 validation accuracy: 0.970\n",
      "[19,   100/  446] train loss: 0.439 train accuracy: 0.953\n",
      "[19,   200/  446] train loss: 0.421 train accuracy: 0.984\n",
      "[19,   300/  446] train loss: 0.365 train accuracy: 0.977\n",
      "[19,   400/  446] train loss: 0.346 train accuracy: 0.961\n",
      "epoch: 19 validation accuracy: 0.969\n",
      "[20,   100/  446] train loss: 0.444 train accuracy: 0.969\n",
      "[20,   200/  446] train loss: 0.375 train accuracy: 0.977\n",
      "[20,   300/  446] train loss: 0.408 train accuracy: 0.969\n",
      "[20,   400/  446] train loss: 0.395 train accuracy: 0.977\n",
      "epoch: 20 validation accuracy: 0.970\n",
      "Training with hparamsT=5, alpha=0.4, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.100\n",
      "[1,   100/  446] train loss: 0.658 train accuracy: 0.992\n",
      "[1,   200/  446] train loss: 0.440 train accuracy: 1.000\n",
      "[1,   300/  446] train loss: 0.441 train accuracy: 0.992\n",
      "[1,   400/  446] train loss: 0.342 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.204\n",
      "[2,   100/  446] train loss: 0.306 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.335 train accuracy: 1.000\n",
      "[2,   300/  446] train loss: 0.328 train accuracy: 0.992\n",
      "[2,   400/  446] train loss: 0.276 train accuracy: 1.000\n",
      "epoch: 2 validation accuracy: 0.234\n",
      "[3,   100/  446] train loss: 0.267 train accuracy: 1.000\n",
      "[3,   200/  446] train loss: 0.240 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.242 train accuracy: 1.000\n",
      "[3,   400/  446] train loss: 0.210 train accuracy: 0.992\n",
      "epoch: 3 validation accuracy: 0.282\n",
      "[4,   100/  446] train loss: 0.255 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.216 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.189 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.197 train accuracy: 0.992\n",
      "epoch: 4 validation accuracy: 0.335\n",
      "[5,   100/  446] train loss: 0.201 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.134 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.166 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.177 train accuracy: 0.992\n",
      "epoch: 5 validation accuracy: 0.391\n",
      "[6,   100/  446] train loss: 0.172 train accuracy: 1.000\n",
      "[6,   200/  446] train loss: 0.149 train accuracy: 1.000\n",
      "[6,   300/  446] train loss: 0.150 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.126 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.434\n",
      "[7,   100/  446] train loss: 0.186 train accuracy: 1.000\n",
      "[7,   200/  446] train loss: 0.138 train accuracy: 1.000\n",
      "[7,   300/  446] train loss: 0.154 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.145 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.506\n",
      "[8,   100/  446] train loss: 0.135 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.141 train accuracy: 1.000\n",
      "[8,   300/  446] train loss: 0.138 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.115 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.507\n",
      "[9,   100/  446] train loss: 0.094 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.101 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.108 train accuracy: 1.000\n",
      "[9,   400/  446] train loss: 0.119 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.539\n",
      "[10,   100/  446] train loss: 0.109 train accuracy: 1.000\n",
      "[10,   200/  446] train loss: 0.077 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.093 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.111 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.570\n",
      "[11,   100/  446] train loss: 0.097 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.117 train accuracy: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,   300/  446] train loss: 0.100 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.082 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.592\n",
      "[12,   100/  446] train loss: 0.100 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.080 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.093 train accuracy: 1.000\n",
      "[12,   400/  446] train loss: 0.098 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.633\n",
      "[13,   100/  446] train loss: 0.095 train accuracy: 1.000\n",
      "[13,   200/  446] train loss: 0.084 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.098 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.079 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.634\n",
      "[14,   100/  446] train loss: 0.090 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.089 train accuracy: 1.000\n",
      "[14,   300/  446] train loss: 0.090 train accuracy: 0.992\n",
      "[14,   400/  446] train loss: 0.065 train accuracy: 1.000\n",
      "epoch: 14 validation accuracy: 0.660\n",
      "[15,   100/  446] train loss: 0.082 train accuracy: 1.000\n",
      "[15,   200/  446] train loss: 0.074 train accuracy: 1.000\n",
      "[15,   300/  446] train loss: 0.093 train accuracy: 0.992\n",
      "[15,   400/  446] train loss: 0.087 train accuracy: 0.992\n",
      "epoch: 15 validation accuracy: 0.669\n",
      "[16,   100/  446] train loss: 0.074 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.070 train accuracy: 1.000\n",
      "[16,   300/  446] train loss: 0.067 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.075 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.688\n",
      "[17,   100/  446] train loss: 0.077 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.077 train accuracy: 1.000\n",
      "[17,   300/  446] train loss: 0.067 train accuracy: 1.000\n",
      "[17,   400/  446] train loss: 0.067 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.692\n",
      "[18,   100/  446] train loss: 0.066 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.076 train accuracy: 1.000\n",
      "[18,   300/  446] train loss: 0.059 train accuracy: 1.000\n",
      "[18,   400/  446] train loss: 0.058 train accuracy: 1.000\n",
      "epoch: 18 validation accuracy: 0.703\n",
      "[19,   100/  446] train loss: 0.071 train accuracy: 0.992\n",
      "[19,   200/  446] train loss: 0.057 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.078 train accuracy: 1.000\n",
      "[19,   400/  446] train loss: 0.067 train accuracy: 1.000\n",
      "epoch: 19 validation accuracy: 0.708\n",
      "[20,   100/  446] train loss: 0.069 train accuracy: 1.000\n",
      "[20,   200/  446] train loss: 0.066 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.059 train accuracy: 1.000\n",
      "[20,   400/  446] train loss: 0.063 train accuracy: 1.000\n",
      "epoch: 20 validation accuracy: 0.717\n",
      "epoch: 0 validation accuracy: 0.717\n",
      "[1,   100/  446] train loss: 0.777 train accuracy: 0.969\n",
      "[1,   200/  446] train loss: 0.666 train accuracy: 0.953\n",
      "[1,   300/  446] train loss: 0.658 train accuracy: 0.945\n",
      "[1,   400/  446] train loss: 0.608 train accuracy: 0.938\n",
      "epoch: 1 validation accuracy: 0.954\n",
      "[2,   100/  446] train loss: 0.595 train accuracy: 0.938\n",
      "[2,   200/  446] train loss: 0.497 train accuracy: 0.953\n",
      "[2,   300/  446] train loss: 0.621 train accuracy: 0.938\n",
      "[2,   400/  446] train loss: 0.534 train accuracy: 0.953\n",
      "epoch: 2 validation accuracy: 0.959\n",
      "[3,   100/  446] train loss: 0.606 train accuracy: 0.945\n",
      "[3,   200/  446] train loss: 0.340 train accuracy: 0.992\n",
      "[3,   300/  446] train loss: 0.514 train accuracy: 0.992\n",
      "[3,   400/  446] train loss: 0.592 train accuracy: 0.930\n",
      "epoch: 3 validation accuracy: 0.961\n",
      "[4,   100/  446] train loss: 0.521 train accuracy: 0.969\n",
      "[4,   200/  446] train loss: 0.491 train accuracy: 0.945\n",
      "[4,   300/  446] train loss: 0.407 train accuracy: 0.945\n",
      "[4,   400/  446] train loss: 0.573 train accuracy: 0.938\n",
      "epoch: 4 validation accuracy: 0.962\n",
      "[5,   100/  446] train loss: 0.526 train accuracy: 0.953\n",
      "[5,   200/  446] train loss: 0.492 train accuracy: 0.969\n",
      "[5,   300/  446] train loss: 0.466 train accuracy: 0.945\n",
      "[5,   400/  446] train loss: 0.427 train accuracy: 0.977\n",
      "epoch: 5 validation accuracy: 0.963\n",
      "[6,   100/  446] train loss: 0.531 train accuracy: 0.938\n",
      "[6,   200/  446] train loss: 0.503 train accuracy: 0.945\n",
      "[6,   300/  446] train loss: 0.470 train accuracy: 0.969\n",
      "[6,   400/  446] train loss: 0.447 train accuracy: 0.969\n",
      "epoch: 6 validation accuracy: 0.964\n",
      "[7,   100/  446] train loss: 0.410 train accuracy: 0.953\n",
      "[7,   200/  446] train loss: 0.430 train accuracy: 0.969\n",
      "[7,   300/  446] train loss: 0.473 train accuracy: 0.969\n",
      "[7,   400/  446] train loss: 0.406 train accuracy: 0.969\n",
      "epoch: 7 validation accuracy: 0.964\n",
      "[8,   100/  446] train loss: 0.362 train accuracy: 0.984\n",
      "[8,   200/  446] train loss: 0.383 train accuracy: 0.969\n",
      "[8,   300/  446] train loss: 0.393 train accuracy: 0.969\n",
      "[8,   400/  446] train loss: 0.340 train accuracy: 0.977\n",
      "epoch: 8 validation accuracy: 0.965\n",
      "[9,   100/  446] train loss: 0.377 train accuracy: 0.984\n",
      "[9,   200/  446] train loss: 0.298 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.370 train accuracy: 0.961\n",
      "[9,   400/  446] train loss: 0.414 train accuracy: 0.969\n",
      "epoch: 9 validation accuracy: 0.964\n",
      "[10,   100/  446] train loss: 0.373 train accuracy: 0.977\n",
      "[10,   200/  446] train loss: 0.404 train accuracy: 0.984\n",
      "[10,   300/  446] train loss: 0.415 train accuracy: 0.945\n",
      "[10,   400/  446] train loss: 0.452 train accuracy: 0.961\n",
      "epoch: 10 validation accuracy: 0.965\n",
      "[11,   100/  446] train loss: 0.326 train accuracy: 0.977\n",
      "[11,   200/  446] train loss: 0.368 train accuracy: 0.977\n",
      "[11,   300/  446] train loss: 0.326 train accuracy: 0.992\n",
      "[11,   400/  446] train loss: 0.392 train accuracy: 0.992\n",
      "epoch: 11 validation accuracy: 0.965\n",
      "[12,   100/  446] train loss: 0.364 train accuracy: 0.961\n",
      "[12,   200/  446] train loss: 0.381 train accuracy: 0.977\n",
      "[12,   300/  446] train loss: 0.416 train accuracy: 0.977\n",
      "[12,   400/  446] train loss: 0.362 train accuracy: 0.984\n",
      "epoch: 12 validation accuracy: 0.966\n",
      "[13,   100/  446] train loss: 0.431 train accuracy: 0.953\n",
      "[13,   200/  446] train loss: 0.420 train accuracy: 0.930\n",
      "[13,   300/  446] train loss: 0.331 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.404 train accuracy: 0.984\n",
      "epoch: 13 validation accuracy: 0.965\n",
      "[14,   100/  446] train loss: 0.537 train accuracy: 0.914\n",
      "[14,   200/  446] train loss: 0.382 train accuracy: 0.961\n",
      "[14,   300/  446] train loss: 0.460 train accuracy: 0.969\n",
      "[14,   400/  446] train loss: 0.434 train accuracy: 0.977\n",
      "epoch: 14 validation accuracy: 0.965\n",
      "[15,   100/  446] train loss: 0.461 train accuracy: 0.969\n",
      "[15,   200/  446] train loss: 0.354 train accuracy: 0.961\n",
      "[15,   300/  446] train loss: 0.343 train accuracy: 0.969\n",
      "[15,   400/  446] train loss: 0.353 train accuracy: 0.984\n",
      "epoch: 15 validation accuracy: 0.966\n",
      "[16,   100/  446] train loss: 0.438 train accuracy: 0.953\n",
      "[16,   200/  446] train loss: 0.541 train accuracy: 0.953\n",
      "[16,   300/  446] train loss: 0.409 train accuracy: 0.969\n",
      "[16,   400/  446] train loss: 0.408 train accuracy: 0.961\n",
      "epoch: 16 validation accuracy: 0.965\n",
      "[17,   100/  446] train loss: 0.351 train accuracy: 0.977\n",
      "[17,   200/  446] train loss: 0.465 train accuracy: 0.945\n",
      "[17,   300/  446] train loss: 0.336 train accuracy: 0.984\n",
      "[17,   400/  446] train loss: 0.474 train accuracy: 0.961\n",
      "epoch: 17 validation accuracy: 0.966\n",
      "[18,   100/  446] train loss: 0.385 train accuracy: 0.977\n",
      "[18,   200/  446] train loss: 0.341 train accuracy: 0.961\n",
      "[18,   300/  446] train loss: 0.412 train accuracy: 0.969\n",
      "[18,   400/  446] train loss: 0.382 train accuracy: 0.969\n",
      "epoch: 18 validation accuracy: 0.965\n",
      "[19,   100/  446] train loss: 0.398 train accuracy: 0.961\n",
      "[19,   200/  446] train loss: 0.370 train accuracy: 0.977\n",
      "[19,   300/  446] train loss: 0.335 train accuracy: 0.977\n",
      "[19,   400/  446] train loss: 0.367 train accuracy: 0.938\n",
      "epoch: 19 validation accuracy: 0.966\n",
      "[20,   100/  446] train loss: 0.422 train accuracy: 0.969\n",
      "[20,   200/  446] train loss: 0.329 train accuracy: 0.977\n",
      "[20,   300/  446] train loss: 0.358 train accuracy: 0.977\n",
      "[20,   400/  446] train loss: 0.358 train accuracy: 0.969\n",
      "epoch: 20 validation accuracy: 0.965\n",
      "Training with hparamsT=5, alpha=0.2, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "epoch: 0 validation accuracy: 0.100\n",
      "[1,   100/  446] train loss: 0.395 train accuracy: 0.984\n",
      "[1,   200/  446] train loss: 0.280 train accuracy: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300/  446] train loss: 0.282 train accuracy: 0.992\n",
      "[1,   400/  446] train loss: 0.220 train accuracy: 1.000\n",
      "epoch: 1 validation accuracy: 0.198\n",
      "[2,   100/  446] train loss: 0.197 train accuracy: 1.000\n",
      "[2,   200/  446] train loss: 0.208 train accuracy: 1.000\n",
      "[2,   300/  446] train loss: 0.222 train accuracy: 0.992\n",
      "[2,   400/  446] train loss: 0.173 train accuracy: 1.000\n",
      "epoch: 2 validation accuracy: 0.206\n",
      "[3,   100/  446] train loss: 0.200 train accuracy: 1.000\n",
      "[3,   200/  446] train loss: 0.158 train accuracy: 1.000\n",
      "[3,   300/  446] train loss: 0.165 train accuracy: 1.000\n",
      "[3,   400/  446] train loss: 0.150 train accuracy: 1.000\n",
      "epoch: 3 validation accuracy: 0.222\n",
      "[4,   100/  446] train loss: 0.168 train accuracy: 0.992\n",
      "[4,   200/  446] train loss: 0.147 train accuracy: 1.000\n",
      "[4,   300/  446] train loss: 0.146 train accuracy: 1.000\n",
      "[4,   400/  446] train loss: 0.150 train accuracy: 1.000\n",
      "epoch: 4 validation accuracy: 0.235\n",
      "[5,   100/  446] train loss: 0.157 train accuracy: 0.992\n",
      "[5,   200/  446] train loss: 0.098 train accuracy: 1.000\n",
      "[5,   300/  446] train loss: 0.119 train accuracy: 1.000\n",
      "[5,   400/  446] train loss: 0.128 train accuracy: 1.000\n",
      "epoch: 5 validation accuracy: 0.268\n",
      "[6,   100/  446] train loss: 0.124 train accuracy: 1.000\n",
      "[6,   200/  446] train loss: 0.116 train accuracy: 1.000\n",
      "[6,   300/  446] train loss: 0.124 train accuracy: 1.000\n",
      "[6,   400/  446] train loss: 0.099 train accuracy: 1.000\n",
      "epoch: 6 validation accuracy: 0.290\n",
      "[7,   100/  446] train loss: 0.140 train accuracy: 1.000\n",
      "[7,   200/  446] train loss: 0.104 train accuracy: 1.000\n",
      "[7,   300/  446] train loss: 0.116 train accuracy: 1.000\n",
      "[7,   400/  446] train loss: 0.108 train accuracy: 1.000\n",
      "epoch: 7 validation accuracy: 0.312\n",
      "[8,   100/  446] train loss: 0.109 train accuracy: 1.000\n",
      "[8,   200/  446] train loss: 0.119 train accuracy: 1.000\n",
      "[8,   300/  446] train loss: 0.112 train accuracy: 1.000\n",
      "[8,   400/  446] train loss: 0.087 train accuracy: 1.000\n",
      "epoch: 8 validation accuracy: 0.330\n",
      "[9,   100/  446] train loss: 0.071 train accuracy: 1.000\n",
      "[9,   200/  446] train loss: 0.077 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.090 train accuracy: 1.000\n",
      "[9,   400/  446] train loss: 0.101 train accuracy: 1.000\n",
      "epoch: 9 validation accuracy: 0.347\n",
      "[10,   100/  446] train loss: 0.098 train accuracy: 1.000\n",
      "[10,   200/  446] train loss: 0.068 train accuracy: 1.000\n",
      "[10,   300/  446] train loss: 0.078 train accuracy: 1.000\n",
      "[10,   400/  446] train loss: 0.096 train accuracy: 1.000\n",
      "epoch: 10 validation accuracy: 0.364\n",
      "[11,   100/  446] train loss: 0.081 train accuracy: 1.000\n",
      "[11,   200/  446] train loss: 0.096 train accuracy: 1.000\n",
      "[11,   300/  446] train loss: 0.083 train accuracy: 1.000\n",
      "[11,   400/  446] train loss: 0.071 train accuracy: 1.000\n",
      "epoch: 11 validation accuracy: 0.392\n",
      "[12,   100/  446] train loss: 0.079 train accuracy: 1.000\n",
      "[12,   200/  446] train loss: 0.068 train accuracy: 1.000\n",
      "[12,   300/  446] train loss: 0.076 train accuracy: 1.000\n",
      "[12,   400/  446] train loss: 0.085 train accuracy: 1.000\n",
      "epoch: 12 validation accuracy: 0.414\n",
      "[13,   100/  446] train loss: 0.079 train accuracy: 1.000\n",
      "[13,   200/  446] train loss: 0.072 train accuracy: 1.000\n",
      "[13,   300/  446] train loss: 0.087 train accuracy: 1.000\n",
      "[13,   400/  446] train loss: 0.069 train accuracy: 1.000\n",
      "epoch: 13 validation accuracy: 0.413\n",
      "[14,   100/  446] train loss: 0.077 train accuracy: 1.000\n",
      "[14,   200/  446] train loss: 0.076 train accuracy: 1.000\n",
      "[14,   300/  446] train loss: 0.077 train accuracy: 1.000\n",
      "[14,   400/  446] train loss: 0.055 train accuracy: 1.000\n",
      "epoch: 14 validation accuracy: 0.431\n",
      "[15,   100/  446] train loss: 0.074 train accuracy: 1.000\n",
      "[15,   200/  446] train loss: 0.062 train accuracy: 1.000\n",
      "[15,   300/  446] train loss: 0.080 train accuracy: 1.000\n",
      "[15,   400/  446] train loss: 0.078 train accuracy: 1.000\n",
      "epoch: 15 validation accuracy: 0.440\n",
      "[16,   100/  446] train loss: 0.072 train accuracy: 1.000\n",
      "[16,   200/  446] train loss: 0.064 train accuracy: 1.000\n",
      "[16,   300/  446] train loss: 0.062 train accuracy: 1.000\n",
      "[16,   400/  446] train loss: 0.068 train accuracy: 1.000\n",
      "epoch: 16 validation accuracy: 0.456\n",
      "[17,   100/  446] train loss: 0.074 train accuracy: 1.000\n",
      "[17,   200/  446] train loss: 0.064 train accuracy: 1.000\n",
      "[17,   300/  446] train loss: 0.063 train accuracy: 1.000\n",
      "[17,   400/  446] train loss: 0.063 train accuracy: 1.000\n",
      "epoch: 17 validation accuracy: 0.461\n",
      "[18,   100/  446] train loss: 0.062 train accuracy: 1.000\n",
      "[18,   200/  446] train loss: 0.064 train accuracy: 1.000\n",
      "[18,   300/  446] train loss: 0.052 train accuracy: 1.000\n",
      "[18,   400/  446] train loss: 0.053 train accuracy: 1.000\n",
      "epoch: 18 validation accuracy: 0.472\n",
      "[19,   100/  446] train loss: 0.065 train accuracy: 0.992\n",
      "[19,   200/  446] train loss: 0.051 train accuracy: 1.000\n",
      "[19,   300/  446] train loss: 0.066 train accuracy: 1.000\n",
      "[19,   400/  446] train loss: 0.062 train accuracy: 1.000\n",
      "epoch: 19 validation accuracy: 0.478\n",
      "[20,   100/  446] train loss: 0.062 train accuracy: 1.000\n",
      "[20,   200/  446] train loss: 0.056 train accuracy: 1.000\n",
      "[20,   300/  446] train loss: 0.052 train accuracy: 1.000\n",
      "[20,   400/  446] train loss: 0.060 train accuracy: 1.000\n",
      "epoch: 20 validation accuracy: 0.493\n",
      "epoch: 0 validation accuracy: 0.493\n",
      "[1,   100/  446] train loss: 0.784 train accuracy: 0.922\n",
      "[1,   200/  446] train loss: 0.664 train accuracy: 0.938\n",
      "[1,   300/  446] train loss: 0.678 train accuracy: 0.930\n",
      "[1,   400/  446] train loss: 0.635 train accuracy: 0.914\n",
      "epoch: 1 validation accuracy: 0.937\n",
      "[2,   100/  446] train loss: 0.660 train accuracy: 0.914\n",
      "[2,   200/  446] train loss: 0.529 train accuracy: 0.930\n",
      "[2,   300/  446] train loss: 0.605 train accuracy: 0.930\n",
      "[2,   400/  446] train loss: 0.585 train accuracy: 0.930\n",
      "epoch: 2 validation accuracy: 0.946\n",
      "[3,   100/  446] train loss: 0.559 train accuracy: 0.930\n",
      "[3,   200/  446] train loss: 0.342 train accuracy: 0.984\n",
      "[3,   300/  446] train loss: 0.563 train accuracy: 0.961\n",
      "[3,   400/  446] train loss: 0.627 train accuracy: 0.898\n",
      "epoch: 3 validation accuracy: 0.948\n",
      "[4,   100/  446] train loss: 0.530 train accuracy: 0.953\n",
      "[4,   200/  446] train loss: 0.499 train accuracy: 0.953\n",
      "[4,   300/  446] train loss: 0.419 train accuracy: 0.945\n",
      "[4,   400/  446] train loss: 0.551 train accuracy: 0.906\n",
      "epoch: 4 validation accuracy: 0.948\n",
      "[5,   100/  446] train loss: 0.466 train accuracy: 0.953\n",
      "[5,   200/  446] train loss: 0.486 train accuracy: 0.969\n",
      "[5,   300/  446] train loss: 0.434 train accuracy: 0.953\n",
      "[5,   400/  446] train loss: 0.443 train accuracy: 0.969\n",
      "epoch: 5 validation accuracy: 0.951\n",
      "[6,   100/  446] train loss: 0.506 train accuracy: 0.953\n",
      "[6,   200/  446] train loss: 0.510 train accuracy: 0.938\n",
      "[6,   300/  446] train loss: 0.473 train accuracy: 0.930\n",
      "[6,   400/  446] train loss: 0.428 train accuracy: 0.953\n",
      "epoch: 6 validation accuracy: 0.952\n",
      "[7,   100/  446] train loss: 0.347 train accuracy: 0.977\n",
      "[7,   200/  446] train loss: 0.384 train accuracy: 0.977\n",
      "[7,   300/  446] train loss: 0.433 train accuracy: 0.969\n",
      "[7,   400/  446] train loss: 0.416 train accuracy: 0.961\n",
      "epoch: 7 validation accuracy: 0.952\n",
      "[8,   100/  446] train loss: 0.333 train accuracy: 0.969\n",
      "[8,   200/  446] train loss: 0.347 train accuracy: 0.977\n",
      "[8,   300/  446] train loss: 0.375 train accuracy: 0.969\n",
      "[8,   400/  446] train loss: 0.299 train accuracy: 0.969\n",
      "epoch: 8 validation accuracy: 0.954\n",
      "[9,   100/  446] train loss: 0.303 train accuracy: 0.977\n",
      "[9,   200/  446] train loss: 0.277 train accuracy: 1.000\n",
      "[9,   300/  446] train loss: 0.292 train accuracy: 0.977\n",
      "[9,   400/  446] train loss: 0.445 train accuracy: 0.938\n",
      "epoch: 9 validation accuracy: 0.954\n",
      "[10,   100/  446] train loss: 0.328 train accuracy: 0.961\n",
      "[10,   200/  446] train loss: 0.341 train accuracy: 0.969\n",
      "[10,   300/  446] train loss: 0.380 train accuracy: 0.953\n",
      "[10,   400/  446] train loss: 0.439 train accuracy: 0.953\n",
      "epoch: 10 validation accuracy: 0.954\n",
      "[11,   100/  446] train loss: 0.303 train accuracy: 0.977\n",
      "[11,   200/  446] train loss: 0.332 train accuracy: 0.953\n",
      "[11,   300/  446] train loss: 0.317 train accuracy: 0.953\n",
      "[11,   400/  446] train loss: 0.339 train accuracy: 0.977\n",
      "epoch: 11 validation accuracy: 0.956\n",
      "[12,   100/  446] train loss: 0.378 train accuracy: 0.953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,   200/  446] train loss: 0.311 train accuracy: 0.977\n",
      "[12,   300/  446] train loss: 0.329 train accuracy: 0.977\n",
      "[12,   400/  446] train loss: 0.273 train accuracy: 0.984\n",
      "epoch: 12 validation accuracy: 0.955\n",
      "[13,   100/  446] train loss: 0.372 train accuracy: 0.945\n",
      "[13,   200/  446] train loss: 0.386 train accuracy: 0.922\n",
      "[13,   300/  446] train loss: 0.295 train accuracy: 0.992\n",
      "[13,   400/  446] train loss: 0.423 train accuracy: 0.938\n",
      "epoch: 13 validation accuracy: 0.957\n",
      "[14,   100/  446] train loss: 0.504 train accuracy: 0.930\n",
      "[14,   200/  446] train loss: 0.396 train accuracy: 0.961\n",
      "[14,   300/  446] train loss: 0.373 train accuracy: 0.945\n",
      "[14,   400/  446] train loss: 0.365 train accuracy: 0.977\n",
      "epoch: 14 validation accuracy: 0.956\n",
      "[15,   100/  446] train loss: 0.477 train accuracy: 0.953\n",
      "[15,   200/  446] train loss: 0.306 train accuracy: 0.969\n",
      "[15,   300/  446] train loss: 0.274 train accuracy: 0.977\n",
      "[15,   400/  446] train loss: 0.283 train accuracy: 0.977\n",
      "epoch: 15 validation accuracy: 0.956\n",
      "[16,   100/  446] train loss: 0.388 train accuracy: 0.953\n",
      "[16,   200/  446] train loss: 0.579 train accuracy: 0.914\n",
      "[16,   300/  446] train loss: 0.345 train accuracy: 0.969\n",
      "[16,   400/  446] train loss: 0.364 train accuracy: 0.961\n",
      "epoch: 16 validation accuracy: 0.955\n",
      "[17,   100/  446] train loss: 0.236 train accuracy: 0.977\n",
      "[17,   200/  446] train loss: 0.408 train accuracy: 0.945\n",
      "[17,   300/  446] train loss: 0.285 train accuracy: 0.977\n",
      "[17,   400/  446] train loss: 0.461 train accuracy: 0.953\n",
      "epoch: 17 validation accuracy: 0.956\n",
      "[18,   100/  446] train loss: 0.309 train accuracy: 0.977\n",
      "[18,   200/  446] train loss: 0.306 train accuracy: 0.953\n",
      "[18,   300/  446] train loss: 0.354 train accuracy: 0.969\n",
      "[18,   400/  446] train loss: 0.291 train accuracy: 0.992\n",
      "epoch: 18 validation accuracy: 0.957\n",
      "[19,   100/  446] train loss: 0.355 train accuracy: 0.953\n",
      "[19,   200/  446] train loss: 0.330 train accuracy: 0.961\n",
      "[19,   300/  446] train loss: 0.339 train accuracy: 0.969\n",
      "[19,   400/  446] train loss: 0.358 train accuracy: 0.945\n",
      "epoch: 19 validation accuracy: 0.957\n",
      "[20,   100/  446] train loss: 0.346 train accuracy: 0.953\n",
      "[20,   200/  446] train loss: 0.260 train accuracy: 0.977\n",
      "[20,   300/  446] train loss: 0.304 train accuracy: 0.984\n",
      "[20,   400/  446] train loss: 0.357 train accuracy: 0.953\n",
      "epoch: 20 validation accuracy: 0.957\n"
     ]
    }
   ],
   "source": [
    "temperatures = [5]\n",
    "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "# loss = alpha * st + (1 - alpha) * tt\n",
    "alphas = [0.8, 0.5, 0.4, 0.2]\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['alpha'] = hparam_tuple[0]\n",
    "    hparam['T'] = hparam_tuple[1]\n",
    "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[3]\n",
    "    hparam['lr_decay'] = hparam_tuple[4]\n",
    "    hparam['momentum'] = hparam_tuple[5]\n",
    "    hparam['lr'] = hparam_tuple[6]\n",
    "    hparams_list.append(hparam)\n",
    "\n",
    "results_distill = {}\n",
    "for hparam in hparams_list:\n",
    "    print('Training with hparams' + utils.hparamToString(hparam))\n",
    "    reproducibilitySeed()\n",
    "    student_net = networks.StudentNetwork()\n",
    "    student_net = student_net.to(fast_device)\n",
    "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
    "    results_distill[hparam_tuple] = [None, None]\n",
    "    results_distill[hparam_tuple][0] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
    "                                                                    train_loader, val_loader, \n",
    "                                                                    print_every=print_every, \n",
    "                                                                    fast_device=fast_device)\n",
    "    results_distill[hparam_tuple][1] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs_bf, \n",
    "                                                                    train_balanced_loader, val_loader, \n",
    "                                                                    print_every=print_every, \n",
    "                                                                    fast_device=fast_device, \n",
    "                                                                    only_penultimate_train=True)\n",
    "    save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    torch.save({'results' : results_distill[hparam_tuple], \n",
    "                'model_state_dict' : student_net.state_dict(), \n",
    "                'epoch' : num_epochs}, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [10, 5]\n",
    "T_scatter = [math.log(h['T']) for h in hparams_list]\n",
    "alpha_scatter = [h['alpha'] for h in hparams_list]\n",
    "colors = []\n",
    "for i in range(len(hparams_list)):\n",
    "    cur_hparam_tuple = utils.hparamDictToTuple(hparams_list[i])\n",
    "    colors.append(results_distill[cur_hparam_tuple]['val_acc'][-1])\n",
    "    \n",
    "marker_size = 100\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(T_scatter, alpha_scatter, marker_size, c=colors, edgecolors='black')\n",
    "plt.colorbar()\n",
    "for i in range(len(T_scatter)):\n",
    "    ax.annotate(str('%0.4f' % (colors[i], )), (T_scatter[i], alpha_scatter[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "color = ['r', 'b', 'g', 'm']\n",
    "for hparam, c in zip(hparams_list, color):\n",
    "    cur_results = results_distill[utils.hparamDictToTuple(hparam)]\n",
    "    val_acc = cur_results[0]['val_acc'] + cur_results[1]['val_acc']\n",
    "    plt.plot(val_acc, color=c, label=str(hparam['alpha']))\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.title('Validation Accuracy vs Epoch for different alpha')\n",
    "plt.savefig(summaries_path_student + 'val_acc_vs_epoch_wrt_alpha.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T=5, alpha=0.8, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "test accuracy:  0.9745\n",
      "\n",
      "T=5, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "test accuracy:  0.9725\n",
      "\n",
      "T=5, alpha=0.4, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "test accuracy:  0.9708\n",
      "\n",
      "T=5, alpha=0.2, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "test accuracy:  0.9633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hparam in hparams_list:\n",
    "    load_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
    "    load_dict = torch.load(load_path)\n",
    "    student_net = networks.StudentNetwork()\n",
    "    student_net.load_state_dict(load_dict['model_state_dict'])\n",
    "    student_net = student_net.to(fast_device)\n",
    "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
    "    print(utils.hparamToString(hparam))\n",
    "    print('test accuracy: ', test_accuracy)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
