{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and init GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "\n",
    "from tuner import HyperparameterTuner\n",
    "from tuner import MyTask\n",
    "\n",
    "use_tpu = False\n",
    "use_gpu = True\n",
    "\n",
    "if use_tpu:\n",
    "    from tensorflow.contrib import tpu\n",
    "    from tensorflow.contrib.cluster_resolver import TPUClusterResolver\n",
    "\n",
    "if use_gpu:\n",
    "    import os\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_tpu:\n",
    "    tpu_cluster = TPUClusterResolver(tpu=[tpu_name]).get_master()\n",
    "    sess = tf.Session(tpu_cluster)\n",
    "    sess.run(tpu.initialize_system())\n",
    "elif use_gpu:\n",
    "    sess = tf.Session(config=config)\n",
    "else:\n",
    "    sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_home = ''\n",
    "if use_tpu:\n",
    "    pass\n",
    "#     task_home = 'gs://continual_learning/permMNIST_EWC/'\n",
    "else:\n",
    "    task_home = '../../../../../'\n",
    "\n",
    "cur_dir = './'\n",
    "checkpoint_path = cur_dir + 'checkpoints_0/'\n",
    "summaries_path = cur_dir + 'summaries_0/'\n",
    "data_path = task_home + 'cifar-100-python/'\n",
    "split_path = './split.txt' \n",
    "if use_tpu:\n",
    "    tpu_name = 'gectpu'\n",
    "    \n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     2,
     29,
     36,
     41
    ]
   },
   "outputs": [],
   "source": [
    "label_smooth_param = 0\n",
    "\n",
    "def splitDataset(dataset, dataset_split, seed):\n",
    "    np.random.seed(seed)\n",
    "    task_list = []\n",
    "    train_labels = np.argmax(dataset.train.labels, axis=1)\n",
    "    validation_labels = np.argmax(dataset.validation.labels, axis=1)\n",
    "    test_labels = np.argmax(dataset.test.labels, axis=1)\n",
    "    for i in range(len(dataset_split)):\n",
    "        cur_train_indices = [False] * dataset.train.images.shape[0]\n",
    "        cur_validation_indices = [False] * dataset.validation.images.shape[0]\n",
    "        cur_test_indices = [False] * dataset.test.images.shape[0]\n",
    "        for j in range(len(dataset_split[i])):\n",
    "            cur_train_indices = np.logical_or(cur_train_indices, (train_labels == dataset_split[i][j]))\n",
    "            cur_validation_indices = np.logical_or(cur_validation_indices, (validation_labels == dataset_split[i][j]))\n",
    "            cur_test_indices = np.logical_or(cur_test_indices, (test_labels == dataset_split[i][j]))\n",
    "\n",
    "        task = deepcopy(dataset)\n",
    "        task.train.images = task.train.images[cur_train_indices]\n",
    "        task.train.labels = task.train.labels[cur_train_indices]\n",
    "        task.validation.images = task.validation.images[cur_validation_indices]\n",
    "        task.validation.labels = task.validation.labels[cur_validation_indices]\n",
    "        task.test.images = task.test.images[cur_test_indices]\n",
    "        task.test.labels = task.test.labels[cur_test_indices]\n",
    "        task = MyTask(task)\n",
    "        task_list.append(task)\n",
    "\n",
    "    return task_list\n",
    "    \n",
    "def smoothLabels(dataset):\n",
    "    train_labels = dataset.train.labels\n",
    "    train_labels_argmax = np.argmax(train_labels, axis=1)\n",
    "    train_labels = train_labels + label_smooth_param / (train_labels.shape[1] - 1)\n",
    "    train_labels[range(train_labels.shape[0]), train_labels_argmax] = 1 - label_smooth_param\n",
    "    dataset.train._labels = train_labels\n",
    "\n",
    "class TempDataset(object):\n",
    "    def __init__(self):\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "    \n",
    "class TempTask(object):\n",
    "    def __init__(self):\n",
    "        self.train = TempDataset()\n",
    "        self.validation = TempDataset()\n",
    "        self.test = TempDataset()\n",
    "    \n",
    "    \n",
    "def readDatasets():\n",
    "    num_class = 100\n",
    "    labels_list = list(range(num_class))\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(labels_list)\n",
    "    split = []\n",
    "    task_weights = []\n",
    "    \n",
    "    split = [labels_list[ : 90]]\n",
    "    task_weights = [0.90]\n",
    "    for single_label in labels_list[90 : ]:\n",
    "        split.append([single_label])\n",
    "        task_weights.append(0.01)\n",
    "    num_tasks = len(split)\n",
    "    \n",
    "    with open(data_path + 'train', 'rb') as f:\n",
    "        f_train_data = pickle.load(f, encoding='bytes')\n",
    "        \n",
    "    with open(data_path + 'test', 'rb') as f:\n",
    "        f_test_data = pickle.load(f, encoding='bytes')\n",
    "        \n",
    "    cifar_100 = TempTask()\n",
    "    temp_train_labels = np.array(f_train_data[b'fine_labels'], dtype=np.int32)\n",
    "    temp_test_labels = np.array(f_test_data[b'fine_labels'], dtype=np.int32)\n",
    "    f_train_data[b'fine_labels'] = np.zeros((temp_train_labels.shape[0], num_class))\n",
    "    (f_train_data[b'fine_labels'])[range(temp_train_labels.shape[0]), temp_train_labels] = 1\n",
    "    f_test_data[b'fine_labels'] = np.zeros((temp_test_labels.shape[0], num_class))\n",
    "    (f_test_data[b'fine_labels'])[range(temp_test_labels.shape[0]), temp_test_labels] = 1\n",
    "    f_train_data[b'data'] = np.reshape(f_train_data[b'data'], (-1, 3, 32, 32))\n",
    "    f_test_data[b'data'] = np.reshape(f_test_data[b'data'], (-1, 3, 32, 32))\n",
    "    f_train_data[b'data'] = np.transpose(f_train_data[b'data'], (0, 2, 3, 1))\n",
    "    f_test_data[b'data'] = np.transpose(f_test_data[b'data'], (0, 2, 3, 1))\n",
    "    \n",
    "    tr_data = f_train_data[b'data']\n",
    "    te_data = f_test_data[b'data']\n",
    "    # normalizing data\n",
    "    avg = np.mean(tr_data, axis=(0, 1, 2))\n",
    "    std = np.std(tr_data, axis=(0, 1, 2))\n",
    "    \n",
    "    f_train_data[b'data'] = (tr_data - avg) / std\n",
    "    f_test_data[b'data'] = (te_data - avg) / std\n",
    "    \n",
    "    seed = 0\n",
    "    np.random.seed(0)\n",
    "    shuffle_train_perm = np.random.permutation(f_train_data[b'data'].shape[0])\n",
    "    f_train_data[b'data'] = f_train_data[b'data'][shuffle_train_perm]\n",
    "    f_train_data[b'fine_labels'] = f_train_data[b'fine_labels'][shuffle_train_perm]\n",
    "    \n",
    "    num_val_per_class = 20\n",
    "    \n",
    "    for i in range(num_class):\n",
    "        pos = (np.argmax(f_train_data[b'fine_labels'], axis=1) == i)\n",
    "        \n",
    "        if (i == 0):\n",
    "            cifar_100.validation.images = (f_train_data[b'data'][pos])[0 : num_val_per_class]\n",
    "            cifar_100.validation.labels = (f_train_data[b'fine_labels'][pos])[0 : num_val_per_class]\n",
    "\n",
    "            cifar_100.train.images = (f_train_data[b'data'][pos])[num_val_per_class : ]\n",
    "            cifar_100.train.labels = (f_train_data[b'fine_labels'][pos])[num_val_per_class : ]\n",
    "        else:\n",
    "            cifar_100.validation.images = np.concatenate((cifar_100.validation.images, (f_train_data[b'data'][pos])[0 : num_val_per_class]))\n",
    "            cifar_100.validation.labels = np.concatenate((cifar_100.validation.labels, (f_train_data[b'fine_labels'][pos])[0 : num_val_per_class]))\n",
    "\n",
    "            cifar_100.train.images = np.concatenate((cifar_100.train.images, (f_train_data[b'data'][pos])[num_val_per_class : ]))\n",
    "            cifar_100.train.labels = np.concatenate((cifar_100.train.labels, (f_train_data[b'fine_labels'][pos])[num_val_per_class : ]))\n",
    "        \n",
    "    cifar_100.test.images = f_test_data[b'data']\n",
    "    cifar_100.test.labels = f_test_data[b'fine_labels']\n",
    "    \n",
    "    shuffle_train_perm = np.random.permutation(cifar_100.train.images.shape[0])\n",
    "    cifar_100.train.images = cifar_100.train.images[shuffle_train_perm]\n",
    "    cifar_100.train.labels = cifar_100.train.labels[shuffle_train_perm]\n",
    "    \n",
    "    if (label_smooth_param != 0):\n",
    "        smoothLabels(cifar_100)\n",
    "        \n",
    "    task_list = splitDataset(cifar_100, split, seed)\n",
    "    return split, num_tasks, task_weights, task_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tuner object and train!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "output_shape = (100, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../../../../classifiers.py:100: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(sess=sess, network=network, \n",
    "                            input_shape=input_shape, output_shape=output_shape,\n",
    "                            checkpoint_path=checkpoint_path, summaries_path=summaries_path, \n",
    "                            readDatasets=readDatasets, load_best_hparams=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.setPerExampleAppend(1.0)\n",
    "tuner.updateTunerHparams({'mask_softmax' : True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training each task separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "learning_rates = [1e-1]\n",
    "momentums = [0.9]\n",
    "regs = [0.0001]\n",
    "dropout_input_probs = [1.0]\n",
    "dropout_hidden_probs = [0.9]\n",
    "prod = list(itertools.product(regs, dropout_input_probs, dropout_hidden_probs, momentums, learning_rates))\n",
    "hparams = []\n",
    "for hparams_tuple in prod:\n",
    "    cur_dict = {}\n",
    "    cur_dict['reg'] = hparams_tuple[0]\n",
    "    cur_dict['dropout_input_prob'] = hparams_tuple[2]\n",
    "    cur_dict['dropout_hidden_prob'] = hparams_tuple[2]\n",
    "    cur_dict['momentum'] = hparams_tuple[3]\n",
    "    cur_dict['learning_rate'] = hparams_tuple[4]\n",
    "    hparams.append(cur_dict)\n",
    "\n",
    "tuner.hparams_list[t] = hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 160\n",
    "num_updates = math.ceil(tuner.task_list[t].train.images.shape[0] / BATCH_SIZE) * num_epochs\n",
    "tuner.print_every = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "best_avg, best_hparams = tuner.tuneOnTask(t, BATCH_SIZE, \n",
    "                                          save_weights=False, \n",
    "                                          num_updates=num_updates, verbose=True, \n",
    "                                          random_crop_flip=True)\n",
    "print(\"time taken : %d\" % (time.time() - start_time))\n",
    "sound_file = '/mnt/a99/d0/shriramsb/code/Alan Walker - Alone.mp3'\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "lr_scatter = ([math.log10(h['learning_rate']) for h in hparams])\n",
    "dropout_scatter = [h['dropout_hidden_prob'] for h in hparams]\n",
    "colors = []\n",
    "for i in range(len(hparams)):\n",
    "    cur_hparam_tuple = tuner.hparamsDictToTuple(hparams[i], tuner.tuner_hparams)\n",
    "    colors.append(tuner.results_list[t][cur_hparam_tuple]['best_avg'])\n",
    "    \n",
    "marker_size = 100\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(lr_scatter, dropout_scatter, marker_size, c=colors, edgecolors='black')\n",
    "plt.colorbar()\n",
    "for i in range(len(lr_scatter)):\n",
    "    ax.annotate(str('%0.4f' % (colors[i], )), (lr_scatter[i], dropout_scatter[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "best_hparams_tuple = tuner.hparamsDictToTuple(hparams[0], tuner.tuner_hparams)\n",
    "cur_res = tuner.results_list[t][best_hparams_tuple]\n",
    "x = np.arange(0, cur_res['total_updates'], cur_res['updates_per_epoch'])\n",
    "cur_best_avg = cur_res['best_avg']\n",
    "cur_best_avg_updates = cur_res['best_avg_updates']\n",
    "updates_per_epoch = cur_res['updates_per_epoch']\n",
    "# print(\"dropout: %f, fisher_multiplier: %e, lr: %e\" % (k[0], k[1], k[2]))\n",
    "print(\"cur_best_avg: %e, num_updates: %d\" % (cur_best_avg, cur_best_avg_updates))\n",
    "print(\"best val_acc: %s\" % (str(np.array(cur_res['val_acc'])[:, (cur_best_avg_updates // updates_per_epoch - 1) // tuner.eval_frequency])))\n",
    "# plt.plot(cur_res['loss_with_penalty'], color='g')\n",
    "plt.plot(cur_res['loss'], color='m')\n",
    "plt.plot(x, cur_res['val_loss'][-1], color='b')\n",
    "plt.show()\n",
    "# plt.ylim(ymin=0.9)\n",
    "plt.plot(cur_res['val_acc'][0], color='b', )\n",
    "# plt.plot(cur_res['val_acc'][1], color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(best_avg, best_hparams)\n",
    "VALIDATION_BATCH_SIZE = 128\n",
    "print(tuner.validationAccuracy(t, VALIDATION_BATCH_SIZE, restore_model=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t = 1\n",
    "learning_rates = [1e-1]\n",
    "momentums = [0.9]\n",
    "regs = [0.0001]\n",
    "dropout_input_probs = [1.0]\n",
    "dropout_hidden_probs = [0.9]\n",
    "prod = list(itertools.product(regs, dropout_input_probs, dropout_hidden_probs, momentums, learning_rates))\n",
    "hparams = []\n",
    "for hparams_tuple in prod:\n",
    "    cur_dict = {}\n",
    "    cur_dict['reg'] = hparams_tuple[0]\n",
    "    cur_dict['dropout_input_prob'] = hparams_tuple[2]\n",
    "    cur_dict['dropout_hidden_prob'] = hparams_tuple[2]\n",
    "    cur_dict['momentum'] = hparams_tuple[3]\n",
    "    cur_dict['learning_rate'] = hparams_tuple[4]\n",
    "    hparams.append(cur_dict)\n",
    "\n",
    "tuner.hparams_list[t] = hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 160\n",
    "num_updates = math.ceil(tuner.task_list[t].train.images.shape[0] / BATCH_SIZE) * num_epochs\n",
    "tuner.print_every = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "best_avg, best_hparams = tuner.tuneOnTask(t, BATCH_SIZE, \n",
    "                                          save_weights=False, \n",
    "                                          num_updates=num_updates, verbose=True, \n",
    "                                          random_crop_flip=True)\n",
    "print(\"time taken : %d\" % (time.time() - start_time))\n",
    "sound_file = '/mnt/a99/d0/shriramsb/code/Alan Walker - Alone.mp3'\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "lr_scatter = ([math.log10(h['learning_rate']) for h in hparams])\n",
    "dropout_scatter = [h['dropout_hidden_prob'] for h in hparams]\n",
    "colors = []\n",
    "for i in range(len(hparams)):\n",
    "    cur_hparam_tuple = tuner.hparamsDictToTuple(hparams[i], tuner.tuner_hparams)\n",
    "    colors.append(tuner.results_list[t][cur_hparam_tuple]['best_avg'])\n",
    "    \n",
    "marker_size = 100\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(lr_scatter, dropout_scatter, marker_size, c=colors, edgecolors='black')\n",
    "plt.colorbar()\n",
    "for i in range(len(lr_scatter)):\n",
    "    ax.annotate(str('%0.4f' % (colors[i], )), (lr_scatter[i], dropout_scatter[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "best_hparams_tuple = tuner.hparamsDictToTuple(hparams[0], tuner.tuner_hparams)\n",
    "cur_res = tuner.results_list[t][best_hparams_tuple]\n",
    "x = np.arange(0, cur_res['total_updates'], cur_res['updates_per_epoch'])\n",
    "cur_best_avg = cur_res['best_avg']\n",
    "cur_best_avg_updates = cur_res['best_avg_updates']\n",
    "updates_per_epoch = cur_res['updates_per_epoch']\n",
    "# print(\"dropout: %f, fisher_multiplier: %e, lr: %e\" % (k[0], k[1], k[2]))\n",
    "print(\"cur_best_avg: %e, num_updates: %d\" % (cur_best_avg, cur_best_avg_updates))\n",
    "print(\"best val_acc: %s\" % (str(np.array(cur_res['val_acc'])[:, (cur_best_avg_updates // updates_per_epoch - 1) // tuner.eval_frequency])))\n",
    "# plt.plot(cur_res['loss_with_penalty'], color='g')\n",
    "plt.plot(cur_res['loss'], color='m')\n",
    "plt.plot(x, cur_res['val_loss'][-1], color='b')\n",
    "plt.show()\n",
    "# plt.ylim(ymin=0.9)\n",
    "plt.plot(cur_res['val_acc'][0], color='b', )\n",
    "plt.plot(cur_res['val_acc'][1], color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train tasks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "learning_rates = [(((49, 1e-1), (63, 1e-1 / 5), 1e-1 / (5 * 5)), (1e-1, ))]\n",
    "momentums = [0.9]\n",
    "regs = [0.00001]\n",
    "dropout_input_probs = [1.0]\n",
    "dropout_hidden_probs = [0.9]\n",
    "prod = list(itertools.product(regs, dropout_input_probs, dropout_hidden_probs, momentums, learning_rates))\n",
    "hparams = []\n",
    "for hparams_tuple in prod:\n",
    "    cur_dict = {}\n",
    "    cur_dict['reg'] = hparams_tuple[0]\n",
    "    cur_dict['dropout_input_prob'] = hparams_tuple[2]\n",
    "    cur_dict['dropout_hidden_prob'] = hparams_tuple[2]\n",
    "    cur_dict['momentum'] = hparams_tuple[3]\n",
    "    cur_dict['learning_rate'] = hparams_tuple[4]\n",
    "    hparams.append(cur_dict)\n",
    "    \n",
    "for i in range(0, t + 1):\n",
    "    tuner.hparams_list[i] = hparams\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hparams = len(hparams)\n",
    "num_epochs = 70\n",
    "num_updates = math.ceil(tuner.task_list[t].train.images.shape[0] / BATCH_SIZE) * num_epochs\n",
    "tuner.print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with T=None,alpha=0.0,dropout_hidden_prob=0.9,dropout_input_prob=0.9,epsilon=0.0,fisher_multiplier=0.0,learning_rate=too_long,momentum=0.9,reg=1e-05,bf_num_images=2000,mask_softmax=True,old:new=1.0,task=0\n",
      "count new class: 0\n",
      "epoch: 0, iter: 0/338, validation accuracies: [0.01111111], average train loss: nan, average train accuracy: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/a99/d0/shriramsb/tf_venv/.env/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/mnt/a99/d0/shriramsb/tf_venv/.env/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 100/338, loss: 3.973179, accuracy: 0.062500\n",
      "epoch: 0, iter: 200/338, loss: 3.803414, accuracy: 0.101562\n",
      "epoch: 0, iter: 300/338, loss: 3.734842, accuracy: 0.093750\n",
      "count new class: 0\n",
      "epoch: 1, iter: 0/338, validation accuracies: [0.09277778], average train loss: 4.006732, average train accuracy: 0.067654\n",
      "epoch: 1, iter: 62/338, loss: 3.670586, accuracy: 0.085938\n",
      "epoch: 1, iter: 162/338, loss: 3.465936, accuracy: 0.109375\n",
      "epoch: 1, iter: 262/338, loss: 3.498276, accuracy: 0.164062\n",
      "count new class: 0\n",
      "epoch: 2, iter: 0/338, validation accuracies: [0.18444445], average train loss: 3.464753, average train accuracy: 0.155187\n",
      "epoch: 2, iter: 24/338, loss: 2.918329, accuracy: 0.179688\n",
      "epoch: 2, iter: 124/338, loss: 2.971162, accuracy: 0.242188\n",
      "epoch: 2, iter: 224/338, loss: 2.987640, accuracy: 0.304688\n",
      "epoch: 2, iter: 324/338, loss: 2.950171, accuracy: 0.273438\n",
      "count new class: 0\n",
      "epoch: 3, iter: 0/338, validation accuracies: [0.26499999], average train loss: 3.024389, average train accuracy: 0.236594\n",
      "epoch: 3, iter: 86/338, loss: 2.750528, accuracy: 0.296875\n",
      "epoch: 3, iter: 186/338, loss: 2.582305, accuracy: 0.328125\n",
      "epoch: 3, iter: 286/338, loss: 2.767455, accuracy: 0.296875\n",
      "count new class: 0\n",
      "epoch: 4, iter: 0/338, validation accuracies: [0.28722222], average train loss: 2.687556, average train accuracy: 0.305681\n",
      "epoch: 4, iter: 48/338, loss: 2.481462, accuracy: 0.312500\n",
      "epoch: 4, iter: 148/338, loss: 2.353767, accuracy: 0.359375\n",
      "epoch: 4, iter: 248/338, loss: 2.408099, accuracy: 0.335938\n",
      "count new class: 0\n",
      "epoch: 5, iter: 0/338, validation accuracies: [0.375], average train loss: 2.375383, average train accuracy: 0.367372\n",
      "epoch: 5, iter: 10/338, loss: 2.429046, accuracy: 0.390625\n",
      "epoch: 5, iter: 110/338, loss: 2.031659, accuracy: 0.460938\n",
      "epoch: 5, iter: 210/338, loss: 2.092623, accuracy: 0.476562\n",
      "epoch: 5, iter: 310/338, loss: 2.112135, accuracy: 0.398438\n",
      "count new class: 0\n",
      "epoch: 6, iter: 0/338, validation accuracies: [0.42277778], average train loss: 2.160910, average train accuracy: 0.417784\n",
      "epoch: 6, iter: 72/338, loss: 1.952878, accuracy: 0.468750\n",
      "epoch: 6, iter: 172/338, loss: 1.927047, accuracy: 0.460938\n",
      "epoch: 6, iter: 272/338, loss: 2.090720, accuracy: 0.445312\n",
      "count new class: 0\n",
      "epoch: 7, iter: 0/338, validation accuracies: [0.41388888], average train loss: 1.987163, average train accuracy: 0.458256\n",
      "epoch: 7, iter: 34/338, loss: 2.005359, accuracy: 0.484375\n",
      "epoch: 7, iter: 134/338, loss: 1.903830, accuracy: 0.460938\n",
      "epoch: 7, iter: 234/338, loss: 1.615638, accuracy: 0.593750\n",
      "epoch: 7, iter: 334/338, loss: 1.853656, accuracy: 0.492188\n",
      "count new class: 0\n",
      "epoch: 8, iter: 0/338, validation accuracies: [0.42722223], average train loss: 1.832256, average train accuracy: 0.491679\n",
      "epoch: 8, iter: 96/338, loss: 1.729728, accuracy: 0.531250\n",
      "epoch: 8, iter: 196/338, loss: 1.722788, accuracy: 0.507812\n",
      "epoch: 8, iter: 296/338, loss: 1.734757, accuracy: 0.523438\n",
      "count new class: 0\n",
      "epoch: 9, iter: 0/338, validation accuracies: [0.47777777], average train loss: 1.718416, average train accuracy: 0.517613\n",
      "epoch: 9, iter: 58/338, loss: 1.736069, accuracy: 0.539062\n",
      "epoch: 9, iter: 158/338, loss: 1.641317, accuracy: 0.523438\n",
      "epoch: 9, iter: 258/338, loss: 1.507521, accuracy: 0.562500\n",
      "count new class: 0\n",
      "epoch: 10, iter: 0/338, validation accuracies: [0.49777778], average train loss: 1.630441, average train accuracy: 0.539663\n",
      "epoch: 10, iter: 20/338, loss: 1.594733, accuracy: 0.601562\n",
      "epoch: 10, iter: 120/338, loss: 1.579188, accuracy: 0.546875\n",
      "epoch: 10, iter: 220/338, loss: 1.416105, accuracy: 0.531250\n",
      "epoch: 10, iter: 320/338, loss: 1.302094, accuracy: 0.609375\n",
      "count new class: 0\n",
      "epoch: 11, iter: 0/338, validation accuracies: [0.48611111], average train loss: 1.531890, average train accuracy: 0.564395\n",
      "epoch: 11, iter: 82/338, loss: 1.577225, accuracy: 0.523438\n",
      "epoch: 11, iter: 182/338, loss: 1.479704, accuracy: 0.539062\n",
      "epoch: 11, iter: 282/338, loss: 1.212637, accuracy: 0.617188\n",
      "count new class: 0\n",
      "epoch: 12, iter: 0/338, validation accuracies: [0.50666667], average train loss: 1.469669, average train accuracy: 0.580090\n",
      "epoch: 12, iter: 44/338, loss: 1.403524, accuracy: 0.609375\n",
      "epoch: 12, iter: 144/338, loss: 1.338276, accuracy: 0.546875\n",
      "epoch: 12, iter: 244/338, loss: 1.130181, accuracy: 0.640625\n",
      "count new class: 0\n",
      "epoch: 13, iter: 0/338, validation accuracies: [0.51833334], average train loss: 1.398156, average train accuracy: 0.598881\n",
      "epoch: 13, iter: 6/338, loss: 1.312449, accuracy: 0.609375\n",
      "epoch: 13, iter: 106/338, loss: 1.553720, accuracy: 0.531250\n",
      "epoch: 13, iter: 206/338, loss: 1.603910, accuracy: 0.531250\n",
      "epoch: 13, iter: 306/338, loss: 1.008260, accuracy: 0.742188\n",
      "count new class: 0\n",
      "epoch: 14, iter: 0/338, validation accuracies: [0.52111112], average train loss: 1.338877, average train accuracy: 0.612079\n",
      "epoch: 14, iter: 68/338, loss: 1.449080, accuracy: 0.617188\n",
      "epoch: 14, iter: 168/338, loss: 0.907075, accuracy: 0.726562\n",
      "epoch: 14, iter: 268/338, loss: 1.483617, accuracy: 0.546875\n",
      "count new class: 0\n",
      "epoch: 15, iter: 0/338, validation accuracies: [0.53666666], average train loss: 1.287699, average train accuracy: 0.625393\n",
      "epoch: 15, iter: 30/338, loss: 1.425898, accuracy: 0.625000\n",
      "epoch: 15, iter: 130/338, loss: 1.059775, accuracy: 0.664062\n",
      "epoch: 15, iter: 230/338, loss: 1.370230, accuracy: 0.617188\n",
      "epoch: 15, iter: 330/338, loss: 1.235983, accuracy: 0.664062\n",
      "count new class: 0\n",
      "epoch: 16, iter: 0/338, validation accuracies: [0.53277777], average train loss: 1.246724, average train accuracy: 0.640902\n",
      "epoch: 16, iter: 92/338, loss: 1.159483, accuracy: 0.625000\n",
      "epoch: 16, iter: 192/338, loss: 1.226809, accuracy: 0.664062\n",
      "epoch: 16, iter: 292/338, loss: 0.951877, accuracy: 0.718750\n",
      "count new class: 0\n",
      "epoch: 17, iter: 0/338, validation accuracies: [0.55555555], average train loss: 1.201127, average train accuracy: 0.648206\n",
      "epoch: 17, iter: 54/338, loss: 1.070343, accuracy: 0.671875\n",
      "epoch: 17, iter: 154/338, loss: 1.097503, accuracy: 0.710938\n",
      "epoch: 17, iter: 254/338, loss: 1.263095, accuracy: 0.656250\n",
      "count new class: 0\n",
      "epoch: 18, iter: 0/338, validation accuracies: [0.55222222], average train loss: 1.151316, average train accuracy: 0.657591\n",
      "epoch: 18, iter: 16/338, loss: 1.156469, accuracy: 0.656250\n",
      "epoch: 18, iter: 116/338, loss: 1.150050, accuracy: 0.687500\n",
      "epoch: 18, iter: 216/338, loss: 1.107674, accuracy: 0.671875\n",
      "epoch: 18, iter: 316/338, loss: 1.029946, accuracy: 0.718750\n",
      "count new class: 0\n",
      "epoch: 19, iter: 0/338, validation accuracies: [0.53944444], average train loss: 1.122978, average train accuracy: 0.669610\n",
      "epoch: 19, iter: 78/338, loss: 0.962211, accuracy: 0.726562\n",
      "epoch: 19, iter: 178/338, loss: 1.011593, accuracy: 0.710938\n",
      "epoch: 19, iter: 278/338, loss: 0.976503, accuracy: 0.765625\n",
      "count new class: 0\n",
      "epoch: 20, iter: 0/338, validation accuracies: [0.58000001], average train loss: 1.072396, average train accuracy: 0.681005\n",
      "epoch: 20, iter: 40/338, loss: 0.887403, accuracy: 0.703125\n",
      "epoch: 20, iter: 140/338, loss: 1.091890, accuracy: 0.671875\n",
      "epoch: 20, iter: 240/338, loss: 1.027776, accuracy: 0.687500\n",
      "count new class: 0\n",
      "epoch: 21, iter: 0/338, validation accuracies: [0.55888888], average train loss: 1.049313, average train accuracy: 0.687616\n",
      "epoch: 21, iter: 2/338, loss: 1.071030, accuracy: 0.640625\n",
      "epoch: 21, iter: 102/338, loss: 0.911113, accuracy: 0.679688\n",
      "epoch: 21, iter: 202/338, loss: 1.063248, accuracy: 0.703125\n",
      "epoch: 21, iter: 302/338, loss: 0.887827, accuracy: 0.726562\n",
      "count new class: 0\n",
      "epoch: 22, iter: 0/338, validation accuracies: [0.58500001], average train loss: 1.013914, average train accuracy: 0.697138\n",
      "epoch: 22, iter: 64/338, loss: 0.905956, accuracy: 0.757812\n",
      "epoch: 22, iter: 164/338, loss: 1.074830, accuracy: 0.656250\n",
      "epoch: 22, iter: 264/338, loss: 1.077789, accuracy: 0.679688\n",
      "count new class: 0\n",
      "epoch: 23, iter: 0/338, validation accuracies: [0.56444445], average train loss: 0.988876, average train accuracy: 0.703888\n",
      "epoch: 23, iter: 26/338, loss: 0.990666, accuracy: 0.687500\n",
      "epoch: 23, iter: 126/338, loss: 0.849381, accuracy: 0.726562\n",
      "epoch: 23, iter: 226/338, loss: 1.064839, accuracy: 0.679688\n",
      "epoch: 23, iter: 326/338, loss: 1.008922, accuracy: 0.671875\n",
      "count new class: 0\n",
      "epoch: 24, iter: 0/338, validation accuracies: [0.55999999], average train loss: 0.958888, average train accuracy: 0.713480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24, iter: 88/338, loss: 1.132950, accuracy: 0.656250\n",
      "epoch: 24, iter: 188/338, loss: 1.128352, accuracy: 0.648438\n",
      "epoch: 24, iter: 288/338, loss: 0.822551, accuracy: 0.789062\n",
      "count new class: 0\n",
      "epoch: 25, iter: 0/338, validation accuracies: [0.59611112], average train loss: 0.936986, average train accuracy: 0.718496\n",
      "epoch: 25, iter: 50/338, loss: 0.885150, accuracy: 0.695312\n",
      "epoch: 25, iter: 150/338, loss: 1.040605, accuracy: 0.703125\n",
      "epoch: 25, iter: 250/338, loss: 0.865655, accuracy: 0.757812\n",
      "count new class: 0\n",
      "epoch: 26, iter: 0/338, validation accuracies: [0.57666666], average train loss: 0.905767, average train accuracy: 0.726193\n",
      "epoch: 26, iter: 12/338, loss: 1.021281, accuracy: 0.671875\n",
      "epoch: 26, iter: 112/338, loss: 0.908286, accuracy: 0.726562\n",
      "epoch: 26, iter: 212/338, loss: 0.820326, accuracy: 0.734375\n",
      "epoch: 26, iter: 312/338, loss: 0.848009, accuracy: 0.710938\n",
      "count new class: 0\n",
      "epoch: 27, iter: 0/338, validation accuracies: [0.59666668], average train loss: 0.885172, average train accuracy: 0.731185\n",
      "epoch: 27, iter: 74/338, loss: 0.925943, accuracy: 0.757812\n",
      "epoch: 27, iter: 174/338, loss: 0.730829, accuracy: 0.742188\n",
      "epoch: 27, iter: 274/338, loss: 0.902179, accuracy: 0.726562\n",
      "count new class: 0\n",
      "epoch: 28, iter: 0/338, validation accuracies: [0.59444443], average train loss: 0.866534, average train accuracy: 0.737056\n",
      "epoch: 28, iter: 36/338, loss: 0.826805, accuracy: 0.726562\n",
      "epoch: 28, iter: 136/338, loss: 0.827689, accuracy: 0.742188\n",
      "epoch: 28, iter: 236/338, loss: 0.954784, accuracy: 0.750000\n",
      "epoch: 28, iter: 336/338, loss: 0.506068, accuracy: 0.843750\n",
      "count new class: 0\n",
      "epoch: 29, iter: 0/338, validation accuracies: [0.59166668], average train loss: 0.841040, average train accuracy: 0.744083\n",
      "epoch: 29, iter: 98/338, loss: 0.781172, accuracy: 0.726562\n",
      "epoch: 29, iter: 198/338, loss: 0.837944, accuracy: 0.781250\n",
      "epoch: 29, iter: 298/338, loss: 0.681196, accuracy: 0.804688\n",
      "count new class: 0\n",
      "epoch: 30, iter: 0/338, validation accuracies: [0.58722222], average train loss: 0.826459, average train accuracy: 0.748798\n",
      "epoch: 30, iter: 60/338, loss: 0.680456, accuracy: 0.796875\n",
      "epoch: 30, iter: 160/338, loss: 0.805701, accuracy: 0.710938\n",
      "epoch: 30, iter: 260/338, loss: 0.624755, accuracy: 0.789062\n",
      "count new class: 0\n",
      "epoch: 31, iter: 0/338, validation accuracies: [0.60555555], average train loss: 0.801080, average train accuracy: 0.756426\n",
      "epoch: 31, iter: 22/338, loss: 0.930073, accuracy: 0.679688\n",
      "epoch: 31, iter: 122/338, loss: 0.844104, accuracy: 0.734375\n",
      "epoch: 31, iter: 222/338, loss: 0.869156, accuracy: 0.726562\n",
      "epoch: 31, iter: 322/338, loss: 0.749438, accuracy: 0.742188\n",
      "count new class: 0\n",
      "epoch: 32, iter: 0/338, validation accuracies: [0.61500001], average train loss: 0.785592, average train accuracy: 0.763036\n",
      "epoch: 32, iter: 84/338, loss: 0.731162, accuracy: 0.773438\n",
      "epoch: 32, iter: 184/338, loss: 0.936708, accuracy: 0.648438\n",
      "epoch: 32, iter: 284/338, loss: 0.575195, accuracy: 0.828125\n",
      "count new class: 0\n",
      "epoch: 33, iter: 0/338, validation accuracies: [0.59333334], average train loss: 0.766321, average train accuracy: 0.765232\n",
      "epoch: 33, iter: 46/338, loss: 0.768614, accuracy: 0.757812\n",
      "epoch: 33, iter: 146/338, loss: 0.701240, accuracy: 0.796875\n",
      "epoch: 33, iter: 246/338, loss: 0.838762, accuracy: 0.750000\n",
      "count new class: 0\n",
      "epoch: 34, iter: 0/338, validation accuracies: [0.60055557], average train loss: 0.753607, average train accuracy: 0.768283\n",
      "epoch: 34, iter: 8/338, loss: 0.678639, accuracy: 0.812500\n",
      "epoch: 34, iter: 108/338, loss: 0.951851, accuracy: 0.703125\n",
      "epoch: 34, iter: 208/338, loss: 0.759747, accuracy: 0.742188\n",
      "epoch: 34, iter: 308/338, loss: 0.768833, accuracy: 0.765625\n",
      "count new class: 0\n",
      "epoch: 35, iter: 0/338, validation accuracies: [0.60222223], average train loss: 0.732829, average train accuracy: 0.775032\n",
      "epoch: 35, iter: 70/338, loss: 0.578417, accuracy: 0.789062\n",
      "epoch: 35, iter: 170/338, loss: 0.688357, accuracy: 0.757812\n",
      "epoch: 35, iter: 270/338, loss: 0.800293, accuracy: 0.773438\n",
      "count new class: 0\n",
      "epoch: 36, iter: 0/338, validation accuracies: [0.60833334], average train loss: 0.732556, average train accuracy: 0.774871\n",
      "epoch: 36, iter: 32/338, loss: 0.756532, accuracy: 0.781250\n",
      "epoch: 36, iter: 132/338, loss: 0.812595, accuracy: 0.742188\n",
      "epoch: 36, iter: 232/338, loss: 0.657115, accuracy: 0.796875\n",
      "epoch: 36, iter: 332/338, loss: 0.704042, accuracy: 0.757812\n",
      "count new class: 0\n",
      "epoch: 37, iter: 0/338, validation accuracies: [0.61166666], average train loss: 0.702984, average train accuracy: 0.782429\n",
      "epoch: 37, iter: 94/338, loss: 0.682809, accuracy: 0.804688\n",
      "epoch: 37, iter: 194/338, loss: 0.823755, accuracy: 0.757812\n",
      "epoch: 37, iter: 294/338, loss: 0.723519, accuracy: 0.781250\n",
      "count new class: 0\n",
      "epoch: 38, iter: 0/338, validation accuracies: [0.59999999], average train loss: 0.694715, average train accuracy: 0.783561\n",
      "epoch: 38, iter: 56/338, loss: 0.703194, accuracy: 0.789062\n",
      "epoch: 38, iter: 156/338, loss: 0.657803, accuracy: 0.796875\n",
      "epoch: 38, iter: 256/338, loss: 0.616417, accuracy: 0.812500\n",
      "count new class: 0\n",
      "epoch: 39, iter: 0/338, validation accuracies: [0.62000001], average train loss: 0.678984, average train accuracy: 0.788785\n",
      "epoch: 39, iter: 18/338, loss: 0.715270, accuracy: 0.835938\n",
      "epoch: 39, iter: 118/338, loss: 0.675322, accuracy: 0.796875\n",
      "epoch: 39, iter: 218/338, loss: 0.404202, accuracy: 0.867188\n",
      "epoch: 39, iter: 318/338, loss: 0.452694, accuracy: 0.835938\n",
      "count new class: 0\n",
      "epoch: 40, iter: 0/338, validation accuracies: [0.62666667], average train loss: 0.657591, average train accuracy: 0.794425\n",
      "epoch: 40, iter: 80/338, loss: 0.520160, accuracy: 0.843750\n",
      "epoch: 40, iter: 180/338, loss: 0.666530, accuracy: 0.781250\n",
      "epoch: 40, iter: 280/338, loss: 0.619989, accuracy: 0.796875\n",
      "count new class: 0\n",
      "epoch: 41, iter: 0/338, validation accuracies: [0.60999999], average train loss: 0.650266, average train accuracy: 0.798470\n",
      "epoch: 41, iter: 42/338, loss: 0.594600, accuracy: 0.828125\n",
      "epoch: 41, iter: 142/338, loss: 0.503446, accuracy: 0.890625\n",
      "epoch: 41, iter: 242/338, loss: 0.534498, accuracy: 0.835938\n",
      "count new class: 0\n",
      "epoch: 42, iter: 0/338, validation accuracies: [0.61277777], average train loss: 0.640601, average train accuracy: 0.798054\n",
      "epoch: 42, iter: 4/338, loss: 0.596525, accuracy: 0.773438\n",
      "epoch: 42, iter: 104/338, loss: 0.547126, accuracy: 0.851562\n",
      "epoch: 42, iter: 204/338, loss: 0.628669, accuracy: 0.812500\n",
      "epoch: 42, iter: 304/338, loss: 0.552959, accuracy: 0.835938\n",
      "count new class: 0\n",
      "epoch: 43, iter: 0/338, validation accuracies: [0.61666668], average train loss: 0.629008, average train accuracy: 0.806028\n",
      "epoch: 43, iter: 66/338, loss: 0.501779, accuracy: 0.804688\n",
      "epoch: 43, iter: 166/338, loss: 0.500786, accuracy: 0.828125\n",
      "epoch: 43, iter: 266/338, loss: 0.630274, accuracy: 0.796875\n",
      "count new class: 0\n",
      "epoch: 44, iter: 0/338, validation accuracies: [0.61777777], average train loss: 0.599734, average train accuracy: 0.811437\n",
      "epoch: 44, iter: 28/338, loss: 0.745297, accuracy: 0.757812\n",
      "epoch: 44, iter: 128/338, loss: 0.643167, accuracy: 0.796875\n",
      "epoch: 44, iter: 228/338, loss: 0.656863, accuracy: 0.789062\n",
      "epoch: 44, iter: 328/338, loss: 0.584575, accuracy: 0.820312\n",
      "count new class: 0\n",
      "epoch: 45, iter: 0/338, validation accuracies: [0.63166667], average train loss: 0.594866, average train accuracy: 0.812685\n",
      "epoch: 45, iter: 90/338, loss: 0.625747, accuracy: 0.804688\n",
      "epoch: 45, iter: 190/338, loss: 0.600334, accuracy: 0.812500\n",
      "epoch: 45, iter: 290/338, loss: 0.662898, accuracy: 0.828125\n",
      "count new class: 0\n",
      "epoch: 46, iter: 0/338, validation accuracies: [0.6238889], average train loss: 0.585662, average train accuracy: 0.816337\n",
      "epoch: 46, iter: 52/338, loss: 0.726478, accuracy: 0.781250\n",
      "epoch: 46, iter: 152/338, loss: 0.520221, accuracy: 0.851562\n",
      "epoch: 46, iter: 252/338, loss: 0.704056, accuracy: 0.781250\n",
      "count new class: 0\n",
      "epoch: 47, iter: 0/338, validation accuracies: [0.61611111], average train loss: 0.568910, average train accuracy: 0.824797\n",
      "epoch: 47, iter: 14/338, loss: 0.478305, accuracy: 0.843750\n",
      "epoch: 47, iter: 114/338, loss: 0.744929, accuracy: 0.804688\n",
      "epoch: 47, iter: 214/338, loss: 0.523082, accuracy: 0.796875\n",
      "epoch: 47, iter: 314/338, loss: 0.460510, accuracy: 0.875000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count new class: 0\n",
      "epoch: 48, iter: 0/338, validation accuracies: [0.61944443], average train loss: 0.566209, average train accuracy: 0.822693\n",
      "epoch: 48, iter: 76/338, loss: 0.635339, accuracy: 0.820312\n",
      "epoch: 48, iter: 176/338, loss: 0.513040, accuracy: 0.835938\n",
      "epoch: 48, iter: 276/338, loss: 0.640295, accuracy: 0.773438\n",
      "count new class: 0\n",
      "epoch: 49, iter: 0/338, validation accuracies: [0.6], average train loss: 0.560627, average train accuracy: 0.822924\n",
      "epoch: 49, iter: 38/338, loss: 0.468513, accuracy: 0.875000\n",
      "epoch: 49, iter: 138/338, loss: 0.428258, accuracy: 0.851562\n",
      "epoch: 49, iter: 238/338, loss: 0.351473, accuracy: 0.914062\n",
      "count new class: 0\n",
      "epoch: 50, iter: 0/338, validation accuracies: [0.66611111], average train loss: 0.420837, average train accuracy: 0.869499\n",
      "epoch: 50, iter: 0/338, loss: 0.305917, accuracy: 0.906250\n",
      "epoch: 50, iter: 100/338, loss: 0.361732, accuracy: 0.875000\n",
      "epoch: 50, iter: 200/338, loss: 0.356939, accuracy: 0.914062\n",
      "epoch: 50, iter: 300/338, loss: 0.498496, accuracy: 0.859375\n",
      "count new class: 0\n",
      "epoch: 51, iter: 0/338, validation accuracies: [0.66611111], average train loss: 0.360307, average train accuracy: 0.890764\n",
      "epoch: 51, iter: 62/338, loss: 0.270521, accuracy: 0.945312\n",
      "epoch: 51, iter: 162/338, loss: 0.190947, accuracy: 0.937500\n",
      "epoch: 51, iter: 262/338, loss: 0.443171, accuracy: 0.851562\n",
      "count new class: 0\n",
      "epoch: 52, iter: 0/338, validation accuracies: [0.67055557], average train loss: 0.337932, average train accuracy: 0.896427\n",
      "epoch: 52, iter: 24/338, loss: 0.242161, accuracy: 0.953125\n",
      "epoch: 52, iter: 124/338, loss: 0.336445, accuracy: 0.882812\n",
      "epoch: 52, iter: 224/338, loss: 0.323472, accuracy: 0.906250\n",
      "epoch: 52, iter: 324/338, loss: 0.290002, accuracy: 0.921875\n",
      "count new class: 0\n",
      "epoch: 53, iter: 0/338, validation accuracies: [0.66499999], average train loss: 0.321643, average train accuracy: 0.900864\n",
      "epoch: 53, iter: 86/338, loss: 0.306242, accuracy: 0.921875\n",
      "epoch: 53, iter: 186/338, loss: 0.341091, accuracy: 0.882812\n",
      "epoch: 53, iter: 286/338, loss: 0.425025, accuracy: 0.875000\n",
      "count new class: 0\n",
      "epoch: 54, iter: 0/338, validation accuracies: [0.66555556], average train loss: 0.319584, average train accuracy: 0.900379\n",
      "epoch: 54, iter: 48/338, loss: 0.491660, accuracy: 0.835938\n",
      "epoch: 54, iter: 148/338, loss: 0.183566, accuracy: 0.953125\n",
      "epoch: 54, iter: 248/338, loss: 0.228061, accuracy: 0.937500\n",
      "count new class: 0\n",
      "epoch: 55, iter: 0/338, validation accuracies: [0.66833332], average train loss: 0.301185, average train accuracy: 0.907752\n",
      "epoch: 55, iter: 10/338, loss: 0.315751, accuracy: 0.914062\n",
      "epoch: 55, iter: 110/338, loss: 0.209945, accuracy: 0.921875\n",
      "epoch: 55, iter: 210/338, loss: 0.374931, accuracy: 0.898438\n",
      "epoch: 55, iter: 310/338, loss: 0.240529, accuracy: 0.921875\n",
      "count new class: 0\n",
      "epoch: 56, iter: 0/338, validation accuracies: [0.66277778], average train loss: 0.294814, average train accuracy: 0.908215\n",
      "epoch: 56, iter: 72/338, loss: 0.260976, accuracy: 0.921875\n",
      "epoch: 56, iter: 172/338, loss: 0.265880, accuracy: 0.937500\n",
      "epoch: 56, iter: 272/338, loss: 0.454422, accuracy: 0.890625\n",
      "count new class: 0\n",
      "epoch: 57, iter: 0/338, validation accuracies: [0.66277778], average train loss: 0.285749, average train accuracy: 0.910411\n",
      "epoch: 57, iter: 34/338, loss: 0.217864, accuracy: 0.921875\n",
      "epoch: 57, iter: 134/338, loss: 0.365365, accuracy: 0.890625\n",
      "epoch: 57, iter: 234/338, loss: 0.182100, accuracy: 0.953125\n",
      "epoch: 57, iter: 334/338, loss: 0.158863, accuracy: 0.960938\n",
      "count new class: 0\n",
      "epoch: 58, iter: 0/338, validation accuracies: [0.67388889], average train loss: 0.281159, average train accuracy: 0.913022\n",
      "epoch: 58, iter: 96/338, loss: 0.260343, accuracy: 0.929688\n",
      "epoch: 58, iter: 196/338, loss: 0.278658, accuracy: 0.906250\n",
      "epoch: 58, iter: 296/338, loss: 0.185029, accuracy: 0.968750\n",
      "count new class: 0\n",
      "epoch: 59, iter: 0/338, validation accuracies: [0.66333334], average train loss: 0.277112, average train accuracy: 0.914409\n",
      "epoch: 59, iter: 58/338, loss: 0.339166, accuracy: 0.875000\n",
      "epoch: 59, iter: 158/338, loss: 0.298222, accuracy: 0.914062\n",
      "epoch: 59, iter: 258/338, loss: 0.374669, accuracy: 0.882812\n",
      "count new class: 0\n",
      "epoch: 60, iter: 0/338, validation accuracies: [0.66388888], average train loss: 0.269134, average train accuracy: 0.915103\n",
      "epoch: 60, iter: 20/338, loss: 0.210184, accuracy: 0.914062\n",
      "epoch: 60, iter: 120/338, loss: 0.347626, accuracy: 0.890625\n",
      "epoch: 60, iter: 220/338, loss: 0.237653, accuracy: 0.929688\n",
      "epoch: 60, iter: 320/338, loss: 0.292981, accuracy: 0.890625\n",
      "count new class: 0\n",
      "epoch: 61, iter: 0/338, validation accuracies: [0.66277778], average train loss: 0.264924, average train accuracy: 0.917391\n",
      "epoch: 61, iter: 82/338, loss: 0.224367, accuracy: 0.937500\n",
      "epoch: 61, iter: 182/338, loss: 0.369352, accuracy: 0.890625\n",
      "epoch: 61, iter: 282/338, loss: 0.256721, accuracy: 0.898438\n",
      "count new class: 0\n",
      "epoch: 62, iter: 0/338, validation accuracies: [0.66166666], average train loss: 0.260808, average train accuracy: 0.918200\n",
      "epoch: 62, iter: 44/338, loss: 0.294928, accuracy: 0.898438\n",
      "epoch: 62, iter: 144/338, loss: 0.334631, accuracy: 0.898438\n",
      "epoch: 62, iter: 244/338, loss: 0.171267, accuracy: 0.937500\n",
      "count new class: 0\n",
      "epoch: 63, iter: 0/338, validation accuracies: [0.66388888], average train loss: 0.255861, average train accuracy: 0.920234\n",
      "epoch: 63, iter: 6/338, loss: 0.237595, accuracy: 0.921875\n",
      "epoch: 63, iter: 106/338, loss: 0.219160, accuracy: 0.914062\n",
      "epoch: 63, iter: 206/338, loss: 0.310528, accuracy: 0.914062\n",
      "epoch: 63, iter: 306/338, loss: 0.154735, accuracy: 0.953125\n",
      "count new class: 0\n",
      "epoch: 64, iter: 0/338, validation accuracies: [0.66944443], average train loss: 0.240793, average train accuracy: 0.926405\n",
      "epoch: 64, iter: 68/338, loss: 0.254784, accuracy: 0.914062\n",
      "epoch: 64, iter: 168/338, loss: 0.262368, accuracy: 0.921875\n",
      "epoch: 64, iter: 268/338, loss: 0.223513, accuracy: 0.929688\n",
      "count new class: 0\n",
      "epoch: 65, iter: 0/338, validation accuracies: [0.66777778], average train loss: 0.234819, average train accuracy: 0.927815\n",
      "epoch: 65, iter: 30/338, loss: 0.231074, accuracy: 0.945312\n",
      "epoch: 65, iter: 130/338, loss: 0.217020, accuracy: 0.937500\n",
      "epoch: 65, iter: 230/338, loss: 0.266213, accuracy: 0.890625\n",
      "epoch: 65, iter: 330/338, loss: 0.212737, accuracy: 0.929688\n",
      "count new class: 0\n",
      "epoch: 66, iter: 0/338, validation accuracies: [0.66944444], average train loss: 0.228609, average train accuracy: 0.930150\n",
      "epoch: 66, iter: 92/338, loss: 0.265426, accuracy: 0.906250\n",
      "epoch: 66, iter: 192/338, loss: 0.218227, accuracy: 0.929688\n",
      "epoch: 66, iter: 292/338, loss: 0.286786, accuracy: 0.929688\n",
      "count new class: 0\n",
      "epoch: 67, iter: 0/338, validation accuracies: [0.66611111], average train loss: 0.224159, average train accuracy: 0.932369\n",
      "epoch: 67, iter: 54/338, loss: 0.180671, accuracy: 0.937500\n",
      "epoch: 67, iter: 154/338, loss: 0.268298, accuracy: 0.921875\n",
      "epoch: 67, iter: 254/338, loss: 0.222443, accuracy: 0.945312\n",
      "count new class: 0\n",
      "epoch: 68, iter: 0/338, validation accuracies: [0.67000001], average train loss: 0.223538, average train accuracy: 0.931745\n",
      "epoch: 68, iter: 16/338, loss: 0.167891, accuracy: 0.945312\n",
      "epoch: 68, iter: 116/338, loss: 0.192199, accuracy: 0.953125\n",
      "epoch: 68, iter: 216/338, loss: 0.235458, accuracy: 0.921875\n",
      "epoch: 68, iter: 316/338, loss: 0.169637, accuracy: 0.945312\n",
      "count new class: 0\n",
      "epoch: 69, iter: 0/338, validation accuracies: [0.66777777], average train loss: 0.222547, average train accuracy: 0.932923\n",
      "epoch: 69, iter: 78/338, loss: 0.293502, accuracy: 0.898438\n",
      "epoch: 69, iter: 178/338, loss: 0.255120, accuracy: 0.914062\n",
      "epoch: 69, iter: 278/338, loss: 0.244032, accuracy: 0.921875\n",
      "count new class: 0\n",
      "epoch: 70, iter: 0/338, validation accuracies: [0.67111112], average train loss: 0.215873, average train accuracy: 0.934403\n",
      "epochs: 70.000000, final train loss: 0.218073, validation accuracies: [0.67111112]\n",
      "best epochs: 58.000000, best_avg: 0.673889, validation accuracies: [0.66277778]\n",
      "saving model dropout_hidden_prob=0.9,dropout_input_prob=0.9,learning_rate=too_long,momentum=0.9,reg=1e-05,bf_num_images=2000,mask_softmax=True,old:new=1.0,task=0 at time step 23660\n",
      "calculating penultimate output...\n",
      "time taken: %f 3.9225914478302\n",
      "saving penultimate output...\n"
     ]
    }
   ],
   "source": [
    "best_avg, best_hparams_index = tuner.tuneTasksInRange(0, t, BATCH_SIZE, num_hparams, \n",
    "                                                        num_updates=num_updates, verbose=True, \n",
    "                                                        random_crop_flip=True, \n",
    "                                                        equal_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6721111110581292]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.test(t, BATCH_SIZE, restore_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_best_avg: 6.738889e-01, num_updates: 58\n",
      "best val_acc: [0.66277778]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "best_hparams_tuple = tuner.hparamsDictToTuple(hparams[0], tuner.tuner_hparams)\n",
    "cur_res = tuner.results_list[t][best_hparams_tuple][0]\n",
    "x = np.arange(0, cur_res['total_updates'], cur_res['updates_per_epoch'])\n",
    "cur_best_avg = cur_res['best_avg']\n",
    "cur_best_epoch = cur_res['best_epoch']\n",
    "updates_per_epoch = cur_res['updates_per_epoch']\n",
    "# print(\"dropout: %f, fisher_multiplier: %e, lr: %e\" % (k[0], k[1], k[2]))\n",
    "print(\"cur_best_avg: %e, num_updates: %d\" % (cur_best_avg, cur_best_epoch))\n",
    "print(\"best val_acc: %s\" % (str(np.array(cur_res['val_acc'])[:, (cur_best_epoch - 1) // tuner.eval_frequency])))\n",
    "# plt.plot(cur_res['loss_with_penalty'], color='g')\n",
    "# plt.plot(cur_res['loss'], color='m')\n",
    "# plt.plot(x, cur_res['val_loss'][-1], color='b')\n",
    "# plt.show()\n",
    "# plt.ylim(ymin=0.9)\n",
    "# plt.plot(cur_res['val_acc'][-1], color='b', )\n",
    "plt.plot(cur_res['val_acc'][0], color='g', )\n",
    "# plt.plot(cur_res['val_acc'][1], color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 2\n",
    "learning_rates = [(((49, 1e-1), (63, 1e-1 / 5), 1e-1 / (5 * 5)), (1e-1, ))]\n",
    "momentums = [0.9]\n",
    "regs = [0.00001]\n",
    "dropout_input_probs = [1.0]\n",
    "dropout_hidden_probs = [0.9]\n",
    "prod = list(itertools.product(regs, dropout_input_probs, dropout_hidden_probs, momentums, learning_rates))\n",
    "hparams = []\n",
    "for hparams_tuple in prod:\n",
    "    cur_dict = {}\n",
    "    cur_dict['reg'] = hparams_tuple[0]\n",
    "    cur_dict['dropout_input_prob'] = hparams_tuple[2]\n",
    "    cur_dict['dropout_hidden_prob'] = hparams_tuple[2]\n",
    "    cur_dict['momentum'] = hparams_tuple[3]\n",
    "    cur_dict['learning_rate'] = hparams_tuple[4]\n",
    "    hparams.append(cur_dict)\n",
    "    \n",
    "for i in range(1, t + 1):\n",
    "    tuner.hparams_list[i] = hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hparams = len(hparams)\n",
    "num_epochs = 70\n",
    "num_updates = math.ceil(tuner.task_list[t].train.images.shape[0] / BATCH_SIZE) * num_epochs\n",
    "tuner.print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_avg, best_hparams_index, test_acc = tuner.tuneTasksInRange(1, t, BATCH_SIZE, num_hparams, \n",
    "                                                        num_updates=num_updates, verbose=True, \n",
    "                                                        random_crop_flip=True, \n",
    "                                                        equal_weights=True, \n",
    "                                                        eval_test_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "best_hparams_tuple = tuner.hparamsDictToTuple(hparams[0], tuner.tuner_hparams)\n",
    "cur_res = tuner.results_list[t][best_hparams_tuple][0]\n",
    "x = np.arange(0, cur_res['total_updates'], cur_res['updates_per_epoch'])\n",
    "cur_best_avg = cur_res['best_avg']\n",
    "cur_best_epoch = cur_res['best_epoch']\n",
    "updates_per_epoch = cur_res['updates_per_epoch']\n",
    "# print(\"dropout: %f, fisher_multiplier: %e, lr: %e\" % (k[0], k[1], k[2]))\n",
    "print(\"cur_best_avg: %e, num_updates: %d\" % (cur_best_avg, cur_best_epoch))\n",
    "print(\"best val_acc: %s\" % (str(np.array(cur_res['val_acc'])[:, (cur_best_epoch - 1) // tuner.eval_frequency])))\n",
    "# plt.plot(cur_res['loss_with_penalty'], color='g')\n",
    "# plt.plot(cur_res['loss'], color='m')\n",
    "# plt.plot(x, cur_res['val_loss'][-1], color='b')\n",
    "# plt.show()\n",
    "# plt.ylim(ymin=0.9)\n",
    "plt.plot(cur_res['val_acc'][-1], color='b', )\n",
    "plt.plot(cur_res['val_acc'][0], color='g', )\n",
    "# plt.plot(cur_res['val_acc'][1], color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllCosineSimilarity(wts, init_classes, only_dot=False):\n",
    "    num_init_class = len(init_classes)\n",
    "    cosine_wts = [[0.0 for _ in range(num_init_class)] for _ in range(num_init_class)]\n",
    "    for i in range(num_init_class):\n",
    "        for j in range(num_init_class):\n",
    "            w_i = wts[0][:, init_classes[i]]\n",
    "            w_j = wts[0][:, init_classes[j]]\n",
    "            if (only_dot):\n",
    "                cosine_wts[i][j] = np.sum(w_i * w_j)\n",
    "            else:\n",
    "                cosine_wts[i][j] = np.sum(w_i * w_j) / np.sqrt(np.sum(w_i ** 2)) / np.sqrt(np.sum(w_j ** 2))\n",
    "    return cosine_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tasks_test = 10\n",
    "wts = [None for _ in range(num_tasks_test)]\n",
    "init_classes = tuner.split[0]\n",
    "cosine_sim_wts = [None for _ in range(num_tasks_test)]\n",
    "dot_sim_wts = [None for _ in range(num_tasks_test)]\n",
    "for i in range(num_tasks_test):\n",
    "    tuner.test(i, BATCH_SIZE, restore_model=True, hparams=tuner.hparams_list[i][0])\n",
    "    wts[i] = sess.run([v for v in tf.all_variables() if 'dense' in v.name and 'kernel:0' in v.name])\n",
    "    cosine_sim_wts[i] = np.array(getAllCosineSimilarity(wts[i], init_classes, only_dot=False))\n",
    "    dot_sim_wts[i] = np.array(getAllCosineSimilarity(wts[i], init_classes, only_dot=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_tasks_test):\n",
    "#     plt.imshow(cosine_sim_wts[i])\n",
    "    print(\"task\", i)\n",
    "    print(\"sum cosine: \", np.sum(cosine_sim_wts[i]) - num_init_class)\n",
    "    print(\"sum dot: \", np.sum(dot_sim_wts[i]) - np.sum(wts[i][0][: , init_classes] ** 2))\n",
    "    print(\"sum norms: \", np.sum(np.sqrt(np.sum(wts[i][0][:, init_classes] ** 2, axis=0))))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.saveResultsList()\n",
    "tuner.saveBestHparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 128\n",
    "test_accuracies = []\n",
    "for i in range(t + 1):\n",
    "    accuracy = tuner.test(i, TEST_BATCH_SIZE, restore_model=False)\n",
    "    test_accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(t + 1):\n",
    "    print(test_accuracies[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_tpu:\n",
    "    sess.run(tpu.shutdown_system())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "filename='code_state.bak'\n",
    "my_shelf = shelve.open(filename,'n') # 'n' for new\n",
    "\n",
    "for key in dir():\n",
    "    try:\n",
    "        my_shelf[key] = globals()[key]\n",
    "    except TypeError:\n",
    "        #\n",
    "        # __builtins__, my_shelf, and imported modules can not be shelved.\n",
    "        #\n",
    "        print('ERROR shelving: {0}'.format(key))\n",
    "my_shelf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
